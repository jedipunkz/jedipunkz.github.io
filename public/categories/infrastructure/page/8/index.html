


    
        
    




<!DOCTYPE HTML>

<html>
    <head>
        
            <title>Infrastructure Posts - ジェダイさんのブログ</title>
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="generator" content="Hugo 0.53" />
        


        
        
            
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Infrastructure"/>
<meta name="twitter:description" content=""/>

        <meta property="og:title" content="Infrastructure" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://jedipunkz.github.io/categories/infrastructure/" />
<meta property="og:updated_time" content="2013-05-19T00:00:00&#43;00:00"/>

        
<meta itemprop="name" content="Infrastructure">
<meta itemprop="description" content="">


        

        

        
        
            
        

        
        
            <link rel="stylesheet" href="/css/google-font.css" />
            <link rel="stylesheet" href="/css/font-awesome.min.css" />
            <link rel="stylesheet" href="/css/main.css" />
            <link rel="stylesheet" href="/css/add-on.css" />
            <link rel="stylesheet" href="/css/monokai-sublime.css">
        

        

        
        
        
            
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-30563095-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

        
    </head>
    <body>

        
        <div id="wrapper">

    
<header id="header">
    
        <h2><a href="/"></i></a></h2>
    

    <nav class="links">
        <ul>
            
                <li>
                    <a href="">
                        Blog
                    </a>
                </li>
            
                <li>
                    <a href="about/index.html">
                        About
                    </a>
                </li>
            
        </ul>
    </nav>
    <nav class="main">
        <ul>
            
            <li class="search">
                <a class="fa-search" href="#search">Search</a>
                <form id="search" method="get" action="//google.com/search">
                    <input type="text" name="q" placeholder="Search" />
                    <input type="hidden" name="q" value="site:https://jedipunkz.github.io">
                </form>
            </li>
            <li class="menu">
                <a class="fa-bars" href="#menu">Menu</a>
            </li>
        </ul>
    </nav>
</header>


<section id="menu">

    
        <section>
            <form class="search" method="get" action="//google.com/search">
                <input type="text" name="q" placeholder="Search" />
                <input type="hidden" name="q" value="site:https://jedipunkz.github.io">
            </form>
        </section>

    
        <section>
            <ul class="links">
                
                    <li>
                        <a href="">
                            <h3>
                                
                                Blog
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="about/index.html">
                            <h3>
                                
                                About
                            </h3>
                        </a>
                    </li>
                
            </ul>
        </section>

    
        <section>
            <ul class="links">
                <header>
                    <h3>Recent Posts</h3>
                </header>
                
                    
                

                
                    <li>
                        <a href="https://jedipunkz.github.io/blog/2018/12/31/istio/"><p>Istio, Helm を使って Getting Started 的なアプリをデプロイ</p></a>
                    </li>
                
                    <li>
                        <a href="https://jedipunkz.github.io/blog/2017/07/02/test-kitchen-cluster/"><p>Docker,Test-Kitchen,Ansible でクラスタを構成する</p></a>
                    </li>
                
                    <li>
                        <a href="https://jedipunkz.github.io/blog/2017/04/13/gke-lb/"><p>GCP ロードバランサと GKE クラスタを Terraform を使って構築する</p></a>
                    </li>
                
                    <li>
                        <a href="https://jedipunkz.github.io/blog/2017/02/12/serverless-fission/"><p>Serverless on Kubernetes : Fission を使ってみた</p></a>
                    </li>
                
                    <li>
                        <a href="https://jedipunkz.github.io/blog/2017/01/13/kubernetes-deployments/"><p>Kubernetes Deployments を使ってみた！</p></a>
                    </li>
                
            </ul>
        </section>

    
        
</section>

    
    <div id="main">
        <h1>Infrastructure</h1>
        
        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/05/19/openstack-ceph/">OpenStack &#43; Ceph 連携</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-05-19'>
            May 19, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>こんにちは。最近 OpenStack の導入に向けて保守性や可用性について調査している
<a href="https://twitter.com/jedipunkz">@jedipunkz</a> です。</p>

<p>OpenStack は MySQL のダンプや OS イメージ・スナップショットのバックアップをとっ
ておけばコントローラの復旧も出来ますし、Grizzly 版の Quantum では冗長や分散が
取れるので障害時に耐えられます。また Quantum の復旧は手動もで可能です。最後の
悩みだった Cinder の接続先ストレージですが、OpenStack のスタンスとしては高価な
ストレージの機能を使ってバックアップ取るか、Ceph, SheepDog のようなオープンソー
スを使うか、でした。で、今回は Ceph を OpenStack に連携させようと思いました。</p>

<p>この作業により Cinder の接続先ストレージが Ceph になるのと Glance の OS イメー
ジ・スナップショットの保管先が Ceph になります。</p>

<p>下記の参考資料が完成度高く、ほぼ内容はそのままです。若干付け足していますが。</p>

<h2 id="参考資料">参考資料</h2>

<p><a href="http://ceph.com/docs/master/rbd/rbd-openstack/">http://ceph.com/docs/master/rbd/rbd-openstack/</a></p>

<h2 id="前提の構成">前提の構成</h2>

<pre><code>+-------------+-------------+--------------------------------------------- Public/API Network
|             |             |             
+-----------+ +-----------+ +-----------+ +-----------+ +-----------+ +-----------+
|           | |           | |vm|vm|..   | |           | |           | |           |
| controller| |  network  | +-----------+ |  ceph01   | |  ceph01   | |  ceph01   |
|           | |           | |  compute  | |           | |           | |           |
|           | |           | |           | |           | |           | |           |
+-----------+ +-----------+ +-----------+ +-----------+ +-----------+ +-----------+
|             |     |       |     |       |             |             |
+-------------+-----)-------+-----)-------+-------------+-------------+-- Management/API Network
                    |             |                       
                    +-------------+-----------------------------------+-- Data Network
</code></pre>

<ul>
<li>Ceph は OpenStack の Management Network 上に配置</li>
<li>Ceph は3台構成 (何台でも可)</li>
<li>OpenStack も3台構成 (何台でも可)</li>
<li>連携処理するのは controller, compute ノード</li>
</ul>

<p>では早速手順ですが、OpenStack と Ceph の構築手順は割愛します。私の他の記事を参
考にしていただければと思います。</p>

<ul>
<li><a href="http://jedipunkz.github.io/blog/2013/04/20/openstack-grizzly-installation-script/">構築スクリプト</a></li>
<li><a href="http://jedipunkz.github.io/blog/2013/05/11/ceph-deploy/">ceph-deploy で Ceph 構築</a></li>
</ul>

<h2 id="ceph-openstack-連携手順">Ceph + OpenStack 連携手順</h2>

<h4 id="openstack-用に-ceph-pool-を作成する">OpenStack 用に Ceph Pool を作成する</h4>

<pre><code>ceph01% sudo ceph pool create volumes 128
ceph01% sudo ceph pool create images 128
</code></pre>

<h4 id="sudoers-の設定">sudoers の設定</h4>

<p>controller, compute ノードにて sudoers の設定</p>

<pre><code>jedipunkz ALL = (root) NOPASSWD:ALL
</code></pre>

<h4 id="ceph-パッケージのインストール">ceph パッケージのインストール</h4>

<p>controller, compute ノードに ceph をインストールする。</p>

<pre><code>controller% wget -q -O- 'https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc' | sudo apt-key add -
controller% echo deb http://ceph.com/debian/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list
controller% sudo apt-get update &amp;&amp; sudo apt-get install -y python-ceph ceph-common
</code></pre>

<h4 id="etc-ceph-作成">/etc/ceph 作成</h4>

<pre><code>controller% sudo mkdir /etc/ceph
compute   % sudo mkdir /etc/ceph
</code></pre>

<h4 id="ceph-コンフィギュレーションのコピー">ceph コンフィギュレーションのコピー</h4>

<p>controller, compute ノードに ceph コンフィギュレーションをコピーする。尚、接続
先の OpenStack ノードでの sudoers 設定は予め済ませること。</p>

<pre><code>ceph01% sudo -i
ceph01# ssh &lt;controller&gt; sudo tee /etc/ceph/ceph.conf &lt;/etc/ceph/ceph.conf
ceph01# ssh &lt;compute&gt; sudo tee /etc/ceph/ceph.conf &lt;/etc/ceph/ceph.conf
</code></pre>

<h4 id="認証設定">認証設定</h4>

<p>nova, cinder, glance 用にユーザを作成する。</p>

<pre><code>ceph01% sudo ceph auth get-or-create client.volumes mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rx pool=images'
ceph01% sudo ceph auth get-or-create client.images mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images'
</code></pre>

<h4 id="キーリングの作成">キーリングの作成</h4>

<p>Ceph キーリングの作成を行う。Glance, Cinder が起動しているホスト controller ノードに
キーリングを配置する。</p>

<pre><code>ceph01% sudo ceph auth get-or-create client.images | ssh {your-glance-api-server} sudo tee /etc/ceph/ceph.client.images.keyring
ceph01% ssh {your-glance-api-server} sudo chown glance:glance /etc/ceph/ceph.client.images.keyring
ceph01% sudo ceph auth get-or-create client.volumes | ssh {your-volume-server} sudo tee /etc/ceph/ceph.client.volumes.keyring
ceph01% ssh {your-volume-server} sudo chown cinder:cinder /etc/ceph/ceph.client.volumes.keyring
</code></pre>

<p>compute ノードにて libvirt に secret key を格納する。ここで登場する uuid は後
に利用するためメモをとっておくこと。</p>

<pre><code>ceph01 % sudo ceph auth get-key client.volumes | ssh 10.200.10.59 tee client.volumes.key

compute% cat &gt; secret.xml &lt;&lt;EOF
&lt;secret ephemeral='no' private='no'&gt;
  &lt;usage type='ceph'&gt;
    &lt;name&gt;client.volumes secret&lt;/name&gt;
  &lt;/usage&gt;
&lt;/secret&gt;
EOF
comupte% sudo virsh secret-define --file secret.xml
&lt;uuid of secret is output here&gt;
compute% sudo virsh secret-set-value --secret {uuid of secret} --base64 $(cat client.volumes.key) &amp;&amp; rm client.volumes.key secret.xml
</code></pre>

<h4 id="openstack-連携のための設定">OpenStack 連携のための設定</h4>

<p>controller:/etc/glance/glance-api.conf に下記を追記。</p>

<pre><code>default_store=rbd
rbd_store_user=images
rbd_store_pool=images
show_image_direct_url=True
</code></pre>

<p>controller:/etc/cinder/cinder.conf に下記を追記。先ほど登場した uuid を入力す
る。</p>

<pre><code>volume_driver=cinder.volume.driver.RBDDriver
rbd_pool=volumes
rbd_user=volumes
rbd_secret_uuid={uuid of secret}
</code></pre>

<p>controller:/etc/init/cinder-volume.conf の冒頭に下記の記述を追記する。</p>

<pre><code>env CEPH_ARGS=&quot;--id volumes&quot;
</code></pre>

<p>OpenStack の各サービスを再起動もしくはホストの再起動を行う。</p>

<pre><code>sudo service glance-api restart
sudo service nova-compute restart
sudo service cinder-volume restart
</code></pre>

<h4 id="確認">確認</h4>

<p>実際にインスタンスを作成して Volume をアタッチしディスクを消費していくと Ceph
のディスク使用量が増えていきます。</p>

<pre><code>% cinder create --display-name test 5
% nova volumeattach &lt;instance_id&gt; &lt;volume_id&gt; auto
</code></pre>

<h2 id="まとめ">まとめ</h2>

<p>Cinder は分散ストレージですので各ファイルのレプリカが全て失われない限りデータ
はロストしません。ただし Ceph 自体の完成度は以前に比べ高くはなったものの、運用
に耐えられるかどうかまだ私にも分かりません。先日の OpenStack Day に来日してい
たファウンデーションの方が「ベンダロックインするな」と言っていました。僕もオー
プンソースでなんとかしたいと思っています。OpenStack を導入するためには今、Ceph
は欠かすことが出来ないコンポーネントな気がしています。皆で Ceph も盛り上げて行
きたいです。</p>

<p>また、この構成の際のOpenStack 全体の保全について考えると&hellip;</p>

<ul>
<li>MySQL のデータさえダンプの取得すれば OK</li>
<li>OS イメージ・スナップショットは Ceph 上にあるのでバックアップ不要</li>
<li>Ceph はなんとしても守る。バックアップ取るのは難しい</li>
<li>Network ノードは分散・冗長可能, データのバックアップは不要</li>
<li>Compute ノード上のインスタンスデータは Ceph のスナップショットから復旧</li>
</ul>

<p>といったことが考えられます。つまり MySQL のデータさえダンプしておけば
OpenStack 全体が復旧できることになります。実際にやってみましたが可能でした。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/05/19/openstack-ceph/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/05/18/chef-cookbook-adding-users/">Chef Cookbook でユーザ・グループ追加</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-05-18'>
            May 18, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>こんにちは。<a href="https://twitter.com/jedipunkz">@jedipunkz</a> です。
今回は Opscode Chef でユーザ・グループを作成する方法をまとめます。</p>

<p>&lsquo;users&rsquo; Cookbook を使います。</p>

<pre><code>% cd ${YOUR_CHEF_REPO}
% ${EDITOR} Berksfile
cookbook 'users'
% berks install --path ./cookbooks
</code></pre>

<p>data_bag を使ってユーザ・グループの管理をしたいので管理ディレクトリを作成しま
す。</p>

<pre><code>% mkdir -p data_bags/users
</code></pre>

<p>data_bags/users/jedipunkz.json ファイルを作成します。必要に応じて内容を書き換えてください。</p>

<pre><code>{
  &quot;id&quot;: &quot;jedipunkz&quot;,
  &quot;ssh_keys&quot;: &quot;ssh-rsa AAAABx92tstses jedipunkz@somewhere&quot;,
  &quot;groups&quot;: [ &quot;sysadmin&quot;, &quot;sudo&quot; ],
  &quot;uid&quot;: 2001,
  &quot;shell&quot;: &quot;\/usr\/bin\/zsh&quot;,
  &quot;comment&quot;: &quot;jedipunkz sysadmin&quot;,
  &quot;password&quot;: &quot;$1$s%H8BMHlB$7s3h30y9IB1SklftZXYhvssJ&quot;

}
</code></pre>

<p>json ファイルの説明です。</p>

<ul>
<li>id : ユーザ名</li>
<li>ssh_keys : SSH 公開鍵</li>
<li>groups : 所属させるグループ</li>
<li>uid : unix id</li>
<li>sheell : ログインシェル</li>
<li>comment : コメント</li>
<li>passwd : ハッシュ化したパスワード</li>
</ul>

<p>特にハッシュ化したパスワードは下記のコマンドで生成出来ます。</p>

<pre><code>% openssl passwd -1 'yourPassword'
</code></pre>

<p>data_bag を作成し json ファイルを読み込みます。</p>

<pre><code>% knife data bag create users
% knife data bag from file users data_bags/users/jedipunkz.json
</code></pre>

<p>現在 (2013/05/18 現在) 、&rsquo;users&rsquo; Cookbook に不具合があるらしく groups に記した
グループにユーザが所属してくれませんでした。なので下記の対処をします。
sysadmins.rb を今回は利用します。このファイルに下記の行を追記します。僕は sudo
グループに所属させたかったので (先ほど groups: に記した) こうしましたが、他の
グループが良ければ変更してください。また、Ubuntu Server を扱うことがメインの僕
なので group_id は 27 にしています。適宜変更してください。</p>

<pre><code>% ${EDITOR} cookbooks/users/recipes/sysadmins.rb
# 下記の行を追記
users_manage &quot;sudo&quot; do
  group_id 27
end
</code></pre>

<p>cookbook を Chef サーバにアップロードします。</p>

<pre><code>% knife cookbook upload users
</code></pre>

<p>適用したいノードの run_list に Recipe &lsquo;users::sysadmins&rsquo; を追加します。</p>

<pre><code>% knife node run_list add ${YOUR_NODE_NAME} users::sysadmins
</code></pre>

<p>chef-client の次回実行時にユーザ &lsquo;jedipunkz&rsquo; が作成されているはずです。SSH で
ログインして確認してみてください。待ちきれなかったら knife ssh して
chef-client を実行してください。</p>

<p>この &lsquo;users&rsquo; cookbook は他の Cookbook からも呼び出して利用することが出来るので
応用が利きますね。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/05/18/chef-cookbook-adding-users/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/05/11/ceph-deploy/">Ceph-Deploy で Ceph 分散ストレージ構築</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-05-11'>
            May 11, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>今回は ceph-deploy というツールを使って Ceph ストレージを簡単に構築することが
出来るので紹介します。Ceph は分散ストレージでオブジェクトストレージとしてもブ
ロックストレージとしても動作します。今回の構築ではブロックストレージとしてのみ
の動作です。</p>

<p>Ceph が公開しているのが ceph-deploy なわけですが、マニュアル操作に代わる構築方
法として公開しているようです。その他にも Chef Cookbook も公開されているようで
す。</p>

<p>それでは早速。</p>

<h2 id="今回の構成">今回の構成</h2>

<pre><code>+--------+ +--------+ +--------+
| ceph01 | | ceph02 | | ceph03 |
|  osd   | |  osd   | |  osd   |
|  mon   | |  mon   | |  mon   |
|  mds   | |  mds   | |  mds   |
+--------+ +--------+ +--------+
| 10.0.0.1 | 10.0.0.2 | 10.0.0.3
|          |          |          
+----------+----------+
|
| 10.0.0.10
+-------------+
| workstation |
+-------------+
</code></pre>

<p>特徴は</p>

<ul>
<li>すべてのホストで osd, mon, mds を動作</li>
<li>ceph データ格納用ディスクデバイスを /dev/sdb として利用</li>
<li>workstation は ceph-deploy を実行するホスト</li>
</ul>

<p>です。osd は object store daemon で実際にファイルを格納していくデーモン。mon
はモニタリング用デーモン, mds は metadata server で POSIX 互換のファイルシステ
ムをクライアントに提供するためのデーモンです。</p>

<h2 id="ceph-deploy-を使うまでの準備">ceph-deploy を使うまでの準備</h2>

<p>ceph-deploy を使うまでのターゲットのホスト ceph01-03 と workstation と共に準備
が必要です。</p>

<h4 id="ceph01-03-の準備">ceph01-03 の準備</h4>

<p>&lsquo;ceph&rsquo; ユーザの作成を行う。</p>

<pre><code>% ssh user@ceph-server
% sudo useradd -d /home/ceph -m ceph
% sudo passwd ceph
</code></pre>

<p>sudoers の設定を行う。</p>

<pre><code>% echo &quot;ceph ALL = (root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/ceph
% sudo chmod 0440 /etc/sudoers.d/ceph
</code></pre>

<h4 id="workstation-の準備">workstation の準備</h4>

<p>ノンパスフレーズの SSH 公開鍵・秘密鍵を生成する。</p>

<pre><code>workstation% ssh-keygen
Generating public/private key pair.
Enter file in which to save the key (/ceph-client/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /ceph-client/.ssh/id_rsa.
Your public key has been saved in /ceph-client/.ssh/id_rsa.pub.
</code></pre>

<p>公開鍵をターゲットホスト (ceph01-03) に配置</p>

<pre><code>workstation% ssh-copy-id ceph@ceph01
workstation% ssh-copy-id ceph@ceph02
workstation% ssh-copy-id ceph@ceph03
</code></pre>

<p>ceph-deploy の取得を行う。</p>

<pre><code>workstation% git clone https://github.com/ceph/ceph-deploy.git ~/ceph-deploy
</code></pre>

<p>&lsquo;python-virtualenv&rsquo; パッケージをインストールする。</p>

<pre><code>workstation% sudo apt-get update ; sudo apt-get -y install python-virtualenv
</code></pre>

<p>ceph-deploy をブートストラップする</p>

<pre><code>workstation% cd ~/ceph-deploy
workstation% ./bootstrap
</code></pre>

<p>PATH を通す。自分の shell に合わせて登録してください。</p>

<pre><code>workstation% ${EDITOR} ~/.zshrc
export PATH=$HOME/ceph-deploy:$PATH
</code></pre>

<p>ホスト名の解決を行う。</p>

<pre><code>workstation% sudo ${EDITOR} /etc/hosts
10.0.0.1    ceph01
10.0.0.2    ceph02
10.0.0.3    ceph03
</code></pre>

<p>これで準備は終わり。</p>

<h2 id="3台構成構築">3台構成構築</h2>

<p>3台 (ceph01-03) を新規に構築する方法を書きます。すべて workstaiton 上からの操
作です。</p>

<p>ceph サーバ・クライアント間通信のための鍵の生成とコンフィギュレーションの生成
を下記の操作で行う。</p>

<pre><code>workstation% ceph-deploy new ceph01 ceph02 ceph03
</code></pre>

<p>下記の操作で ceph パッケージのインストールを各 Ceph サーバにて行う。&ndash;testing
等と引数を渡せば RC 版の利用が行える。何も渡さなければ stable 版。</p>

<pre><code>workstation% ceph-deploy install ceph01 ceph02 ceph03
</code></pre>

<p>MON daemon のデプロイを行う。</p>

<pre><code>workstation% ceph-deploy mon create ceph01 ceph02 ceph03
</code></pre>

<p>鍵のデプロイを行う。Ceph サーバ間・クライアント間での共有鍵である。1 Cluster
に対して1つの鍵を保有する。</p>

<pre><code>workstation% ceph-deploy gatherkeys create ceph01 ceph02 ceph03
</code></pre>

<p>OSD daemon のデプロイを行う。下記の様にパーティションを指定しなければツールが
自動でパーティショニングを行なってくれる。</p>

<pre><code>workstation% ceph-deploy osd create create ceph01:/dev/sdb ceph02:/dev/sdb ceph03:/dev/sdb
</code></pre>

<p>MDS deamon のデプロイを行う。</p>

<pre><code>cephcleint% ceph-deploy mds create ceph01 ceph02 ceph03
</code></pre>

<p>これで終わりです。これらの操作が終わるとすべてのホスト ceph01-03 で mon, osd,
mds の各デーモンが起動していることが分かると思います。超カンタン！</p>

<h2 id="マウントしてみよう">マウントしてみよう！</h2>

<p>さぁ～、クライアントからマウントしてみましょう。ここでは workstaion ホストを利
用します。Linux 系のマシンで同じネットワークセグメントに属していれば大抵マウン
ト出来ると思います。mds が稼働しているホストに対してであればどこにでもマウント
出来ます。</p>

<h4 id="block-device-としてマウントする方法">Block Device としてマウントする方法</h4>

<p>ストレージ上に block device を生成しそれをマウントする。</p>

<pre><code>workstation% rbd create foo --size 4096
workstation% sudo modprobe rbd
workstation% sudo rbd map foo --pool rbd --name client.admin
workstation% sudo mkfs.ext4 -m0 /dev/rbd/rbd/foo
workstation% sudo mkdir /mnt/myrbd
workstation% sudo mount /dev/rbd/rbd/foo /mnt/myrbd
</code></pre>

<h4 id="kernel-driver-を用いてマウントする方法">Kernel Driver を用いてマウントする方法</h4>

<p>kernel Driver を用いてストレージをマウントする。</p>

<pre><code>workstation% sudo mkdir /mnt/mycephfs
workstation% sudo mount -t ceph 10.0.0.1:6789:/ /mnt/mycephfs -o \
            name=admin,secret=`sudo ceph-authtool -p /etc/ceph/ceph.keyring`
</code></pre>

<h4 id="fuse-driver-ユーザランド-を用いてマウントする方法">Fuse Driver (ユーザランド) を用いてマウントする方法</h4>

<p>ユーザランドソフトウェア FUSE を用いてマウントする。</p>

<pre><code>workstation% sudo mkdir /home/&lt;username&gt;/cephfs
workstation% sudo ceph-fuse -m 10.0.0.1:6789 /home/&lt;username&gt;/cephfs
</code></pre>

<h2 id="まとめ">まとめ</h2>

<p>もし導入するのであればマニュアルでの構築も一度体験した方が良いかもしれません。
ツールを使うと一体どんな作業がされているのか理解出来ないので。ただ今ではマニュ
アル操作で構築している途中に &lsquo;ceph-deploy を使ってください&rsquo; と warning が出る
ので、開発元としてもこちらの構築方法を薦めたいのでしょう。あと Ceph はドキュメ
ントが非常に充実しています。ドキュメントの全てに大事なことが書いてあるので一度
読むことをオススメします。また Ceph が Chef Cookbook も公開しているようで、そ
ちらの方法もドキュメントにチラっと書いてありました。私はまだ試していませんが時
間があればやってみたいです。あとあと！ceph-deploy はまだ未完成な域を脱していま
せん。上記の通り新規構築系の操作はひと通り出来るのですが、ホストの削除系の実装
がまだされていませんでした。ホスト追加系の操作に関しても削除系程ではないのです
が完成度が上がっていません。手作業で少しカバーしてあげる必要があります。</p>

<p>OpenStack の Cinder の先のストレージについて最近考えていました。LVM 管理のロー
カルディスクでもいいのですが運用のことを考えるとバックアップを取らなくちゃい
けないのだけど logcal volume が存在しないのでスナップショットバックアップが出
来なそう。Cinder は比較的高価なストレージも扱えるのでそちらの機能でバックアッ
プ取るのもいいけど、ここはオープンソースでなんとかしたい！と思って Ceph を検討
してみました。</p>

<p>Ceph は分散ストレージでオブジェクトストレージとしてもブロックストレージとして
も動作が可能。OpenStack と組み合わせると Cinder の先のストレージとしても
Glance のイメージ置き場としても利用可能らしい。Cinder の接続先ストレージとして
の動作方法はまた別の機会にブログに書きます。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/05/11/ceph-deploy/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/26/quantum-network-distributing/">Quantum Network ノードの分散・冗長</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-26'>
            April 26, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>こんにちは。Grizzly がリリースされてから暫く経ちました。今回は Folsom リリース
まであった Quantum ノードのボトルネックと単一障害点を解決する新しい機能につい
て評価した結果をお伝えします。</p>

<p>Folsom までは</p>

<ul>
<li>Quantum L3-agent が落ちると、その OpenStack 一式の上にある仮想マシン全ての通
信が途絶える</li>
<li>Quantum L3-agent に仮想マシンの全てのトラフィックが集まりボトルネックとなる。</li>
</ul>

<p>という問題がありました。Folsom リリース時代にもし僕が職場で OpenStack を導入す
るのであればこれらを理由に nova-network を選択していたかもしれません。
nova-network は compute ノードが落ちればその上の仮想マシンも同時に落ちるが、他
の compute ノード上の仮想マシンの通信には影響を与えないからです。もちろん仮想
ルータ・仮想ネットワークの生成等を API でユーザに提供したいなどの要望があれば
Quantum を選択するしかありませんが。これに対して Grizzly リリースの Quantum は
改善に向けて大きな機能を提供してくれています。L3-agent, DHCP-agent の分散・冗
長機能です。</p>

<p>下記の構成が想定出来ます。ここでは Network ノードを2台用意しました。それ以上の
台数に増やすことも出来ます。</p>

<pre><code>+-------------+-------------+-------------------------- Public/API Network
|             |             |
+-----------+ +-----------+ +-----------+ +-----------+
|           | |           | |           | |vm|vm|..   |
| controller| |  network  | |  network  | +-----------+
|           | |           | |           | |  compute  |
+-----------+ +-----------+ +-----------+ +-----------+
|             |     |       |     |       |     |
+-------------+-----)-------+-----)-------+-----)------ Management/API Network
                    |             |             |
                    +-------------+-------------+------ Data Network
</code></pre>

<p>L3-agent の分散は仮想ルータ単位で行います。それに対し DHCP-agent は仮想
ネットワーク単位で行います。</p>

<h2 id="agent-一覧の取得">agent 一覧の取得</h2>

<p>上記の構成を構築すると下記のように agent 一覧が取得出来ます。</p>

<pre><code>% quantum agent-list # 'admin' ユーザでアクセス
+--------------------------------------+--------------------+-----------------------+-------+----------------+
| id                                   | agent_type         | host                  | alive | admin_state_up |
+--------------------------------------+--------------------+-----------------------+-------+----------------+
| 44795822-2d9f-434e-ba98-748f7411442f | DHCP agent         | grizzly03.example.com | :-)   | True           |
| a5150a40-0405-4399-ac1a-be012f55d9f5 | DHCP agent         | grizzly02.example.com | :-)   | True           |
| b7bf4e59-06ac-475c-84ab-413d8d29f293 | Open vSwitch agent | grizzly04.example.com | :-)   | True           |
| cc5a6b94-6ddd-4109-8f2f-1b28c6aaf5e6 | L3 agent           | grizzly03.example.com | :-)   | True           |
| d39803cf-19d3-47d7-8205-cf9a143dd0ea | Open vSwitch agent | grizzly02.example.com | :-)   | True           |
| d8e59803-9aad-4c62-a47a-519bc788e0fb | Open vSwitch agent | grizzly03.example.com | :-)   | True           |
| f6f747cf-ffb0-446c-a455-2947fd3e87e8 | L3 agent           | grizzly02.example.com | :-)   | True           |
+--------------------------------------+--------------------+-----------------------+-------+----------------+
</code></pre>

<p>ホスト名は下記。</p>

<ul>
<li>controller : grizzly01.exmaple.com</li>
<li>network01  : grizzly02.exmaple.com</li>
<li>network02  : grizzly03.exmaple.com</li>
<li>compute    : grizzly04.exmaple.com</li>
</ul>

<h2 id="l3-agent-の分散方法-ノード移動">L3-agent の分散方法 (ノード移動)</h2>

<p>仮想ルータ (ここでは &lsquo;router-test01&rsquo; とする) がどの L3-agent に属しているか確
認を取る。</p>

<pre><code>% quantum l3-agent-list-hosting-router router-demo
+--------------------------------------+-----------------------+----------------+-------+
| id                                   | host                  | admin_state_up | alive |
+--------------------------------------+-----------------------+----------------+-------+
| f6f747cf-ffb0-446c-a455-2947fd3e87e8 | grizzly02.example.com | True           | :-)   |
+--------------------------------------+-----------------------+----------------+-------+
</code></pre>

<p>1台目の Network ノード (grizzly02.example.com) 上の L3-agent に属していること
が確認取れた。次にこの親子関係を削除する。</p>

<pre><code>% quantum l3-agent-router-remove f6f747cf-ffb0-446c-a455-2947fd3e87e8 router-test01
Removed Router router-demo to L3 agent
</code></pre>

<p>最後に仮想ルータ &lsquo;router-test01&rsquo; を2台目の Network ノード上の L3-agent の管理
下に設定する。</p>

<pre><code>% quantum l3-agent-router-add cc5a6b94-6ddd-4109-8f2f-1b28c6aaf5e6 router-demo
Added router router-demo to L3 agent
% quantum l3-agent-list-hosting-router router-demo
+--------------------------------------+-----------------------+----------------+-------+
| id                                   | host                  | admin_state_up | alive |
+--------------------------------------+-----------------------+----------------+-------+
| cc5a6b94-6ddd-4109-8f2f-1b28c6aaf5e6 | grizzly0404.cpi.ad.jp | True           | xxx   |
+--------------------------------------+-----------------------+----------------+-------+
</code></pre>

<h2 id="dhcp-agent-の分散方法-ノード移動">DHCP-Agent の分散方法 (ノード移動)</h2>

<p>仮想マシンが所属しているネットワーク (ここでは &lsquo;int_net&rsquo;) がどの DHCP-agent に所属しているか確認する。</p>

<pre><code>% quantum dhcp-agent-list-hosting-net int_net
+--------------------------------------+-----------------------+----------------+-------+
| id                                   | host                  | admin_state_up | alive |
+--------------------------------------+-----------------------+----------------+-------+
| a5150a40-0405-4399-ac1a-be012f55d9f5 | grizzly02.example.com | True           | :-)   |
+--------------------------------------+-----------------------+----------------+-------+
</code></pre>

<p>1台目のノードに所属しているのが確認できる。次に &lsquo;int_net&rsquo; が所属する DHCP-agent を削除行う。</p>

<pre><code>% quantum dhcp-agent-network-remove a5150a40-0405-4399-ac1a-be012f55d9f5 int_net
Removed network int_net to DHCP agent
</code></pre>

<p>2台目のノードの DHCP-agent を仮想ネットワーク &lsquo;int_net&rsquo; に紐付ける。</p>

<pre><code>% quantum dhcp-agent-network-add 44795822-2d9f-434e-ba98-748f7411442f int_net
Added network int_net to DHCP agent
% quantum dhcp-agent-list-hosting-net int_net
+--------------------------------------+-----------------------+----------------+-------+
| id                                   | host                  | admin_state_up | alive |
+--------------------------------------+-----------------------+----------------+-------+
| 44795822-2d9f-434e-ba98-748f7411442f | grizzly0404.cpi.ad.jp | True           | :-)   |
+--------------------------------------+-----------------------+----------------+-------+
</code></pre>

<h2 id="まとめ">まとめ</h2>

<p>この様に仮想ルータ, 仮想ネットワーク単位で Network ノードの agent の分散が行え
る。上記のように仮想ルータ・ネットワークが1つずつでは分散という意味では無いが
運用の過程で仮想ルータ・ネットワークは増えることが想定出来るのでその際にはトラ
フィック・DHCP 機能を分散することが可能になる、と言える。また片系の Network ノー
ドに寄せておいてからの障害テスト -&gt; もう片系への移動も行なってみたが作業ととも
に仮想マシンの通信が復旧した。このテストを行う前まで &lsquo;agent の移動だけ行えるの
であって仮想ルータ自体が移動するわけではないので冗長という意味はない&rsquo; と考えて
いたのだが、実際には上記の操作で namespace が移動していることが判り (Quantum
の仮想ルータの実体は Linux Namespace) 障害テストの結果、うまくいった。
OpenStack を導入するという意味で、この機能は非常に大きな前進だと僕は思っていま
す。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/26/quantum-network-distributing/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/21/chef-for-openstack-grizzly-roadmap/">Chef for OpenStack</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-21'>
            April 21, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>以前にも話題にしたことがある Chef For OpenStack ですが今週新しい情報が入って来
ました。#ChefConf 2013 というイベントがあったのですがここで Opscode の Matt
Ray さんらが集まり OpenStack を Chef で構築する &lsquo;Chef for OpenStack&rsquo; について
語られた模様です。その時の資料が SlideShare に上がっていたので見てみました。</p>

<p><iframe src="http://www.slideshare.net/slideshow/embed_code/19197748"
width="427" height="356" frameborder="0" marginwidth="0" marginheight="0"
scrolling="no" style="border:1px solid #CCC;border-width:1px 1px
0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen>
</iframe> <div style="margin-bottom:5px"> <strong> <a
href="http://www.slideshare.net/mattray/chef-for-openstack-grizzly-roadmap"
title="Chef for OpenStack: Grizzly Roadmap" target="_blank">Chef for
OpenStack: Grizzly Roadmap</a> </strong> from <strong><a
href="http://www.slideshare.net/mattray" target="_blank">Matt Ray</a></strong>
</div></p>

<p>気にあった点を幾つか挙げていきます。</p>

<ul>
<li><a href="https://github.com/osops">https://github.com/osops</a> で管理される</li>
<li>各コンポーネントの cookbook の名前には &lsquo;-cookbook&rsquo; を最後に付ける</li>
<li>quantum, cinder, ceilometer, heat 等、比較的新しいコンポーネントも加わる</li>
<li>gerrit でコードレビューされ CI も提供される</li>
<li>Chef11 が用いられる</li>
<li>Ruby 1.9.x に対応した chef-client が用いられる</li>
<li>Foodcritic で可能な限りテストされる</li>
<li>chef-solo はサポートされない</li>
<li>5月に &lsquo;2013.1.0&rsquo; がリリースされる (openstack 2013.1 対応と思われる)</li>
<li>chef-repo の形で提供される</li>
<li>Ubuntu 12.04 が前提</li>
<li>HyperVisor は KVM, LXC がサポートされる</li>
</ul>

<p>以上です。恐らく chef-repo で提供されるということは spiceweasel を使った構成構
築が出来るような形になるでしょう。楽しみです。またコントリビュートする方法も掲
載されているので興味が有る方は協力してみるのも楽しいかもしれません。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/21/chef-for-openstack-grizzly-roadmap/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/21/openstack-non-virtio/">OpenStack Grizzy で非 Virtio OS 稼働</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-21'>
            April 21, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>こんにちは jedipunkz です。</p>

<p>Virtio に対応していない OS を OpenStack で稼働させることが今まで出来なかったの
ですが Grizzly から非 Virtio な OS イメージが扱えるようになった。今まで NetBSD
やら古い FreeBSD やら virtio ドライバを OS イメージに入れることに苦労していたの
だけど、これで問題無くなった。</p>

<p>最初、この機能のこと調べるのに「どうせ libvirt が生成する xml を書き換えるのだ
から nova 周りの設定なんだろうー」と思っていたら全く方法が見つからず&hellip;。結局
OS イメージを格納している Glance の設定にありました。</p>

<p>ここでは FreeBSD7.4 Release を例に挙げて説明していきます。</p>

<h2 id="前提とする環境">前提とする環境</h2>

<ul>
<li>OpenStack Grizzly が稼働していること</li>
<li>ホスト OS に Ubuntu 12.04.2 LTS が稼働していること</li>
<li>ゲスト OS に FreeBSD 7.4 Release を用いる</li>
</ul>

<p>とします。OS のバージョンはホスト・ゲスト共に、上記以外でも構いません。Grizzly
さえ動いていれば OK です。</p>

<h2 id="os-イメージ作成">OS イメージ作成</h2>

<p>KVM で OS イメージを作成します。もちろん virtio なインターフェースは指定せず</p>

<ul>
<li>IDE ディスクインターフェース</li>
<li>e1000 (intel) ネットワークインターフェース</li>
</ul>

<p>を指定してあげてください。</p>

<pre><code>% kvm-img create -f qcow2 &lt;IMAGE_NAME&gt; 5G
% sudo kvm -m 1024 --cdrom FreeBSD-7.4-RELEASE-amd64-disc1.iso --drive \
  file=./&lt;IMAGE_NAME&gt; -boot d -net nic,model=e1000 -net user -nographic \
  -vnc :9
</code></pre>

<p>VNC クライアントソフトを用いてホスト :9 番に接続し OS をインストールする。</p>

<h2 id="glance-への登録">Glance への登録</h2>

<p>OpenStack API に接続する環境変数等を合わせ下記のコマンドを実行します。</p>

<pre><code>% glance image-create --name=&quot;FreeBSD7.4&quot; --is-public \
  true --container-format bare --disk-format qcow2 &lt; &lt;IMAGE_NAME&gt;
% glance image-update --property hw_vif_model=e1000 &quot;FreeBSD7.4&quot;
% glance image-update --property hw_disk_bus=ide &quot;FreeBSD7.4&quot;
</code></pre>

<p>&ndash;property オプションでディスク・ネットワークインターフェースの指定を変更して
います。</p>

<h2 id="vm-の稼働">VM の稼働</h2>

<p>あとは普段通り nova boot コマンドで VM を稼働させるだけです。</p>

<pre><code>% nova boot --nic net-id=&lt;network_id&gt; --image &lt;image_id&gt; --flavor &lt;flavor_number&gt; &lt;vm_name&gt;
</code></pre>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/21/openstack-non-virtio/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/20/openstack-grizzly-installation-script/">OpenStack Grizzly 構築スクリプト</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-20'>
            April 20, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>OpenStack Grizzly がリリースされて2週間ほど経過しました。皆さん動かしてみまし
たか？今回、毎度の構築 Bash スクリプトを開発したので公開します。</p>

<p>下記のサイトで公開しています。</p>

<p><a href="https://github.com/jedipunkz/openstack_grizzly_install">https://github.com/jedipunkz/openstack_grizzly_install</a></p>

<p>このスクリプト、複数台構成とオールインワン構成の両方が構成出来るようなっていま
すが、今回は簡単なオールインワン構成の組み方をを簡単に説明したいと思います。</p>

<h2 id="前提の環境">前提の環境</h2>

<ul>
<li>Ubuntu 12.04 LTS が稼働している</li>
<li>Cinder のためのディスクを OS 領域と別に用意 (/dev/sdb1 など)</li>
<li>オールインワン構成の場合は 2 NICs 準備</li>
</ul>

<p>Ubuntu 13.04 の daily build も完成度上がっている時期ですが OVS 側の対応が
OpenStack 構成に問題を生じさせるため 12.04 LTS + Ubuntu Cloud Archive の組み合
わせで構築するのが主流になっているようです。また、Cinder 用のディスクは OS 領
域を保持しているディスクとは別 (もしくはパーティションを切ってディスクデバイス
を別けても可) が必要です。オールインワン構成の場合は NIC を2つ用意する必要があ
ります。通常 OpenStack を複数台構成する場合は</p>

<ul>
<li>コントローラノード x 1 台</li>
<li>ネットワークノード x 1 台</li>
<li>コンピュートノード x n 台</li>
</ul>

<p>で組み、VM はコンピュートノードからネットワークノードを介してインターネットに
接続します。よってそのため更に NIC が必要になるのですが、オールインワン構成の
場合は</p>

<ul>
<li>マネージメントネットワーク, API ネットワーク(内部通信用)</li>
<li>パブリックネットワーク (VM のためのブリッジインターフェース)</li>
</ul>

<p>の計2つを用意してください。</p>

<h2 id="実行前の準備">実行前の準備</h2>

<h4 id="os-のインストール">OS のインストール</h4>

<p>OS のインストール方法は割愛しますが</p>

<ul>
<li>&lsquo;openssh-server&rsquo; のみをインストール</li>
<li>ディスクが1つしかない場合は cinder 用のパーティションを用意</li>
</ul>

<p>の条件が満たされていれば OK です。</p>

<h4 id="cinder-用のディスクデバイスパーティショニング">Cinder 用のディスクデバイスパーティショニング</h4>

<p>Cinder 用に信頼性のあるディスクを用意している場合は fdisk 等を用いてパーティショ
ニングしてください。近々 loopback デバイスでも構築できるようスクリプトの改修を
する予定です。ディスクが一つしかない場合は先程述べたとおり、OS インストール時
にパーティショニングしたディスクデバイスを使います。</p>

<pre><code>% sudo fdisk /dev/sdb
</code></pre>

<h2 id="ネットワークインターフェースの設定">ネットワークインターフェースの設定</h2>

<p>下記のように2つのネットワークインターフェースを設定してください。</p>

<pre><code>% sudo ${EDITOR} /etc/network/interfaces
auto lo
iface lo inet loopback

# this NIC will be used for VM traffic to the internet
auto eth0
iface eth0 inet static
    up ifconfig $IFACE 0.0.0.0 up
    up ip link set $IFACE promisc on
    down ip link set $IFACE promisc off
    down ifconfig $IFACE down
    address 10.200.9.10
    netmask 255.255.255.0
    dns-nameservers &lt;DNS_RESOLVER1&gt; &lt;DNS_RESOLVER&gt;
    dns-search example.com

# this NIC must be on management network
auto eth1
iface eth1 inet static
    address 10.200.10.10
    netmask 255.255.255.0
    gateway 10.200.10.1
    dns-nameservers &lt;DNS_RESOLVER1&gt; &lt;DNS_RESOLVER&gt;
</code></pre>

<p>eth0 が VM のためのブリッジインターフェースになります。eth1 はマネージメントネッ
トワーク用・内部 API 通信用の兼務です。</p>

<h2 id="スクリプトの取得とパラメータ設定">スクリプトの取得とパラメータ設定</h2>

<p>スクリプトの取得を行います。</p>

<pre><code>% git clone git://github.com/jedipunkz/openstack_grizlly_install.git
% cd openstack_grizzly_install
</code></pre>

<p>パラメータを設定するため setup.conf 内の各パラメータを設定変更します。数多くの
パラメータがありますが、最低限のパラメータということで&hellip;</p>

<pre><code>HOST_IP='10.200.10.10'
HOST_PUB_IP='10.200.9.10'
PUBLIC_NIC='eth0'
</code></pre>

<p>を設定してください。HOST_IP は eth1 の IP アドレス、HOST_PUB_IP は eth0 の IP
アドレス、PUBLIC_NIC は eth0 (HOST_PUB_IP のインターフェース名) を指定します。</p>

<h2 id="スクリプトの実行">スクリプトの実行</h2>

<p>いよいよスクリプトを実行します。</p>

<pre><code>% sudo ./setup.sh allinone
</code></pre>

<p>しばらくすると構築が完了します。あとは</p>

<pre><code>http://${HOST_IP}/horizon/
</code></pre>

<p>にブラウザでアクセスすると WEB I/F である Horizon のログイン画面が表示されます。
パラメータをいじっていなければユーザ : demo, パスワード : demo でアクセス出来
ます。</p>

<h2 id="各-api-にコマンドでアクセスする">各 API にコマンドでアクセスする</h2>

<p>API にアクセスするためにコマンドを用いることも出来ます。スクリプトを実行した結
果、下記のファイルが生成されているはずです。</p>

<pre><code>~/openstackrc-demo # 'demo' ユーザで API にアクセス
~/openstackrc      # 'admin' ユーザで API にアクセス
</code></pre>

<p>&lsquo;demo&rsquo; ユーザでアクセスするためには</p>

<pre><code>% source ~/openstackrc-demo
</code></pre>

<p>を実行してください。環境変数が設定され API にアクセス出来るようになります。例
として下記のコマンドを実行してみてください。</p>

<pre><code>% glnace image-list
+--------------------------------------+---------------------+-------------+------------------+------------+--------+
| ID                                   | Name                | Disk Format | Container Format | Size       | Status |
+--------------------------------------+---------------------+-------------+------------------+------------+--------+
| 1a7943a5-8f8f-4c02-9763-5a6d519c31bb | Cirros 0.3.0 x86_64 | qcow2       | bare             | 9761280    | active |
+--------------------------------------+---------------------+-------------+------------------+------------+--------+
</code></pre>

<p>OS イメージ一覧が取得出来ます。スクリプトで予め Glance に登録した Cirros とい
う小さな OS イメージが確認出来るはずです。</p>

<h2 id="まとめ">まとめ</h2>

<p>本格的な構成を組むのであれば上記の URL にも知る指定ある複数台構成を組んでみて
ください。同じくスクリプトで構築出来ます。また今回から Quantum に実装された
LBaaS も組めるようになっています。構築出来た OpenStack で LB を組んでみてくだ
さい。LBaaS の説明については OpenStack ユーザ会の中島さんのブログが参考になり
ます。</p>

<p><a href="http://aikotobaha.blogspot.jp/2013/04/use-full-function-of-openstack-grizzly.html">http://aikotobaha.blogspot.jp/2013/04/use-full-function-of-openstack-grizzly.html</a></p>

<p>LBaaS で組める負荷分散方式が &lsquo;ROUND_ROBIN&rsquo; 以外にも選択出来るぽいのでもう少し
調べたら、僕のブログでも紹介しようかと思います。また Grizzly になって数多くの
機能が新たに実装されているので引き続き紹介していこうかと思います。</p>

<p>OpenStack は多くの機能がありますし構成の仕方も様々。予め理解しなければいけない
技術も多岐にわたるのでブログだけではなかなか説明し切れないところです。
OpenStack のコミュニティが書いた &lsquo;OpenStack Operations Guide&rsquo; なるドキュメント
が最近リリースされました。</p>

<p><a href="http://docs.openstack.org/ops/">http://docs.openstack.org/ops/</a></p>

<p>日本のユーザ会でもこのドキュメントを翻訳しようという活動がされている最中です。
興味があるかたは一度読むことをオススメしますし、もし更に興味が有る方は翻訳活動
に協力するのはいかがでしょうか。ユーザ会の ML で現在話が進んでいます。</p>

<p>引き続き、OpenStack ネタはアップしていきますー。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/20/openstack-grizzly-installation-script/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/06/chef-11-private-network/">Chef 11 サーバのローカルネットワーク上構築</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-06'>
            April 6, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>chef-solo を使うの？Chef サーバを使うの？という議論は結構前からあるし、答えは
「それぞれの環境次第」だと思うのだが、僕は個人的に Chef サーバを使ってます。ホ
ステッド Chef を使いたいけどお金ないし。会社で導入する時はホステッド Chef を契
約してもらうことを企んでます。(・∀・) 何故なら cookbooks を開発することがエン
ジニアの仕事の本質であって Chef サーバを運用管理することは本質ではないから。そ
れこそクラウド使えという話だと思う。</p>

<p>でも！Chef に慣れるには無料で使いたいし、継続的に Cookbooks をターゲットノード
で実行したい。ということで Chef サーバを構築して使っています。</p>

<p>Chef 10 の時代は Chef サーバの構築方法は下記の通り3つありました。</p>

<ul>
<li>手作業！</li>
<li>Bootstrap 構築</li>
<li>Opscode レポジトリの Debian, Ubuntu, CentOS パッケージ構築</li>
</ul>

<p>それが Chef 11 では</p>

<ul>
<li>Ubuntu, RHEL のパッケージ (パッケージインストールですべて環境が揃う)</li>
</ul>

<p><a href="http://www.opscode.com/chef/install/">http://www.opscode.com/chef/install/</a></p>

<p>この方法1つだけ。でも簡単になりました。</p>

<p>&lsquo;Chef Server&rsquo; タブを選択するとダウンロード出来る。じっくりは deb ファイルの中
身を見たことがないけど、チラ見した時に chef を deb の中で実行しているように見
えた。徹底してるｗ</p>

<p>Chef 10 時代のパッケージと違って行う操作は下記の2つのコマンドだけ。</p>

<pre><code>% sudo dpkg -i chef-server_11.0.6-1.ubuntu.12.04_amd64.deb # ダウンロードしたもの
% sudo chef-server-ctl reconfigure
</code></pre>

<p>簡単。でも&hellip; この状態だと https://&lt;サーバの FQDN&gt; でサーバが Listen している。
IP アドレスでアクセスしてもリダイレクトされる。つまり、ローカルネットワーク上
に構築することが出来ない。安易に hosts で解決も出来ない。何故ならターゲットノー
ドは通常まっさらな状態なので bootstrap するたびに hosts を書くなんてアホらしい
しやってはいけない。</p>

<p>今日の本題。ローカルネットワーク上に Chef 11 サーバを構築する方法を調べました。</p>

<h2 id="修正箇所">修正箇所</h2>

<ul>
<li>/var/opt/chef-server/chef-pedant/etc/pedant_config.rb</li>
</ul>

<p>URL を IP アドレスに変更する。</p>

<pre><code>chef_server &quot;https://chef.example.com&quot;
</code></pre>

<ul>
<li>/var/opt/chef-server/erchef/etc/app.config</li>
</ul>

<p>URL を IP アドレスに変更する。</p>

<pre><code>{s3_url, &quot;https://chef.example.com&quot;},
</code></pre>

<ul>
<li>/var/opt/chef-server/nginx/etc/nginx.conf</li>
</ul>

<p>URL を IP アドレスに変更する。2箇所あるので注意。鍵ファイルにも FQDN が記され
ているがそれらは変更しない。</p>

<pre><code>server_name chef.example.com;
</code></pre>

<ul>
<li>/etc/chef-server/chef-server-running.json</li>
</ul>

<p>URL を IP アドレスに変更する。鍵ファイルにも FQDN が記されているがそれらは変更
しない。</p>

<pre><code>&quot;vip&quot;: &quot;chef.example.com&quot;,
&quot;api_fqdn&quot;: &quot;chef.example.com&quot;,
&quot;web_ui_fqdn&quot;: &quot;chef.example.com&quot;,
&quot;server_name&quot;: &quot;chef.example.com&quot;,
&quot;url&quot;: &quot;https://chef.example.com&quot;,
</code></pre>

<p>最後に Chef サーバを再起動する。</p>

<pre><code>% sudo chef-server-ctl restart
</code></pre>

<h2 id="まとめ">まとめ</h2>

<p>会社で、この環境を使って色々試しています。今のところ不具合なく動作している。強
引ワザなのでもっと綺麗な方法を知っている方がいましたら教えて下さい。
m ( _ _ ) m</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/06/chef-11-private-network/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/04/06/cloudmanagement/">クラウドマネジメント勉強会レポ</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-04-06'>
            April 6, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>クラウドマネジメント勉強会に参加してきた。今が旬なのか定員140名が埋まっていま
した。クラウドフェデレーションサービス各種の話が聞ける貴重な勉強会の場でした。</p>

<pre><code>場所 : スクエアエニックスさん
日程 : 2013年4月5日 19:00 -
</code></pre>

<p>少し長くなるので、早速。</p>

<h2 id="クラウド運用管理研究会">クラウド運用管理研究会</h2>

<p>クラウド利用推進機構が運営するクラウド運用管理研究会は下記の3つに分別されるそ
うです。今回は一項目の &lsquo;クラウドマネジメントツール研究会&rsquo; にあたるそう。別の研
究会も既に勉強会を実施しているそうです。</p>

<ul>
<li>クラウドマネジメントツール研究会</li>
<li>デザインパターン研究会</li>
<li>運用管理・監視研究会</li>
</ul>

<h1 id="aws-opsworks">AWS OpsWorks</h1>

<pre><code>アマゾンデータサービスジャパン AWS 片山さん, 船崎さん
</code></pre>

<p>OpsWorks は最近話題になった AWS 利用者に無料で提供されるクラウドフェデレーショ
ンサービス。Web UI で操作し簡単デプロイを実現するサービスです。</p>

<h2 id="opsworks-が自動化するモノ">OpsWorks が自動化するモノ</h2>

<ul>
<li>サーバ設定</li>
<li>ミドルウェア構築</li>
</ul>

<h2 id="特徴">特徴</h2>

<ul>
<li>Chef フレームワークを利用 (chef-solo を内部的に利用)</li>
<li>任意の cookbooks を利用可能</li>
<li>LB, AP, DB などをレイヤ化, 任意のレイヤも作成可能</li>
</ul>

<h2 id="opsworks-の流れ">OpsWorks の流れ</h2>

<ul>
<li>Stack 作成</li>
<li>レイヤ作成 (LB, AP, DB, 任意)</li>
<li>レシピの作成</li>
<li>レイヤにインスタンス作成</li>
</ul>

<h2 id="下記をレイヤ化で区別する">下記をレイヤ化で区別する</h2>

<ul>
<li>Package インストール</li>
<li>OS 設定</li>
<li>アプリデプロイ</li>
</ul>

<h2 id="所感">所感</h2>

<p>AWS OpsWorks の登場で他のクラウドフェデレーションサービスがどうなるの？とさえ
思った。AWS はインターネット・ホスティング業界のあらゆるサービスを押さえようと
している感がある。もう隙間がない！ｗ OpsWorks に関してまだ問題は残っているそう
だ。VPC, micro 現在未対応など。が解決に向けて作業しているそう。</p>

<h1 id="aeolus-conductor">Aeolus Conductor</h1>

<pre><code>RedHat 中井さん
</code></pre>

<h2 id="概要">概要</h2>

<p>複数クラウドに対応したイメージ作成・アプリケーション環境構築の自動化ツール</p>

<ul>
<li>アプリのデプロイ機能にフォーカス</li>
<li>Red Hat CoudForms が商用版</li>
<li>マルチクラウド (ユーザにクラウドが割り当てられる, Hybrid, EC2, RHEV)</li>
</ul>

<h2 id="自動化について中井さんの案-手作り">自動化について中井さんの案 (手作り)</h2>

<ul>
<li>libvirt キック</li>
<li>kickstart 実行</li>
<li>post script にて puppet 実行</li>
<li>manifest は github で管理</li>
</ul>

<p>これらは単一のサーバのみで実施できて、複数台構成等を前提に出来ない等の問題があ
る。それらを解決するのが Aeolus Conductor。</p>

<h2 id="aeolus-conductor-の要素">Aeolus Conductor の要素</h2>

<ul>
<li>システムテンプレート用意 (XML) : OS 構成内容が記されている</li>
<li>マシンイメージ JEOS</li>
<li>アプリケーションブループリント (アプリデプロイ設計書)
shell script である。puppet, chef を呼び出しても OK.</li>
<li>Config サーバを介して VM 間の構成を管理している : インテグレート！ DB, Web</li>
</ul>

<h2 id="aeolus-conductor-の不便な点">Aeolus Conductor の不便な点</h2>

<ul>
<li>特定のクラウド特有の機能には未対応</li>
<li>複数 VM デプロイ時のワークフロー処理が不十分</li>
</ul>

<h2 id="所感-1">所感</h2>

<p>画面を見させてもらったが AWS EC2, RHEV (RedHat の仮想化ソフト) とマルチクラウ
ドに対応していた。ユーザにどのクラウドを割り当てるか？等の権限委譲が出来るもの
ユニーク。</p>

<h1 id="scalr">Scalr</h1>

<pre><code>Scalr ユーザ会 梶川さん (IDC フロンティア)
</code></pre>

<h2 id="概要-特徴">概要, 特徴</h2>

<ul>
<li>オープンソースのマルチクラウド管理ツール</li>
<li>利用出来るクラウド : AWS, Eucalyptus, RackSpace, nimbula, OpenStack, &hellip;</li>
<li>冗長化・オートスケール可能</li>
<li>モニタリングも自動で開始</li>
<li>DNS 管理, オートスケール時、自動的に修正が行われる</li>
<li>スクリプト実行 (任意のタイミングで可能、またタイミングを作成可能)</li>
<li>各サービスのコンフィグプリセット管理 (ミドルウェアのパラメータ？)</li>
</ul>

<h2 id="所感-2">所感</h2>

<p>Scalr ユーザ会のメンバ募集中だそうだ。個人的にオープンソースの Scalr を試そう
と思ったことがあるのだが、手順の wiki が解りづらかった。商用サービスを使わせる
ためにわざと解りづらくしているのか？と思うほど。ユーザ拡大のために是非ドキュメ
ントの整備をお願いしたい。</p>

<h1 id="rightscale-の利用効果と苦労話">RightScale の利用効果と苦労話</h1>

<pre><code>So-net エンタテインメント 成田さん
</code></pre>

<h2 id="利用効果">利用効果</h2>

<ul>
<li>1つのスクリプトを複数台に対して実行可能</li>
<li>手作業が自動化へ</li>
<li>ベストプラクティスの利用が可能に</li>
<li>モニタリングの自動化へ</li>
<li>サーバ台数のスケジューリング化</li>
<li>セキュリティグループはマクロで作成</li>
<li>権限分離による開発者・プロデューサに役割移譲</li>
<li>履歴管理の自動記録</li>
<li>chef recipe が right スクリプトとして走らせられる</li>
</ul>

<h2 id="苦労話">苦労話</h2>

<ul>
<li>Alert 設定のミスでメール大量受信</li>
<li>自動化スクリプトのエラー対応</li>
<li>計画メンテナンスの後は要注意 (仕様変更)</li>
<li>RightScale 上の表示を過信しない, 詳しくはクラウドサービス側を確認</li>
<li>LANG=ja_JP.UTF-8 するとコケる</li>
<li>メンテナンスは金曜日日中 (月に一回)</li>
</ul>

<h2 id="所感-3">所感</h2>

<p>実際に運用している方の話はとても貴重。特に苦労ネタはなかなか知ることが出来ない
ので。自動化のためにスクリプトを書くのがインフラ系エンジニアの仕事になると知ら
せてくれた。Right スクリプトには Chef のレシピも走らせることが出来る、というも
が魅力。またインフラ系エンジニア以外の職種の人にも権限委譲し UI を操作してもら
える辺りは、業務の最適化のために大いに利用できると感じた。</p>

<h1 id="chef-の話">Chef の話</h1>

<pre><code>Engine Yard @yando さん
</code></pre>

<h2 id="engine-yard-とは">Engine Yard とは</h2>

<ul>
<li>PaaS</li>
<li>AWS + Chef + サポート, 監視</li>
<li>chef-solo をキック</li>
<li>chef recipe の管理は Engine Yard が行う</li>
</ul>

<h2 id="chef-へのモチベーション">Chef へのモチベーション</h2>

<ul>
<li>冪等性</li>
<li>シェルスクリプトだと構築直後の状態しか保証されない</li>
</ul>

<h2 id="chef-solo-の話">chef-solo の話</h2>

<ul>
<li>knife-solo でノードに SSH せずに実行</li>
</ul>

<h2 id="利用するにあたって直面する課題">利用するにあたって直面する課題</h2>

<ul>
<li>レシピの実装 -&gt; github 上のレシピを参照・利用</li>
<li>Vagrant の利用でレシピの複数プラットフォーム上でのテスト</li>
<li>レシピの配布方法 -&gt; github, berkshelf, knife solo, nfs, chef-server</li>
<li>レシピの反映 -&gt; capistrano, chef-client, cron</li>
</ul>

<h2 id="engine-yard-local">Engine Yard Local</h2>

<ul>
<li>クラウドと同じレシピでローカルに開発環境を構築出来るツール</li>
<li>クラウドはコストが掛かるし遅いので出来る事ならローカルで、という発想</li>
</ul>

<h2 id="所感-4">所感</h2>

<p>Chef 流行ってますね。うんうん、(・∀・)ｲｲ!! 個人的には Chef の Cookbooks 開発
はインフラエンジニアにしてもらいたい。Engine Yard のような PaaS 使うならアレだ
けどクラウド使うなら運用は引き続き必要だし、運用を意識した Cookbooks 開発は絶
対に必要になってくるからだ。Chef の関連技術がものすごいスピードで進化している
のも魅力。より便利で旬な技術をすぐに利用し貢献する、という良いサイクルをうちの
会社でも実現したい。だって楽しいから。chef-solo 使うの？chef サーバ使うの？と
いう話はここでも挙がってた。どこかでブログにしようかな。僕は chef サーバ使わな
い理由がないと思ってる。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/04/06/cloudmanagement/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Categories
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
        <li><a href='/categories/report'>report</a></li>
    
</ul>

    </footer>
</article>


        
            <article class="post">
    <header>
    <div class="title">
        
            <h2><a href="https://jedipunkz.github.io/blog/2013/03/28/netbsd-on-openstack/">NetBSD on OpenStack</a></h2>
        
        
    </div>
    <div class="meta">
        
            
        

        <time class="published"
            datetime='2013-03-28'>
            March 28, 2013</time>
        <span class="author"></span>
        
        
    </div>
</header>

    

    
    <p><p>もう数日で OpenStack の次期バージョン版 Grizzly がリリースされるタイミングだが
現行バージョン Folsom の OpenStack の上に NetBSD を載せてみた。完全にお遊び
だけど&hellip;。</p>

<p>結局、ほとんど何も特別な対応取ることなく NetBSD が動いた。もちろんハイパーバイ
ザは KVM です。だけど少し条件がある。</p>

<p>qemu の不具合があり Ubuntu 12.04 LTS + Ubuntu Cloud Archives の組み合わせでは
NetBSD が動作しなかった。下記のようなカーネルパニックが発生。</p>

<pre><code>panic: pci_make_tag: bad request
</code></pre>

<p>この不具合に相当するんじゃないかと思ってる。</p>

<p><a href="https://bugs.launchpad.net/qemu/+bug/897771">https://bugs.launchpad.net/qemu/+bug/897771</a></p>

<p>よって下記の組み合わせで動作を確認した。</p>

<ul>
<li>Ubuntu 12.10 + OpenStack (Native Packages)</li>
<li>qemu, kvm : 1.2.0+noroms-0ubuntu2.12.10.3</li>
<li>NetBSD 6.1 RC2 amd64</li>
</ul>

<h2 id="前提条件">前提条件</h2>

<p>OpenStack Folsom が動作していること。</p>

<h2 id="netbsd-os-イメージ作成">NetBSD OS イメージ作成</h2>

<p>nova-compute が動作しているホストの qemu-kvm を利用する。OpenStack 上に何でも
良いので OS を動作させこの kvm プロセスのパラメータを参考に kvm コマンドを実行
し NetBSD をインストールさせた。一番確実な方法。</p>

<pre><code>% cd ~/
% wget http://ftp.netbsd.org/pub/NetBSD/iso/6.1_RC2/NetBSD-6.1_RC2-amd64.iso
% kvm-img create -f qcow2 netbsd.img 5G
% /usr/bin/kvm -M pc-1.0 -cpu \
core2duo,+lahf_lm,+rdtscp,+hypervisor,+avx,+osxsave,+save,+aes,+popcnt,+sse4.2,+sse4.1,+cx16,+vmx,+pclmuldq,+ht,+ss,+ds \
-enable-kvm -m 512 -smp 1,sockets=1,cores=1,threads=1 -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 \
-drive file=~/netbsd.img,if=none,id=drive-virtio-disk0,format=qcow2,cache=none \
-device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x4,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 \
-net nic,model=virtio -vnc :9 -cdrom ~/NetBSD-6.1_RC2-amd64.iso
</code></pre>

<p>VNC :9 に接続して NetBSD を普通ににインストールする。</p>

<p>インストールが終わったら CDROM デバイスを外して起動。</p>

<pre><code>% core2duo,+lahf_lm,+rdtscp,+hypervisor,+avx,+osxsave,+save,+aes,+popcnt,+sse4.2,+sse4.1,+cx16,+vmx,+pclmuldq,+ht,+ss,+ds \
-enable-kvm -m 512 -smp 1,sockets=1,cores=1,threads=1 -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 \
-drive file=~/netbsd.img,if=none,id=drive-virtio-disk0,format=qcow2,cache=none \
-device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x4,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 \
-net nic,model=virtio -vnc :9
</code></pre>

<p>VNC :9 に接続し下記の操作を行う。</p>

<p>vioif0 という virtio なネットワークインターフェースが起動するので下記のように
追記する。</p>

<pre><code># vi /etc/rc.conf # 下記を追記
ifconfig_vioif0=dhcp
sshd=YES
</code></pre>

<p>OpenStack の metadata server から nova の管理するキーペア鍵を取得し
authorized_keys に配置する様、/etc/rc.local に追記する。curl とか便利なツール
はもちろん！入っていないので ftp コマンドでなんとかする。</p>

<pre><code class="language-bash"># vi /etc/rc.local # 下記を追記
if [ ! -d /root/.ssh ]; then
    mkdir -p /root/.ssh
fi
echo &gt;&gt; /root/.ssh/authorized_keys
cd /tmp
ftp http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key
cat openssh-key | grep 'ssh-rsa' &gt;&gt; /root/.ssh/authorized_keys
echo &quot;AUTHORIZED_KEYS:&quot;
echo &quot;*********************&quot;
cat /root/.ssh/authorized_keys
echo &quot;*********************&quot;
</code></pre>

<p>nova のキーペアでログインしたいので sshd は root ユーザでログイン出来るように
修正行う。</p>

<pre><code># vi /etc/ssh/sshd_config
PermitRootLogin yes
</code></pre>

<p>OS をシャットダウンしてイメージ作成は終わり。</p>

<h2 id="glance-へ登録">Glance へ登録</h2>

<p>netbsd.img を Glance に接続できるホストへ移動しイメージ登録を行う。</p>

<pre><code>% glance add name=&quot;NetBSD 6.1 RC2 amd64&quot; is_public=true \
  container_format=ovf disk_format=qcow2 &lt; ~/netbsd.img
</code></pre>

<h2 id="まとめ">まとめ</h2>

<p>何も手を加えていない&hellip;。NetBSD 6.1 は最初から Virtio が有効になっているので何
も考えることなくイメージ作成が出来た。コツは nova-compute が実際に動作している
ホストでイメージを作ること。ハイパーバイザの OS が若干古いホストでも作業してみ
たのだが、OpenStack に載せた途端カーネルパニックに陥った。Qemu はものすごいス
ピードで進化しているのでバージョンの差異は致命的であると共に、日に日に快適な環
境が整ってきているとも言える。</p>
</p>

    <footer>
        <ul class="actions">
            <li><a href="https://jedipunkz.github.io/blog/2013/03/28/netbsd-on-openstack/" class="button big">Continue Reading</a></li>
        </ul>
        <ul class="stats">
    
        

        
        
            <li>
                
                
                    

                    
                        Category
                    
                
            </li>
        
    

    
    
        <li><a href='/categories/infrastructure'>infrastructure</a></li>
    
</ul>

    </footer>
</article>


        

        
<ul class="actions pagination">
    
        <li><a href="/categories/infrastructure/page/7/"
                class="button big previous">Previous Page</a></li>
    

    
        <li><a href="/categories/infrastructure/page/9/"
                class="button big next">Next Page</a></li>
    
</ul>

    </div>
    
<section id="sidebar">

    
        <section id="intro">
            
            
            
            <ul class="icons">
                
                    <li><a href="https://jedipunkz.github.io/categories/infrastructure/index.xml" type="application/rss+xml"
                        target="_blank" title="RSS" class="fa fa-rss"></a></li>
                
                
            </ul>
        </section>

    
        <section id="recent-posts">
            <ul class="posts">
                <header>
                    <h3>Recent Posts</h3>
                </header>
                
                    
                

                
                    
                

                
                    <li>
                        <article>
                            <header>
                                <h3><a href="https://jedipunkz.github.io/blog/2018/12/31/istio/">Istio, Helm を使って Getting Started 的なアプリをデプロイ</a></h3>
                                
                                    
                                
                                <time class="published" datetime=
                                    '2018-12-31'>
                                    December 31, 2018</time>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <h3><a href="https://jedipunkz.github.io/blog/2017/07/02/test-kitchen-cluster/">Docker,Test-Kitchen,Ansible でクラスタを構成する</a></h3>
                                
                                    
                                
                                <time class="published" datetime=
                                    '2017-07-02'>
                                    July 2, 2017</time>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <h3><a href="https://jedipunkz.github.io/blog/2017/04/13/gke-lb/">GCP ロードバランサと GKE クラスタを Terraform を使って構築する</a></h3>
                                
                                    
                                
                                <time class="published" datetime=
                                    '2017-04-13'>
                                    April 13, 2017</time>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <h3><a href="https://jedipunkz.github.io/blog/2017/02/12/serverless-fission/">Serverless on Kubernetes : Fission を使ってみた</a></h3>
                                
                                    
                                
                                <time class="published" datetime=
                                    '2017-02-12'>
                                    February 12, 2017</time>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <h3><a href="https://jedipunkz.github.io/blog/2017/01/13/kubernetes-deployments/">Kubernetes Deployments を使ってみた！</a></h3>
                                
                                    
                                
                                <time class="published" datetime=
                                    '2017-01-13'>
                                    January 13, 2017</time>
                            </header>
                        </article>
                    </li>
                

                
                    <li>
                        <ul class="actions">
                            <li><a href=
                            
                                "/post/"
                            
                            class="button">View more posts</a></li>
                        </ul>
                    </li>
                
            </ul>
        </section>

    
    
    
    
        <section id="categories">
            <ul class="posts">
                <header>
                    <h3><a href="/categories/">Categories</a></h3>
                </header>

                
                    
                

                
                    <li>
                        <article>
                            <header>
                                <a href="/categories/infrastructure/">infrastructure</a>
                                <span style="float:right;">110</span>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <a href="/categories/report/">report</a>
                                <span style="float:right;">9</span>
                            </header>
                        </article>
                    </li>
                
                    <li>
                        <article>
                            <header>
                                <a href="/categories/tools/">tools</a>
                                <span style="float:right;">11</span>
                            </header>
                        </article>
                    </li>
                
            </ul>
        </section>
    

    
        

    
        <section id="footer">
            <ul class="icons">
                
                    <li><a href="https://jedipunkz.github.io/categories/infrastructure/index.xml" type="application/rss+xml"
                        target="_blank" title="RSS" class="fa fa-rss"></a></li>
                
                
            </ul>

            <p class="copyright">&copy; ジェダイさんのブログ. テーマデザインは <a href="//github.com/jpescador" target="_blank">Julio Pescador</a>さんによるものです。 </p>
        </section>

</section>

            </div>
        <a id="back-to-top" href="#" class="fa fa-arrow-up fa-border fa-2x"></a>
        

        
        
            
        

        
        
            <script src="/js/jquery.min.js"></script>
            <script src="/js/skel.min.js"></script>
            <script src="/js/util.js"></script>
            <script src="/js/main.js"></script>
            <script src="/js/backToTop.js"></script>
            <script src="/js/highlight.pack.js"></script>
        

        

            
            <script>hljs.initHighlightingOnLoad();</script>
            
    </body>
</html>

