<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on jedipunkz 🚀 のブログ</title>
    <link>https://jedipunkz.github.io/post/</link>
    <description>Recent content in Posts on jedipunkz 🚀 のブログ</description>
    <image>
      <title>jedipunkz 🚀 のブログ</title>
      <url>https://jedipunkz.github.io/jedipunkz.jpg</url>
      <link>https://jedipunkz.github.io/jedipunkz.jpg</link>
    </image>
    <generator>Hugo -- 0.149.1</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Sep 2025 10:00:00 +0900</lastBuildDate>
    <atom:link href="https://jedipunkz.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Terraform Plan 差分をパースする GitHub Actions を作った</title>
      <link>https://jedipunkz.github.io/post/tf-plan-analyzer/</link>
      <pubDate>Mon, 15 Sep 2025 10:00:00 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/tf-plan-analyzer/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://x.com/jedipunkz&#34;&gt;jedipunkz🚀&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Terraform を運用しているとたまに Plan 結果がどうしても出てしまう事があります。また Terraform を GitHub で実行する環境を運用していると Plan 結果をうまく扱って自動化したいモチベーションも湧いてきます。この場合に Plan の差分をうまく処理してくれる GitHub Action があればなと思って作ってみました。&lt;/p&gt;
&lt;h2 id=&#34;github-actions&#34;&gt;GitHub Actions&lt;/h2&gt;
&lt;p&gt;作成した GitHub Action は下記のレポジトリで公開しています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/tf-plan-parser&#34;&gt;https://github.com/jedipunkz/tf-plan-parser&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;入力オプション設定&#34;&gt;入力・オプション設定&lt;/h2&gt;
&lt;p&gt;この GitHub Action では2つの入力オプションが利用可能です：&lt;/p&gt;
&lt;h3 id=&#34;terraform-plan-必須&#34;&gt;terraform-plan (必須)&lt;/h3&gt;
&lt;p&gt;パース対象となる Terraform Plan の出力結果を指定します。通常は前のステップで実行した &lt;code&gt;terraform plan&lt;/code&gt; コマンドの標準出力を渡します。&lt;/p&gt;
&lt;h3 id=&#34;ignore-resources-オプション&#34;&gt;ignore-resources (オプション)&lt;/h3&gt;
&lt;p&gt;無視したいリソースタイプや特定のリソースを配列形式で指定します。デフォルトは空の配列 &lt;code&gt;[]&lt;/code&gt; です。&lt;/p&gt;
&lt;p&gt;指定方法の例：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;リソースタイプ全体を無視:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;ignore-resources&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[&amp;#34;null_resource&amp;#34;, &amp;#34;local_file&amp;#34;]&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;特定のリソースインスタンスを無視:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;ignore-resources&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[&amp;#34;null_resource.temporary&amp;#34;, &amp;#34;local_file.cache&amp;#34;]&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;リソースタイプとインスタンスの混在:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;ignore-resources&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[&amp;#34;null_resource&amp;#34;, &amp;#34;aws_s3_bucket.temp&amp;#34;, &amp;#34;local_file&amp;#34;]&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;出力される情報&#34;&gt;出力される情報&lt;/h2&gt;
&lt;p&gt;この Action は以下の出力を提供します。また下記は ignore-resources オプションの指定に沿って結果を出力してくれます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;diff-bool: 変更があるかどうかの真偽値（&lt;code&gt;true&lt;/code&gt; または &lt;code&gt;false&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;diff-count: 変更されるリソースの数&lt;/li&gt;
&lt;li&gt;diff-resources: 変更されるリソースのアドレス一覧（カンマ区切り）&lt;/li&gt;
&lt;li&gt;diff-raw: 生の差分データ&lt;/li&gt;
&lt;li&gt;diff-json: s分データの JSON 形式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらの出力を使って、後続のステップで条件分岐や通知の制御が可能です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Go 初学者が学ぶクリーンアーキテクチャ</title>
      <link>https://jedipunkz.github.io/post/go-clean-architecture/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/go-clean-architecture/</guid>
      <description>&lt;p&gt;自分は Go の初学者なのですがクリーンアーキテクチャを学ぶために幾つかの書籍を読んでみたもののなかなかしっくりと理解が出来ていない状態でした。 そこで AI に極力シンプルなコードを書かせて理解するという事をやってみたのですが、なかなかいい感じに理解が進んだのでここで記事にしたいと思っています。&lt;/p&gt;
&lt;h2 id=&#34;クリーンアーキテクチャとは&#34;&gt;クリーンアーキテクチャとは？&lt;/h2&gt;
&lt;p&gt;クリーンアーキテクチャは、Robert C. Martin によって提唱されたソフトウェア設計原則で最も重要な特徴は依存関係の方向性にあります。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;依存関係図&#34; loading=&#34;lazy&#34; src=&#34;../../pix/go-clean-architecture-2.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;従来のアーキテクチャとは異なり、内側の層は外側の層を知らないという原則に基づいています。これにより以下のメリットが得られます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;テスタビリティ: ビジネスロジックを単体でテスト可能&lt;/li&gt;
&lt;li&gt;柔軟性: データベースや Web フレームワークの変更が容易&lt;/li&gt;
&lt;li&gt;保守性: 関心の分離により変更の影響範囲を限定&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;実装するシステムの全体像&#34;&gt;実装するシステムの全体像&lt;/h2&gt;
&lt;p&gt;今回 AI に実装させたのは RESTful API を提供するユーザー管理システムです。&lt;/p&gt;
&lt;p&gt;コードは下記のレポジトリにあります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/go-clean-architecture-playground&#34;&gt;https://github.com/jedipunkz/go-clean-architecture-playground&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;システム構成図&#34; loading=&#34;lazy&#34; src=&#34;../../pix/go-clean-architecture-1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;システムは以下の4つの層で構成されています：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entity レイヤ - ビジネスの核となるルール&lt;/li&gt;
&lt;li&gt;Interface レイヤ - 抽象化による疎結合&lt;/li&gt;
&lt;li&gt;Use Case レイヤ   - ビジネスロジックの実装&lt;/li&gt;
&lt;li&gt;Infrastructure レイヤ - 外部システムとの連携実装&lt;/li&gt;
&lt;li&gt;Controller レイヤ - HTTP APIの提供&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;各層の詳細実装&#34;&gt;各層の詳細実装&lt;/h2&gt;
&lt;h3 id=&#34;1-entity-レイヤ---ビジネスの核となるルール&#34;&gt;1. Entity レイヤ - ビジネスの核となるルール&lt;/h3&gt;
&lt;p&gt;最も内側の層から実装を始めます。エンティティ層は他のどの層にも依存しない純粋なビジネスロジックです。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// entity/user.go&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;package&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;errors&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;User&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;ID&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;       &lt;span style=&#34;color:#e6db74&#34;&gt;`json:&amp;#34;id&amp;#34;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;Name&lt;/span&gt;      &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;`json:&amp;#34;name&amp;#34;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;Email&lt;/span&gt;     &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;`json:&amp;#34;email&amp;#34;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;CreatedAt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Time&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`json:&amp;#34;created_at&amp;#34;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;UpdatedAt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Time&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`json:&amp;#34;updated_at&amp;#34;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;NewUser&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;) (&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;User&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;error&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;名前は必須です&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;メールアドレスは必須です&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;now&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Now&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;User&lt;/span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#a6e22e&#34;&gt;Name&lt;/span&gt;:      &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#a6e22e&#34;&gt;Email&lt;/span&gt;:     &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#a6e22e&#34;&gt;CreatedAt&lt;/span&gt;: &lt;span style=&#34;color:#a6e22e&#34;&gt;now&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#a6e22e&#34;&gt;UpdatedAt&lt;/span&gt;: &lt;span style=&#34;color:#a6e22e&#34;&gt;now&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}, &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;u&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;User&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;UpdateInfo&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;error&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;名前は必須です&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;メールアドレスは必須です&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;u&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Name&lt;/span&gt; = &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;u&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Email&lt;/span&gt; = &lt;span style=&#34;color:#a6e22e&#34;&gt;email&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;u&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;UpdatedAt&lt;/span&gt; = &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Now&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;この &lt;code&gt;User&lt;/code&gt; エンティティは、クリーンアーキテクチャの最も内側に位置する部分です。ここで重要なのは、このエンティティが外部の何にも依存していないことです。データベースがMySQLなのかPostgreSQLなのか、WebフレームワークがGinなのかEchoなのか、そういった技術的な詳細は一切知らないのが特徴になっています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>MCP の理解: Platform Enabler/SRE での活用</title>
      <link>https://jedipunkz.github.io/post/2025/04/06/local-filesystem-mcp-server/</link>
      <pubDate>Sun, 06 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2025/04/06/local-filesystem-mcp-server/</guid>
      <description>&lt;p&gt;自分は Platform Enabler/SRE として従事しています。また AI 関連のアップデートは2025年に入っても属に更新されています。2025年初頭においては自分たちの分野でも AI 関連の利用に関して様々な模索がある状況だと思われますが、Ahthoropic 社が提唱した MCP (Model Context Protocol) がもたらすインパクトはアプリケーションに限定されずインフラ領域のソフトウェアにも大きなメリットをもたらすと思って観測しています。&lt;/p&gt;
&lt;p&gt;この記事では、MCP の概要とどう実装するのかの学習、またどう我々のような Platform Enabler/SRE にとっての活用例があるかを考察していきたいと思っています。&lt;/p&gt;
&lt;h2 id=&#34;mcp-の概要&#34;&gt;MCP の概要&lt;/h2&gt;
&lt;p&gt;MCP (Model Context Protocol) は、AI モデルと外部システム間のやり取りを効率化するプロトコルで JSON-RPC でやりとりします。ユーザーの自然言語入力を基に、AI アシスタントが MCP サーバーを通じてファイル操作やデータ処理を実行します。&lt;/p&gt;
&lt;p&gt;最近 OpenAI 社もこの Anthropic 社の MCP をサポートするというニュースが流れ、途端に注目を集める状況になってきました。&lt;/p&gt;
&lt;h3 id=&#34;処理の流れ&#34;&gt;処理の流れ&lt;/h3&gt;
&lt;p&gt;ここはあくまでの一例です。Assistant の実装でいかようにも出来ると思います。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-------------+          +-----------+      +------------+   +--------+
| User Prompt | &amp;lt;-----&amp;gt;  | Assistant | ---&amp;gt; | MCP Server |   | AI API |
+-------------+ (1),(5)  +-----------+  (3) +------------+   +--------+
                               |                                  ^
                               |             (2),(4)              |
                               +----------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;(1) ユーザからの入力を Assistant が受け取る&lt;/li&gt;
&lt;li&gt;(2) Assistant はユーザからの自然言語を LLM に問い合わせ。その際に LLM に外部機能を定義 (JSON-RPC(MCP サーバが受け取る))&lt;/li&gt;
&lt;li&gt;(3) Aasistant は MCP Server に JSON-RPC でクエリ送信しレスポンスを得る&lt;/li&gt;
&lt;li&gt;(4) Assistant は MCP Server から得たレスポンスを再び LLM に送信し自然言語としてユーザに返す内容を生成してもらう&lt;/li&gt;
&lt;li&gt;(5) Assistant はユーザに自然言語で結果を応答する&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前提&#34;&gt;前提&lt;/h2&gt;
&lt;p&gt;MCP 学習を目的にしているので、ここでは話を簡潔にするため Linux Filesystem を操作する MCP Server を書き、理解していきます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>VPC Lattice &#43; ECS 構成を Terraform を通して理解</title>
      <link>https://jedipunkz.github.io/post/vpclattice-ecs/</link>
      <pubDate>Thu, 28 Nov 2024 00:00:27 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/vpclattice-ecs/</guid>
      <description>&lt;p&gt;jedipunkz です。VPC Lattice が ECS に対応したという情報が &lt;a href=&#34;https://aws.amazon.com/jp/about-aws/whats-new/2024/11/amazon-vpc-lattice-elastic-container-service/&#34;&gt;https://aws.amazon.com/jp/about-aws/whats-new/2024/11/amazon-vpc-lattice-elastic-container-service/&lt;/a&gt; にあがりました。この対応を Terraform を使って構成して検証してみるのが今回の目的になります。&lt;/p&gt;
&lt;h2 id=&#34;今回検証で用いたコード&#34;&gt;今回検証で用いたコード&lt;/h2&gt;
&lt;p&gt;検証コードは下記に置いておきました。
&lt;a href=&#34;https://github.com/jedipunkz/vpclattice-ecs-playground&#34;&gt;https://github.com/jedipunkz/vpclattice-ecs-playground&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;構成の概要としては下記です。(Mermaid 記表でうまく描けていませんが)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VPC1, VPC2 に跨る形で VPC Lattice Service Network が配置&lt;/li&gt;
&lt;li&gt;VPC2 上の何者か (例で EC2) が VPC1 上の ECS に接続可能&lt;/li&gt;
&lt;li&gt;その際は VPC Service Network を介して VPC Lattice Service がエンドポイントとして受ける (うまく描けてない)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という事は今まで複数の VPC 間で ECS のエンドポイントを共有しようとすると&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VPC1, VPC2 とで VPC Peering を張る&lt;/li&gt;
&lt;li&gt;VPC1 上の Private Subnets 上で ALB を構築して ECS Service に接続する&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という構成が必要でしたが、VPC Lattice を使えばそれらが不要になる、という事です。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;VPC Lattice Overview&#34; loading=&#34;lazy&#34; src=&#34;../../pix/vpclattice-overview.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;今回検証した構成&#34;&gt;今回検証した構成&lt;/h2&gt;
&lt;p&gt;今回使った Terraform コードで構築した構成は下記です。各 AWS リソースの関係図になっています。
特徴としては&lt;/p&gt;</description>
    </item>
    <item>
      <title>Go, OpenTelemetry で AWS にログ・トレースを計装してみる</title>
      <link>https://jedipunkz.github.io/post/opentelemetry-aws/</link>
      <pubDate>Sun, 14 Jan 2024 00:23:37 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/opentelemetry-aws/</guid>
      <description>&lt;p&gt;OpenTelemetry を使って AWS (X-Ray, Cloudwatch Logs) にトレースとログを計装する事に興味があったので調べた内容を記そうと思います。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;今回検証してみた構成は下記の様な構成です。AWS を用いた場合 ECS や EKS, Lambda で Go アプリを起動する事が通常ですが、今回は docker-compose で検証しました。ただ ECS, EKS に置き換えるのは比較的簡単だと思います。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;        trace post          PutTelemetryRecords
+--------+      +----------------+      +-----------------+
| Go App | -+-&amp;gt; | Otel Collector | ---&amp;gt; |    AWS X-Ray    |
+--------+  |   +----------------+      +-----------------+
            |   +----------------+      +-----------------+
            +-&amp;gt; |   Fluent-Bit   | ---&amp;gt; | Cloudwatch Logs |
                +----------------+      +-----------------+
                                PutLogEvents
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;ログとトレースの紐づけ&#34;&gt;ログとトレースの紐づけ&lt;/h2&gt;
&lt;p&gt;ログは Cloudwatch Logs へ、トレース情報は AWS X-Ray へ転送しますが、このログとトレースを紐付けると、運用する上で追跡が容易になります。この紐づけは AWS の場合は簡単で下記の要件を満たせば紐づけがされます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>自前開発した Prometheus Exporter で自宅ルータのメトリクス監視運用している話</title>
      <link>https://jedipunkz.github.io/post/linux-tiny-exporter/</link>
      <pubDate>Sat, 13 Jan 2024 22:28:22 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/linux-tiny-exporter/</guid>
      <description>&lt;p&gt;自宅のルータについても可観測性を向上して普段の運用に役立てています。例えば長期スパンでのネットワーク通信料の推移や CPU, Mem 使用率、あとハードウェアの温度の推移などを観測しています。&lt;/p&gt;
&lt;p&gt;今までは Prometheus の Node Exporter を使ってホストの情報を Prometheus Server に提供していたのですが、自分で Go で Prometheus Exporter を書いて運用するにようになったので、それについてまとめます。&lt;/p&gt;
&lt;h2 id=&#34;grafana-の可視化情報&#34;&gt;Grafana の可視化情報&lt;/h2&gt;
&lt;p&gt;下記が可視化された情報です。CPU, Mem やネットワーク送信量、またハードウェアの温度を可視化して運用しています。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;grafana1&#34; loading=&#34;lazy&#34; src=&#34;../../pix/linux-tiny-exporter-1.png&#34;&gt;
&lt;img alt=&#34;grafana2&#34; loading=&#34;lazy&#34; src=&#34;../../pix/linux-tiny-exporter-2.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ソース置き場&#34;&gt;ソース置き場&lt;/h2&gt;
&lt;p&gt;結論になりますが下記にソースを置いています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/linux-tiny-exporter&#34;&gt;https://github.com/jedipunkz/linux-tiny-exporter&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ネットワーク送信受信メトリクスを説明&#34;&gt;ネットワーク送信・受信メトリクスを説明&lt;/h2&gt;
&lt;p&gt;実際にはこのコードでは CPU 使用率, Memory 使用率, Disk IO, Network トラヒック, ハードウェア温度を取得・提供しているのですが、ここでは例としてネットワークトラヒックに関するメトリクスを Prometheus Server に提供するコードを説明しようと思います。&lt;/p&gt;
&lt;h3 id=&#34;パッケージのインポート&#34;&gt;パッケージのインポート&lt;/h3&gt;
&lt;p&gt;Prometheus のクライアントライブラリから2つのパッケージをインポートしています。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;github.com/prometheus/client_golang/prometheus&amp;rdquo;: これは Prometheus の基本的なクライアントライブラリで、メトリクスを定義、収集、エクスポートするための機能を提供します。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;github.com/prometheus/client_golang/prometheus/promhttp&amp;rdquo;: これは Prometheus の HTTP サーバーとクライアントのためのライブラリで、HTTP 経由でメトリクスを公開するためのハンドラを提供します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;github.com/prometheus/client_golang/prometheus&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;github.com/prometheus/client_golang/prometheus/promhttp&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;ネットワークトラヒックに関する構造体定義&#34;&gt;ネットワークトラヒックに関する構造体定義&lt;/h3&gt;
&lt;p&gt;ここからは Internal Packege のコード解説です。&lt;/p&gt;
&lt;p&gt;NetCollector という構造体が定義しています。この構造体は、ネットワークインターフェースごとの受信バイト数、送信バイト数、受信パケット数、送信パケット数の差分を保持します。~Diff はそれぞれの値の差分を保持します。前回のスクレイプ（データ収集）からの変化を表します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;NetCollector&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;receivedBytesDiff&lt;/span&gt;   &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prometheus&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Desc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;transmitBytesDiff&lt;/span&gt;   &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prometheus&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Desc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;receivedPacketsDiff&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prometheus&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Desc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;transmitPacketsDiff&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;prometheus&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Desc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;lastReceivedBytes&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;lastTransmitBytes&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;lastReceivedPackets&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;lastTransmitPackets&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#66d9ef&#34;&gt;float64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;コンストラクタ&#34;&gt;コンストラクタ&lt;/h3&gt;
&lt;p&gt;NewNetCollector 関数は、新しい NetCollector インスタンスを作成します。この関数では、各メトリクスの差分を表す prometheus.Desc オブジェクトを作成し、それらを NetCollector 構造体の対応するフィールドに設定します。また、前回のスクレイプ時の各メトリクスの値を保持するマップも作成します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>VyOS で IPoE/PPPoE を併用して安定した接続&amp;サーバー公開</title>
      <link>https://jedipunkz.github.io/post/vyos-ipoe-pppoe/</link>
      <pubDate>Sun, 10 Dec 2023 01:14:57 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/vyos-ipoe-pppoe/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。今まで自宅では PPPoE 接続をして Global IPv4 アドレスを取得して自宅にマイクラサーバーを外部公開しその接続を使って各端末でオンラインゲームやインターネットをしていました。ただ、IPoE 接続すると混雑時間を回避出来ると聞いていたので (これについては後術します)、普段のゲームや各端末のインターネット接続は IPoE 接続を利用しマイクラサーバーは PPPoE で公開、と出来ないかと考えました。IPoE は IPv4 over IPv6 のトンネリング接続するたため IPoE だけでは IPv4 Global IP アドレスによるサーバー公開は不可能だからです。&lt;/p&gt;
&lt;p&gt;ここでは VyOS を使ってその両者を満たす接続の設定方法を記します。&lt;/p&gt;
&lt;h2 id=&#34;要件&#34;&gt;要件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;PPPoE して Global IPv4 を取得しサーバーを外部に提供&lt;/li&gt;
&lt;li&gt;(その際に Dynamic DNS を利用 (自宅は Cloudflare))&lt;/li&gt;
&lt;li&gt;サーバー以外の端末のトラヒックは IPoE 接続した経路に流す&lt;/li&gt;
&lt;li&gt;回線はNTT フレッツ想定 (自分の場合は Asahi-net, IPv6 接続オプションあり, その他でも可)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iso-イメージをビルド&#34;&gt;ISO イメージをビルド&lt;/h2&gt;
&lt;p&gt;VyOS は Stable のバージョンは有償バージョンでないとダウンロード出来ませんがビルドすれば ISO イメージが作れます。その方法を記します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2023/12 時点で最新の Stable バージョン 1.3.4 を指定&lt;/li&gt;
&lt;li&gt;適当な Linux 端末でビルドしましたが Docker を利用できればどこでも良さそう&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone -b equuleus https://github.com/vyos/vyos-build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd vyos-build/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker run --rm -it --privileged -v &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;pwd&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:/vyos -w /vyos vyos/vyos-build:equuleus bash
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./configure --architecture amd64 --build-type release --version 1.3.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo make iso
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ビルドが完了すると &lt;code&gt;build/&lt;/code&gt; ディレクトリ配下に iso イメージが出来上がっているはずです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>k8s コンテナをインクリメンタルサーチ&amp;ログインする kubectl プラグインの開発</title>
      <link>https://jedipunkz.github.io/post/kubectl-plugin/</link>
      <pubDate>Fri, 16 Jun 2023 23:28:09 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/kubectl-plugin/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は、kubectl プラグインを開発したことがなかったので、Go の学習と合わせてためしに1つ作ってみたのでその内容を記したいと思います。&lt;/p&gt;
&lt;h2 id=&#34;開発した-kubectl-plugin-kubectl-fuzzy-login&#34;&gt;開発した kubectl plugin: kubectl-fuzzy-login&lt;/h2&gt;
&lt;p&gt;下記が今回開発した kubectl プラグインです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/kubectl-fuzzy-login&#34;&gt;https://github.com/jedipunkz/kubectl-fuzzy-login&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;何が出来るか&#34;&gt;何が出来るか&lt;/h3&gt;
&lt;p&gt;下記のキャプチャをご覧頂くと一目瞭然だと思います。&lt;/p&gt;
&lt;p&gt;Kubernetes のポッドとコンテナをインクリメンタルサーチしつつ選択し、最終的にコンテナにログイン出来るプラグインになっています。コンテナがサイドカー構成になっていた場合は、そのうちのどのコンテナにログインするかもインクリメンタルサーチ出来ます。なお、このプラグインは Go で開発しました。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;kubectl-fuzzy-login&#34; loading=&#34;lazy&#34; src=&#34;../../pix/kubectl-fuzzy-login.gif&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;インストール方法&#34;&gt;インストール方法&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://krew.sigs.k8s.io/&#34;&gt;Krew&lt;/a&gt; を利用している場合は下記の操作でインストールできます。Krew が事前にインストールされている必要があります。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/jedipunkz/kubectl-fuzzy-login.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl krew install --manifest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;./kubectl-fuzzy-login/krew/fuzzy-login.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;マニュアル操作でインストールする場合は下記です。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/jedipunkz/kubectl-fuzzy-login.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd kubectl-fuzzy-login
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;go build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp kubectl-fuzzy-login /your/bin/path
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;使用方法&#34;&gt;使用方法&lt;/h3&gt;
&lt;h4 id=&#34;オプション無しで全-namespaces-を対象に検索ログインする&#34;&gt;オプション無しで、全 Namespaces を対象に検索・ログインする&lt;/h4&gt;
&lt;p&gt;オプションを使用しない場合は下記のように実行します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl fuzzy login 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;まず Pod を選択します。Pod 名の一部を入力することでインクリメンタル・ファジー検索出来ます。その Pod に複数のコンテナ (サイドカー) がある場合、更にコンテナをインクリメンタルサーチ出来ます。最終的にコンテナを選択し Enter ボタンを押すことでコンテナにログイン出来ます。ただしコンテナイメージにシェルが入っていない場合は入ることが出来ません。&lt;/p&gt;
&lt;h4 id=&#34;シェル指定&#34;&gt;シェル指定&lt;/h4&gt;
&lt;p&gt;また下記のように &lt;code&gt;-s&lt;/code&gt; オプションでデフォルトのシェルを指定することもできます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl fuzzy login -s /bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;namespace-指定&#34;&gt;Namespace 指定&lt;/h4&gt;
&lt;p&gt;Namespace を &lt;code&gt;-n&lt;/code&gt; オプションで指定することもできます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>手軽にローカルで Argo Rollouts, Istio, Prometheus で Progressive Delivery を試す</title>
      <link>https://jedipunkz.github.io/post/argo-rollout-progressive-delivery/</link>
      <pubDate>Sat, 03 Jun 2023 05:55:09 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/argo-rollout-progressive-delivery/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz🚀&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;以前&lt;a href=&#34;https://jedipunkz.github.io/post/ecs-pipecd/&#34;&gt;こちらの PipeCD 検証の記事&lt;/a&gt; で Progressive Deliver について調査したのですが、Kubernetes でこの Progressive Delivery を実現する方法を調べておきたいなと思って手元の Macbook 上で検証してみたのでその際の手順を記そうかと思います。&lt;/p&gt;
&lt;h2 id=&#34;progressive-delivery-の概要&#34;&gt;Progressive Delivery の概要&lt;/h2&gt;
&lt;p&gt;ここで概要だけ記しておきます。Canary リリースは新しいデプロイメントをある程度の割合だけリリースし、徐々にリリースを進行させるデプロイ方式ということはご存知だと思いますが、Progressive Delivery はその過程で&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新しいデプロイメントの統計情報を得る&lt;/li&gt;
&lt;li&gt;予め定義したデプロイ成功定義に対して条件満たしているかを過程毎にチェックする&lt;/li&gt;
&lt;li&gt;チェック OK であれば次の過程にデプロイを進める&lt;/li&gt;
&lt;li&gt;予め定義した幾つかのデプロイ過程を全て終えるとデプロイ完了となる&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;というステップを経ます。&lt;/p&gt;
&lt;h2 id=&#34;用いるソフトウェア&#34;&gt;用いるソフトウェア&lt;/h2&gt;
&lt;p&gt;Kubernetes で Progressive Delivery を実現するには下記のソフトウェアを用いる事が可能です。
また今回の手順は MacOS を前提に記します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://argo-rollouts.readthedocs.io/en/stable/b&#34;&gt;Argo Rollouts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kubernetes (今回は Minikube を使いました)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事前の準備&#34;&gt;事前の準備&lt;/h2&gt;
&lt;h3 id=&#34;istio&#34;&gt;Istio&lt;/h3&gt;
&lt;p&gt;Istio をダウンロードします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -L https://istio.io/downloadIstio | ISTIO_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;17.2 sh -
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio を Minikube にデプロイします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd istio-17.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;istioctl install --set profile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;demo -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Kubernetes Namespace &lt;code&gt;default&lt;/code&gt; で起動した Pod が自動的に Envoy サイドカーを取得するように設定します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>自前ツールと Cloudwatch 高解像度メトリクスを使ったより高速な ECS オートスケールの実現</title>
      <link>https://jedipunkz.github.io/post/esp/</link>
      <pubDate>Fri, 24 Mar 2023 14:54:11 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/esp/</guid>
      <description>&lt;p&gt;こんにちは &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 🚀 です。&lt;/p&gt;
&lt;p&gt;普段仕事で AWS ECS を使っていて Autoscallng Group によってアプリケーションを据えケールさせて運用していますが、運用している中でより高速にオートスケール出来ないものだろうか？と思うシチュエーションが何回か発生し、対応方法について模索していました。&lt;/p&gt;
&lt;h2 id=&#34;実際に発生したシチュエーション&#34;&gt;実際に発生したシチュエーション&lt;/h2&gt;
&lt;p&gt;下記はコンテナ毎の CPU 使用率です。1分未満の間に急激にアクセスが増えコンテナの CPU 使用率が 100% に達し (実際には vCPU に基づいて 200% となっている)、ECS Service のヘルスチェックに Fail して、コンテナが落ち、新しいコンテナは起動するものの、アクセス不可に耐えられず、コンテナ停止と起動を繰り返すといった状況でした。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;CPU Usage&#34; loading=&#34;lazy&#34; src=&#34;../../pix/esp_cpu_usage.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;autoscaling-policy-cloudwatch-metrics-alarm-の調整&#34;&gt;Autoscaling Policy, Cloudwatch Metrics Alarm の調整&lt;/h2&gt;
&lt;p&gt;まず最初に考えたのが下記の値の調整です。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;aws_app_autoscaling_policy の cooldown 値&lt;/li&gt;
&lt;li&gt;aws_cloudwatch_metric_alarm の period 値&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体的には &lt;code&gt;60sec&lt;/code&gt; となっていた値を &lt;code&gt;10sec&lt;/code&gt; などに変更しました。これによって 60sec のインターバルでしきい値計算してスケールさせていたところを 10sec にインターバルを縮めつつスケールさせる。つまりより迅速にスケールさせることで上記のシチュエーションに耐えられるのではと考えました。&lt;/p&gt;
&lt;p&gt;ですが、結果は NG でした。&lt;/p&gt;
&lt;p&gt;下記は Cloudwatch Metrics の様子です。データはプロットされているものの、&lt;code&gt;データ不足&lt;/code&gt; という状態に陥っている事がわかります。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;Cloudwatch Metrics&#34; loading=&#34;lazy&#34; src=&#34;../../pix/esp_cloudwatch_metrics.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;実際に ECS はこの設定をした Metrics Alarm ではスケールしてくれませんでした。&lt;/p&gt;
&lt;h2 id=&#34;高解像度メトリクスの利用について&#34;&gt;高解像度メトリクスの利用について&lt;/h2&gt;
&lt;p&gt;であれば&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/new-high-resolution-custom-metrics-and-alarms-for-amazon-cloudwatch/&#34;&gt;高解像度メトリクス&lt;/a&gt; を利用すれば良いのではと考えました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sysdig&#43;ECS Fargate でコンテナランタイムセキュリティ実践</title>
      <link>https://jedipunkz.github.io/post/sysdig-ecs-fargate/</link>
      <pubDate>Sat, 24 Sep 2022 22:00:00 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/sysdig-ecs-fargate/</guid>
      <description>&lt;p&gt;こんにちは &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 🚀 です。&lt;/p&gt;
&lt;p&gt;ECS 構成をもう少しセキュアに保てる構成はないものだろうかと模索しているなかで Sysdig を見つけました。まだ導入できる目処は立っていないのですがある程度ノウハウ蓄積出来てきたのでここで検証内容等を記事にしようかと思っています。&lt;/p&gt;
&lt;p&gt;Sysdig は幾つかのサービスが存在するのですが今回検証したのは Sysdig Serverless Security と呼ばれるモノで ECS Fargate 上のコンテナランタイムセキュリティを実践することができるサービスです。&lt;/p&gt;
&lt;h2 id=&#34;sysdig-とは&#34;&gt;Sysdig とは&lt;/h2&gt;
&lt;p&gt;AWS のサービスにも脅威検知を行うことができるサービスが揃っているのはご存知と思います&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;対象&lt;/th&gt;
          &lt;th&gt;目的&lt;/th&gt;
          &lt;th&gt;技術・サービス&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;AWS リソース&lt;/td&gt;
          &lt;td&gt;驚異検知&lt;/td&gt;
          &lt;td&gt;AWS GuardDuty&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;また予防の観点で脆弱性診断が出来るサービスもありあす&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;対象&lt;/th&gt;
          &lt;th&gt;目的&lt;/th&gt;
          &lt;th&gt;技術・サービス&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;AWS リソース&lt;/td&gt;
          &lt;td&gt;セキュリティ診断&lt;/td&gt;
          &lt;td&gt;AWS Trusted Advisor&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ECS コンテナ&lt;/td&gt;
          &lt;td&gt;脆弱性診断&lt;/td&gt;
          &lt;td&gt;ECR Image Scan&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;EC2 上のソフトウェア&lt;/td&gt;
          &lt;td&gt;脆弱性診断&lt;/td&gt;
          &lt;td&gt;AWS Inspector&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;ここで気がつくと思うのですがコンテナ上の驚異検知を行うサービスが AWS には無いと思っています。 (2022/09 時点)&lt;/p&gt;
&lt;p&gt;Sysdig Serverless Security は ECS Fargate コンテナ上の脅威検知を行うサービスです。ECS Fargate 利用時にコンテナ上の脅威検知を行うサービスは他にも幾つかありますが、Sysdig はシステムコールを利用したコンテナランタイムセキュリティを実践して脅威検知・通知が行えるものになります。自分も詳しくないのですがこれを CWPP (Cloud Workload Protection Platform) と言うらしいです。ワークロードというのはクラウド上の仮想マシン・稼働中のソフトウェアを指して、CWPP はマルウェア保護、脆弱性スキャン、アクセス制御、異常検知の機能を使用してそれぞれのワークロードを保護する、ということらしいです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ECS &#43; PipeCD &#43; Datadog でプログレッシブデリバリーを実現</title>
      <link>https://jedipunkz.github.io/post/ecs-pipecd/</link>
      <pubDate>Wed, 10 Aug 2022 09:11:04 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/ecs-pipecd/</guid>
      <description>&lt;p&gt;こんにちは &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 🚀 です。&lt;/p&gt;
&lt;p&gt;今回は CNCF にジョインした &lt;a href=&#34;https://pipecd.dev/&#34;&gt;PipeCD&lt;/a&gt; と Datadog を用いて ECS 環境にてプログレッシブデリバリーを実現する方法について調査したので、その内容を記したいと思います。&lt;/p&gt;
&lt;h2 id=&#34;そもそもプログレッシブデリバリーとは&#34;&gt;そもそもプログレッシブデリバリーとは&lt;/h2&gt;
&lt;p&gt;アプリケーションのデリバリー方法はカナリーリリースやブルーグリーンデプロイメント等がよく知られていると思います。プログレッシブデリバリーはその一歩先を行くデリバリー方式で、Prometheus や Datadog 等のメトリクスを用いて SLO (SRE の SLO と言うよりはデプロイのための指標という意味での) を元にカナリーリリースしたアプリケーションが期待した動作をしているかを確認し (プログレッシブデリバリー的にはこのフェーズを ANALYSIS という様です)、その上でカナリーリリースを完了するというフローになります。&lt;/p&gt;
&lt;h2 id=&#34;構成-pipecd-piped-共に-kubernetes-eks-クラスタ上に起動する構成&#34;&gt;構成 Pipecd, Piped 共に Kubernetes (EKS) クラスタ上に起動する構成&lt;/h2&gt;
&lt;p&gt;この検証ではこちらの構成を選択しました。この構成の特徴は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;piped は pipecd の API エンドポイントを指し示す&lt;/li&gt;
&lt;li&gt;pipecd は UI を提供&lt;/li&gt;
&lt;li&gt;pipecd は Filestore (S3, GCS, Minio など), Datastore (MySQL, Firestore など) を利用可 (今回は Minio, MySQL を選択)&lt;/li&gt;
&lt;li&gt;piped は Target Group, ECS タスク定義等の操作を行うため ECS API へのアクセス権限が必要&lt;/li&gt;
&lt;li&gt;piped の pipeline 上のステージで ANALYSIS という Datadog 等のメトリクスを解析する機能を有している&lt;/li&gt;
&lt;li&gt;アプリケーションレポジトリには app.pipecd.yaml を配置しターゲットグループ・タスク定義・ECS サービスを指し示す&lt;/li&gt;
&lt;li&gt;piped は GitHub レポジトリを参照&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;となっています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ECR 脆弱性スキャン結果表示 CLI の開発と Datadog プロット</title>
      <link>https://jedipunkz.github.io/post/ecr-scan-datadog-go/</link>
      <pubDate>Sat, 30 Apr 2022 13:56:56 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/ecr-scan-datadog-go/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz🚀&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;引き続き Go を学習しています。前回の記事 &lt;a href=&#34;http://localhost:1313/post/ecs-login-cli/&#34;&gt;ECS コンテナにログインする CLI を Go 言語で作った話&lt;/a&gt; のまとめにも記したのですが Go のコードを書くアイデアとして下記をぼんやり考えていました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ECR 脆弱性スキャンのパッケージを開発
&lt;ul&gt;
&lt;li&gt;そのパッケージを利用して Datadog のカスタムメトリクスとして送信&lt;/li&gt;
&lt;li&gt;同様にそのパッケージを利用して ECR スキャンの CLI を作成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;その紹介を軽くしたいと思います。&lt;/p&gt;
&lt;h3 id=&#34;開発した-ecr-脆弱性スキャンの-go-パッケージ&#34;&gt;開発した ECR 脆弱性スキャンの Go パッケージ&lt;/h3&gt;
&lt;p&gt;開発したパッケージは &lt;a href=&#34;https://github.com/jedipunkz/ecrscan&#34;&gt;https://github.com/jedipunkz/ecrscan&lt;/a&gt; になります。&lt;/p&gt;
&lt;p&gt;下記のように Ecr 構造体を初期化します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;e&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;myecr&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Ecr&lt;/span&gt;{}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;e&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Repositories&lt;/span&gt; = [][]&lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;		{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;image-to-scan&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;latest&amp;#34;&lt;/span&gt;},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;e&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Resion&lt;/span&gt; = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ap-northeast-1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#a6e22e&#34;&gt;finding&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;vulFindings&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;e&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;ListFindings&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;その後 &lt;code&gt;ListFindings()&lt;/code&gt; メソッドでスキャンします。結果、&lt;code&gt;finding.FindingSeverityCounts&lt;/code&gt; には下記の深刻度毎のイメージに含まれている脆弱性の数が入ります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;INFORMATIONAL&lt;/li&gt;
&lt;li&gt;LOW&lt;/li&gt;
&lt;li&gt;MEDIUM&lt;/li&gt;
&lt;li&gt;HIGH&lt;/li&gt;
&lt;li&gt;CRITICAL&lt;/li&gt;
&lt;li&gt;UNDEFINED&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;また、&lt;code&gt;vulFindings&lt;/code&gt; には含まれている脆弱性の&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CVE 名&lt;/li&gt;
&lt;li&gt;深刻度レベル (INFORMATIONAL, LOW, MEDIUM, HIGH, CRITICAL, UNDEFINED)&lt;/li&gt;
&lt;li&gt;CVE URI&lt;/li&gt;
&lt;li&gt;説明&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;が入ります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ECS コンテナにログインする CLI を Go 言語で作った話</title>
      <link>https://jedipunkz.github.io/post/ecs-login-cli/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:27 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/ecs-login-cli/</guid>
      <description>&lt;p&gt;こんにちは &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 🚀 です。&lt;/p&gt;
&lt;p&gt;今回は Go 言語で ECS コンテナにログインする CLI を作った話を書きます。&lt;/p&gt;
&lt;h3 id=&#34;開発の経緯&#34;&gt;開発の経緯&lt;/h3&gt;
&lt;p&gt;自分はまだ Go 言語の初学者で学習のために開発するアイデアを探していた状態でした。そこで自分の勤めている会社で ECS Execute 機能を使ったコンテナログインの機能を開発者に提供していた事を思い出し色々調べていて「もう少し手間が省けないか？」と思い立った、という経緯で開発をはじめました。&lt;/p&gt;
&lt;h3 id=&#34;awscli-を使った-ecs-execute-機能によるコンテナログイン&#34;&gt;awscli を使った ECS Execute 機能によるコンテナログイン&lt;/h3&gt;
&lt;p&gt;手間が多いと書きましたが実際に awscli を使う場合どの程度の手間があるのか簡単に記します。まず下記のコマンドを実行して&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ aws ecs list-tasks --cluster &amp;lt;クラスタ名&amp;gt; --service &amp;lt;サービス名&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;taskArn が得られるので Arn から task ID を拾って、その task ID を使って&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ aws ecs execute --cluster &amp;lt;クラスタ名&amp;gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --task &amp;lt;task ID&amp;gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -- container &amp;lt;コンテナ名&amp;gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --interfactive &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --command &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;とコマンドを実行することでコンテナにログイン出来ます。が手間が少し多いのと task ID を拾い出す作業も辛いので改善したい&amp;hellip;。&lt;/p&gt;
&lt;h3 id=&#34;操作画面&#34;&gt;操作画面&lt;/h3&gt;
&lt;p&gt;ということで miniecs という CLI を作ったのですが、 まずは操作している様子を貼り付けます。😷 Fuzzy Finder なインクリメンタルサーチが出来る CLI になっていて、ECS クラスタ名・ECS サービス名・コンテナ名を一部入力するとログインしたい環境が選択出来るツールになっています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>App Mesh と ECS によるカナリーリリース構成を検証してみた</title>
      <link>https://jedipunkz.github.io/post/app-mesh-ecs-canary/</link>
      <pubDate>Fri, 10 Dec 2021 13:56:56 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/app-mesh-ecs-canary/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz🚀&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回も &lt;a href=&#34;https://qiita.com/advent-calendar/2021/readyfor&#34;&gt;READYFOR Advent Calendar 2021&lt;/a&gt; の記事として執筆します。&lt;/p&gt;
&lt;h2 id=&#34;今回のテーマ&#34;&gt;今回のテーマ&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jedipunkz.github.io/post/progressive_delivery/&#34;&gt;前回の記事&lt;/a&gt; では ECS 移行後の構成について検討する内容を記しました。Progressive Delivery を実践する上でもその一歩手前の構成と言っていいカナリーリリース構成について、今回は記していきたいと思います。&lt;/p&gt;
&lt;h3 id=&#34;デグレしてしまっていたカナリーリリース&#34;&gt;デグレしてしまっていたカナリーリリース&lt;/h3&gt;
&lt;p&gt;READYFOR では AWS ECS 移行を行い ECS + CodeDeploy による Blue/Green デプロイメントを導入しました。逆に移行前までに出来ていたカナリーリリースが実施できなくなりました。とは言ってもそれまで開発者がカナリーリリースに対して求めていた主な機能はロールバックだったため、ひとまずは Blue/Green デプロイメントで事足りている状況なのですが、今後大きな機能をリリースする際にはトラヒックを徐々に寄せ影響を把握した上でリリース進めるという作業は必要になってくる可能性があります。&lt;/p&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Progressive Delivery の一歩手前の構成を実践する&lt;/li&gt;
&lt;li&gt;大きなリリースのための環境整備&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という意味でも、一回カナリーリリース構成について検討しておこうと考えました。&lt;/p&gt;
&lt;h2 id=&#34;環境構築&#34;&gt;環境構築&lt;/h2&gt;
&lt;h3 id=&#34;今回用意した-terraform-コード&#34;&gt;今回用意した Terraform コード&lt;/h3&gt;
&lt;p&gt;検証で作成した AWS 環境をデプロイするための Terraform コードを下記の場所に置いてあります。参考にしてください。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/tf-appmesh-ecs-canary-release&#34;&gt;https://github.com/jedipunkz/tf-appmesh-ecs-canary-release&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(今回検証で作成したコードは業務上作成したものですが、READYFOR の OSS ポリシーに則り著作権譲渡をうけており、自らのGitHubリポジトリで公開しています。)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;App Mesh&lt;/li&gt;
&lt;li&gt;ECS&lt;/li&gt;
&lt;li&gt;NLB&lt;/li&gt;
&lt;li&gt;Service Discovery&lt;/li&gt;
&lt;li&gt;Envoy&lt;/li&gt;
&lt;li&gt;X-Ray&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;といった技術要素で構成されています。&lt;/p&gt;
&lt;h3 id=&#34;terraform-コードによるデプロイ実施&#34;&gt;Terraform コードによるデプロイ実施&lt;/h3&gt;
&lt;p&gt;上記に記した Terraform コードを使った構成のデプロイ手順を記します。&lt;/p&gt;
&lt;p&gt;前提として Terraform バージョン 1.0.x 系以上をローカルにインストールする必要があります。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#75715e&#34;&gt;# AWS クレデンシャル情報を設定&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ git clone https://github.com/jedipunkz/tf-appmesh-ecs-canary-release
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ cd tf-appmesh-ecs-canary-release
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ terraform plan
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ terraform apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;構成&#34;&gt;構成&lt;/h3&gt;
&lt;p&gt;検証で構築した構成(上記の Terraform コードで構築できる) は下記になります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ECS 以後の構成と Progressive Delivery の調査</title>
      <link>https://jedipunkz.github.io/post/progressive_delivery/</link>
      <pubDate>Thu, 11 Nov 2021 17:28:46 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/progressive_delivery/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は &lt;a href=&#34;https://qiita.com/advent-calendar/2021/readyfor&#34;&gt;READYFOR Advent Calendar 2021&lt;/a&gt; の記事として執筆します。&lt;/p&gt;
&lt;p&gt;READYFOR では 2021 年の夏に AWS ECS へプラットフォーム移行をしました。ECS は自分達の要件を全て満たしてくれ運用コストも極小化できて更に周辺の技術も AWS 公式のものが揃っているので、とても満足している状況です。&lt;/p&gt;
&lt;p&gt;移行を終えたばかりなので「では次のアーキテクチャは？」という話にはまだなっていないのですが、今は準備期間として余裕を持ってスケジューリングできる状態にして頂いているので、SRE チームとしては色々な技術をリサーチしている段階になります。&lt;/p&gt;
&lt;p&gt;今現在は ECS + CodeDeploy を使って Blue/Green デプロイメントを実現しているのですが、よりモダンなデプロイ方式 Progressive Delivery について去年あたりから興味を持っていました。ただ、今までは実際に技術を触るまでには至っていなかったのでこの機会に色々と触ってみたという次第です。&lt;/p&gt;
&lt;p&gt;今までも Blue/Green デプロイメント, Canary リリースとデプロイ方式が複数ありましたが、これらを含む継続的デリバリの次のステップと言われているのが Progressive Delivery です。2020年に Hashicorp 社の &lt;a href=&#34;https://twitter.com/mitchellh&#34;&gt;Mitchell Hashimoto 氏&lt;/a&gt; が来日した際に「今一番気になっているワード」としてあげていましたのが印象的でした。&lt;/p&gt;
&lt;h2 id=&#34;ecs-を使った-canary-リリース&#34;&gt;ECS を使った Canary リリース&lt;/h2&gt;
&lt;p&gt;Progressive Delivery の話をする前に ECS を使った Canary リリースについて少し触れておきます。
(具体的な話についても、どこかのタイミングで記事にできればと思っています)&lt;/p&gt;
&lt;p&gt;AWS App Mesh と ECS, X-Ray を使って下記のような構成を作りました。この構成中の App Mesh の Virtual Router のルーティング情報を修正する形で Canary リリースのトラヒック操作が行えます。ECS 以前は Canary リリースを実現できていて ECS 導入によってそれがデグレした状態だったので、この構成の検証は一つの成果だったと思っていますし、今回話をする Progressive Delivery のひとつ前のステップとも考えています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Go 言語と awscli を使って ECS/Fargate 上でコマンド実行してみた</title>
      <link>https://jedipunkz.github.io/post/ecs-execute-command/</link>
      <pubDate>Tue, 13 Apr 2021 18:35:36 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/ecs-execute-command/</guid>
      <description>&lt;p&gt;こんにちは &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 🚀 です。&lt;/p&gt;
&lt;p&gt;最近、職場では ECS/Fargate でサービスを運用しています。そこで ECS Task 上でコマンドを実行する必要に迫られて幾つか調べたのですが、複数の方法があり検証をしてみました。これには 2021/03 にリリースされたばかりの ECS 上のコンテナでコマンドを実行する機能も含まれています。&lt;/p&gt;
&lt;p&gt;自分たちは自動化する必要があったので Go 言語 (aws-sdk-go) を中心に検証実施しましたが同時に awscli でも動作検証しましたので、その方法をこの記事に記そうかと思います。&lt;/p&gt;
&lt;p&gt;下記の2つの ECS の機能についてそれぞれ Go 言語, awscli で動作検証実施しました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/jp/blogs/news/new-using-amazon-ecs-exec-access-your-containers-fargate-ec2/&#34;&gt;(1) ECS Execute Command (2021/03 リリース)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/reference/ecs/run-task.html&#34;&gt;(2) ECS Run Task&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;用いるツール類&#34;&gt;用いるツール類&lt;/h2&gt;
&lt;p&gt;下記のツールを前提に記事を記します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/sdk-for-go/api/service/ecs/&#34;&gt;aws-sdk-go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/jp/cli/&#34;&gt;awscli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;共通で必要な-taskrolearn&#34;&gt;共通で必要な taskRoleArn&lt;/h2&gt;
&lt;p&gt;まず Task Definition に対して executeRoleArn とは別に TaskRoleArn の付与が必要になります。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-hcl&#34; data-lang=&#34;hcl&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;resource&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;aws_ecs_task_definition&amp;#34; &amp;#34;sample&amp;#34;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  family                   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sample&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cpu                      &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;256&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  memory                   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;512&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  network_mode             &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;awsvpc&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  requires_compatibilities &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;FARGATE&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  execution_role_arn       &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;module&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;ecs_task_execution_role&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;iam_role_arn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  task_role_arn            &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;module&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;ecs_task__role&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;iam_role_arn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  container_definitions    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;template_file&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;container_definition_sample&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;rendered&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;taksRoleArn の内容については &lt;a href=&#34;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task-iam-roles.html&#34;&gt;https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task-iam-roles.html&lt;/a&gt; に情報があり、下記が必要になります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>EKS/Fargate &#43; ArgoCD でボット環境 GitOps 化</title>
      <link>https://jedipunkz.github.io/post/eks-fargate-bot-env/</link>
      <pubDate>Sun, 27 Dec 2020 00:49:51 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/eks-fargate-bot-env/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;仕事ではこれから会社のサービス環境として AWS ECS の導入を始めていくところなのですが、最近の SRE/インフラ界隈のトレンドを自分たちが追うために自分たち SRE が管理しているボット環境を EKS を使って GitOps 化しようということになり色々と準備を進めています。導入までもう一歩のところまで来たので、構成や技術要素についてここに記したいと思います。&lt;/p&gt;
&lt;h2 id=&#34;どんなボットが動いているの&#34;&gt;どんなボットが動いているの？&lt;/h2&gt;
&lt;p&gt;まずボット開発に用いてる言語は Go 言語です。主に aws-sdk-go を使ってボットを開発しています。私達はコミュニケーションツールとして Slack を使っているので Slack ボット化するためには &lt;a href=&#34;https://github.com/slack-go/slack&#34;&gt;slack-go&lt;/a&gt; を使っています。 ただまだボットの数が少なく主に利用されてるのは Ansible を実行するモノです。開発環境へアプリをデプロイするのに Ansible を使っています。もうすぐ ECS 化するので役割はそろそろ終えるのですが&amp;hellip; 利点は開発者だけでなく非エンジニアの方が GitHub のブランチ上のアプリの動作をしたい際に Slack を使って簡単にアプリの動作ができるところです。今後は自動化目的でもっと沢山のボットを開発していきたいです。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;sss&#34; loading=&#34;lazy&#34; src=&#34;../../pix/ansible-bot.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;eksfargate-vs-eksec2&#34;&gt;EKS/Fargate vs EKS/EC2&lt;/h2&gt;
&lt;p&gt;EKS の利用を検討する際に Fargate タイプと EC2 タイプがあります。2020年の今年頭に評価した際には ALB Ingress Controller と HPA のための Metrics Server が正常に動作しない状態だったので、まだ EC2 タイプを選択すべきなのかな&amp;hellip;と考えたのですが AWS 的にも Fargate を推してる気もするし再度評価実施しました。結果ドキュメントもソフトウェアもだいぶ更新されていて ALB Ingress Controller も Metrics Server もあっけなく動作し、今回のボット環境も EKS/Fargte を選択しました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>マルチクラウド対応 SDK の Pulumi を使って Kubernetes を操作</title>
      <link>https://jedipunkz.github.io/post/pulumi/</link>
      <pubDate>Tue, 26 Nov 2019 01:27:22 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/pulumi/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;今日は Pulumi (&lt;a href=&#34;https://www.pulumi.com/&#34;&gt;https://www.pulumi.com/&lt;/a&gt;) について紹介したいと思います。&lt;/p&gt;
&lt;p&gt;最近ではすっかり Terraform がマルチクラウドな IaC ツールとして定着しましたが、巷では AWS CDK を使う現場も増えてきている印象です。AWS CDK は Typescript, Python などのプログラミング言語の中でインフラを定義・操作することができる AWS が提供しているツールです。ただ AWS CDK は名前の通り AWS にのみ対応していて内部的には Cloudformation Template がエキスポートされています。AWS オンリーという点と Cloudformation という点、また 2019 年時点で進化が激しく後方互換性を全く失っているので AWS CDK のアップデートに追従するのに苦労する点、色々ありまだ利用するには早いのかなぁという印象を個人的には持っています。&lt;/p&gt;
&lt;p&gt;そこで今回紹介する Pulumi なのですが CDK 同様にプログラミング言語の中でインフラを定義できて尚且つマルチクラウド対応しています。どちらかというと旧来の SDK の分類だと思うのですが、Terraform 同様にマルチクラウドという点で個人的には以前よりウォッチしていました。&lt;/p&gt;
&lt;p&gt;今回は公式の Getting Started 的なドキュメントに従って作業を進め Kubernetes の上に Pod を起動、その後コードを修正して再デプロイを実施して理解を深めてみたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;作業に必要なソフトウェア&#34;&gt;作業に必要なソフトウェア&lt;/h2&gt;
&lt;p&gt;下記のソフトウェア・ツールが事前にインストールされていることを前提としたいと思います。また macOS を前提に手順を記します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python3, Pip&lt;/li&gt;
&lt;li&gt;Minikube&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pulumi.com/docs/get-started/kubernetes/&#34;&gt;https://www.pulumi.com/docs/get-started/kubernetes/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事前準備&#34;&gt;事前準備&lt;/h2&gt;
&lt;p&gt;まず macOS を使っている場合 Pulumi は下記の通り brew を使ってインストールできます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ECS の構成と Terraform コード化する際の構造化について</title>
      <link>https://jedipunkz.github.io/post/ecs/</link>
      <pubDate>Thu, 17 Oct 2019 18:37:36 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/ecs/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は AWS ECS についてです。直近の仕事で ECS の Terraform コード開発をしていたのですがコードの構造化について考えていました。一枚岩のコードを書いても運用に耐えられるとは考えられません。また ECS を構成するにあたって ECS のネットワークモードとコンテナのロギングについて考えているうちに、どの構成が一番適しているのか？について時間を掛けて考えました。ここではそれらについてまとめたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;terraform-コードの構造化&#34;&gt;Terraform コードの構造化&lt;/h2&gt;
&lt;p&gt;運用の精神的な負担を軽減するという観点で Terraform のコード開発をする上で一番重要なのはコードの構造化だと思います。前回のブログ記事に書いたのですがコードの構造化をする上で下記に留意して考えると良いと思います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;影響範囲&lt;/li&gt;
&lt;li&gt;ステートレスかステートフルか&lt;/li&gt;
&lt;li&gt;安定度&lt;/li&gt;
&lt;li&gt;ライフサイクル&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;結果、具体的に Terraform のコードはどのような構造になるでしょうか。自分は下記のようにコンポーネント化して Terraform の実行単位を別けました。ここは人それぞれだと思いますが、ECS 本体と ECS の周辺 AWS サービスの一般的な物を考慮しつつ、いかにシンプルに構造化するかを考えると自然と下記の区分けになる気がします。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;コンポーネント&lt;/th&gt;
          &lt;th&gt;具体的なリソース&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;ネットワーク&lt;/td&gt;
          &lt;td&gt;vpc, route table, igw, endpoint, subnet&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ECS 本体&lt;/td&gt;
          &lt;td&gt;ecs, alb, autoscaling, cloudwatch, iam&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CI/CD&lt;/td&gt;
          &lt;td&gt;codebuild, codepipeline, ecr, iam&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;パラメータ&lt;/td&gt;
          &lt;td&gt;ssm, kms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;データストア&lt;/td&gt;
          &lt;td&gt;s3, rds, elasticache &amp;hellip;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;vpc や subnet に関して頻繁に更新を掛ける人は少ないのではないでしょうか。よってネットワークは &amp;ldquo;影響範囲&amp;rdquo; を考慮しつつコンポーネントを別けました。また、同じ理由でパラメータ・CI/CD も ECS 本体とは実行単位を別けた方が好ましいと思います。また &amp;ldquo;ステートフルかステートレスか&amp;rdquo; という観点でデータベースやストレージは頻繁に更新する ECS 本体とは別けるべきでしょう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pragmatic Terraform on AWS の内容が素晴らしかったので感想を述べる</title>
      <link>https://jedipunkz.github.io/post/2019/07/27/pragmatic-terraform/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2019/07/27/pragmatic-terraform/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は電子書籍 &amp;lsquo;Pragmatic Terraform on AWS&amp;rsquo; を読んでとても内容が素晴らしかったので紹介させて頂きます。書籍の購入は下記の URL から可能です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://booth.pm/ja/items/1318735&#34;&gt;https://booth.pm/ja/items/1318735&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ブログ記事では書籍の細かい内容については述べません。これから購入される方々が買う意欲を無くすようなブログ記事にしたくないからです。なのでこのブログでは自分が Terraform 運用について感じていた問題点とこの電子書籍がどう解決してくれたのかについて記したいと思います。&lt;/p&gt;
&lt;h2 id=&#34;自分が-terraform-運用で感じていた問題点&#34;&gt;自分が Terraform 運用で感じていた問題点&lt;/h2&gt;
&lt;p&gt;Terraform を使ったインフラコード化と構築は自分の結構経験があるのですが、その構築に使ったコードで構成を運用する難しさはいつも感じていました。Terraform を使った継続的なインフラの運用についてです。具体的には下記のような疑問と言いますか問題点です。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1) どのような実行単位で .tf コードを書くか&lt;/li&gt;
&lt;li&gt;(2) 削除系・修正系の操作も Terraform で行うのか&lt;/li&gt;
&lt;li&gt;(3) ステートフルなインフラとステートレスなインフラの管理方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(1) は &lt;code&gt;terraform plan/apply&lt;/code&gt; を実行するディレクトリの構造についてです。Terraform は同じディレクトリ上にある .tf ファイル全てを読み込んでくれますし一斉にインフラをデプロイすることも可能です。ですが、何かインフラを修正・削除したい場合、削除してはいけないリソースも同ディレクトリ上の .tf ファイルで管理しているわけですから何かしらのミスで大事なインフラに影響を与えてしまう事になります。影響範囲が大きすぎるのです。&lt;/p&gt;
&lt;p&gt;(2) は、&amp;lsquo;初期の構成のみを Terraform で構築自動化する&amp;rsquo; のかどうか、ということになります。構築に使ったコードで継続的に削除系・修正系の操作も行うのか。これも (1) と同様に管理するインフラの規模が大きくなると影響範囲が大きくなり、運用者の精神的負担が増します。&lt;/p&gt;
&lt;p&gt;(3) は RDS, S3 等のステートフルなインフラと、それ以外のステートレスなインフラを同じ .tf コードで管理していいのか、という疑問です。修正・削除が多発するインフラは .tf コードで継続的に運用出来たとしても、RDS, S3 の様な状態が重要になるインフラは滅多に削除・修正操作は通常行いません。これら二種類のインフラを同じように管理してしまっていいのか？という疑問です。&lt;/p&gt;
&lt;p&gt;これらの疑問や思っていた問題点について、この &amp;lsquo;Pragmatic Terraform on AWS&amp;rsquo; は全て解決してくれました。&lt;/p&gt;
&lt;h2 id=&#34;pragmatic-terraform-on-aws-の構成&#34;&gt;Pragmatic Terraform on AWS の構成&lt;/h2&gt;
&lt;p&gt;章ごとの説明は詳細には書きませんが、大体の流れは下記のようになっています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>期待のツール Terrafomer の基本動作方法と問題点</title>
      <link>https://jedipunkz.github.io/post/2019/07/26/terraformer/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2019/07/26/terraformer/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;少し前の話なのですが Google Cloud Platform が Terraformer というツールを出しました。正確には数年前に Google が買収した Waze というサービスのエンジニア達が開発したようです。このツールは GCP, AWS, OpenStack, Kubernetes 等、各クラウド・プラットフォームに対応したリバース Terraform と言えるツールになっていて、構築されたクラウド上の状態を元に terraform の .tf コードと .tfstate ファイルをインポートしてくれます。&lt;code&gt;terraform import&lt;/code&gt; は tfstate のインポートのみに対応してたのでこれは夢のツールじゃないか！ということで当初期待して使い始めたのですが、使ってみる中で幾つかの問題点も見えてきました。今回はその気になった問題点を中心に Terraformer の基本的な動作を説明していきたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;公式サイト&#34;&gt;公式サイト&lt;/h2&gt;
&lt;p&gt;下記の Github アカウントで公開されています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/terraformer&#34;&gt;https://github.com/GoogleCloudPlatform/terraformer&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;requrements&#34;&gt;Requrements&lt;/h2&gt;
&lt;p&gt;Terraformer を動作させるには下記のソフトウェアが必要です。今回は macos を想定して情報を記していますが Linux でも動作します。適宜読み替えてください。インストール方法と設定方法はここでは割愛させて頂きます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;macos&lt;/li&gt;
&lt;li&gt;homebrew&lt;/li&gt;
&lt;li&gt;terraform&lt;/li&gt;
&lt;li&gt;awscli&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;今回の前提のクラウドプラットフォーム&#34;&gt;今回の前提のクラウドプラットフォーム&lt;/h2&gt;
&lt;p&gt;自分がいつも使っているプラットフォームということで今回は aws を前提に記事を書いていきます。ここが結構肝心なところで、Google Cloud Platform が開発したこともあり GCP 向けの機能が一番 Feature されているように読み取れます。つまり aws を対象とした Terraformer の機能が一部追いついていない点も後に述べたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;動作させるまでの準備&#34;&gt;動作させるまでの準備&lt;/h2&gt;
&lt;p&gt;Terraform と同様に Terraformer でも動作せせるディレクトリが必要になります。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir working_dir
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd working_dir
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Terraformer を動作させるために Terraform の plugin が必要です。先に述べたようにここでは &amp;lsquo;aws&amp;rsquo; Plugin をダウンロードします。そのために init.tf を下記の通り作成します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Consul Helm Chart で Kubernetes 上に Consul をデプロイ</title>
      <link>https://jedipunkz.github.io/post/consul-helm-chart/</link>
      <pubDate>Fri, 26 Apr 2019 17:08:02 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/consul-helm-chart/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は Hashicorp の Consul クラスタを Kubernetes 上で稼働させる方法について調べてみました。&lt;/p&gt;
&lt;p&gt;Hashicorp Consul はサービスディスカバリが行えるソフトウェアで、私も以前居た職場で利用していました。アプリケーション間で互いに接続先を確認し合う事が出来ます。以前構築した Consul クラスタはインスタンス上に直に起動していたのですが最近だとどうやってデプロイするのか興味を持ち Kubernetes 上にデプロイする方法を調べた所 Helm を使って簡単にデプロイ出来る事が分かりました。&lt;/p&gt;
&lt;p&gt;また今回は minikube を使って複数のレプリカを起動するようにしていますが、Helm Chart を用いると Kubernetes のノード毎に Consul Pod が1つずつ起動するようになっていて、ノードの障害を考慮した可用性という点でも優れているなぁと感じました。また Kubernetes の Pod ですのでプロセスが落ちた際に即座に再起動が行われるという点でも優れています。勿論 Consul クラスタの Leader が落ちた場合には Leader Election (リーダ昇格のための選挙) が行われ、直ちに隣接した Kubernetes ノード上の Consul Pod がリーダーに昇格します。といった意味でも Kubernetes 上に Consul をデプロイするという考えは優れているのではないでしょうか。&lt;/p&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements&lt;/h3&gt;
&lt;p&gt;下記のソフトウェアが事前に必要です。この手順では予めこれらがインストールされていることとして記していきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;minikube&lt;/li&gt;
&lt;li&gt;kubectl&lt;/li&gt;
&lt;li&gt;helm&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;consul-クラスタ起動までの手順&#34;&gt;Consul クラスタ起動までの手順&lt;/h3&gt;
&lt;p&gt;早速ですが手順を記していきます。&lt;/p&gt;
&lt;p&gt;Hashicorp の Github にて Consul の Helm Chart が公開されています。&lt;code&gt;helm search&lt;/code&gt; しても出てきますが、今回は Github のものを用いました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Istio Sidecar Injection を理解する</title>
      <link>https://jedipunkz.github.io/post/istio-sidecar-injection/</link>
      <pubDate>Wed, 24 Apr 2019 22:55:45 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/istio-sidecar-injection/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;前回の記事 &lt;a href=&#34;https://jedipunkz.github.io/blog/2018/12/31/istio/&#34;&gt;「Istio, Helm を使って Getting Started 的なアプリをデプロイ」&lt;/a&gt;で kubernetes 上で istio をインストールし sidecar injection を有効化しサンプルアプリケーションを起動しました。その結果、sidecar 的に envoy コンテナが起動するところまで確認しました。今回はもう少し単純な pod を用いて &amp;lsquo;sidecar injection&amp;rsquo; の中身をもう少しだけ深掘りして見ていきたいと思います。&lt;/p&gt;
&lt;h3 id=&#34;rquirements&#34;&gt;Rquirements&lt;/h3&gt;
&lt;p&gt;記事と同等の動きを確認するために下記のソフトウェアが必要になります。
それぞれのソフトウェアは事前にインストールされた前提で記事を記していきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;macos or linux os&lt;/li&gt;
&lt;li&gt;kubectl&lt;/li&gt;
&lt;li&gt;istioctl&lt;/li&gt;
&lt;li&gt;minikube&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;参考-url&#34;&gt;参考 URL&lt;/h3&gt;
&lt;p&gt;下記の istio 公式ドキュメントを参考に動作確認しました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/additional-setup/sidecar-injection/&#34;&gt;https://istio.io/docs/setup/kubernetes/additional-setup/sidecar-injection/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/docs/setup/kubernetes/additional-setup/sidecar-injection/&#34;&gt;https://istio.io/docs/setup/kubernetes/additional-setup/sidecar-injection/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minikube-で-kubenetes-をデプロイ&#34;&gt;minikube で kubenetes をデプロイ&lt;/h3&gt;
&lt;p&gt;前回同様に minikube 上で動作を確認していきます。パラメータは適宜、自分の環境に読み替えてください。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube start --memory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8192&lt;/span&gt; --cpus&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; --kubernetes-version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v1.10.0 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --extra-config&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-cert-file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/minikube/certs/ca.crt&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --extra-config&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;controller-manager.cluster-signing-key-file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/minikube/certs/ca.key&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  --vm-driver&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;virtualbox
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;istio-を稼働させる&#34;&gt;istio を稼働させる&lt;/h3&gt;
&lt;p&gt;下記のコマンドを用いてカレントディレクトリに istio のサンプル yaml が入ったフォルダを展開します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -L https://git.io/getLatestIstio | sh -
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;次に下記のコマンドで kubernetes 上に istio をインストールします。
istio コンテナ間の通信をプレインテキスト or TLS で行うよう istio-demo.yml を apply しています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Istio, Helm を使って Getting Started 的なアプリをデプロイ</title>
      <link>https://jedipunkz.github.io/post/2018/12/31/istio/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2018/12/31/istio/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;最近は kubernetes を触ってなかったのですが Istio や Envoy 等 CNCF 関連のソフトウェアの記事をよく見かけるようになって、少し理解しておいたほうがいいかなと思い Istio と Minikube を使って Getting Started 的な事をやってみました。Istio をダウンロードすると中にサンプルアプリケーションが入っているのでそれを利用してアプリのデプロイまでを行ってみます。&lt;/p&gt;
&lt;p&gt;Istio をダウンロードするとお手軽に Istio 環境を作るための yaml ファイルがあり、それを kubectl apply することで Istio 環境を整えられるのですが、ドキュメントにプロダクション環境を想定した場合は Helm Template を用いた方がいいだろう、と記載あったので今回は Helm Template を用いて Istio 環境を作ります。&lt;/p&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;p&gt;下記の環境でテストを行いました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;macos Mojave&lt;/li&gt;
&lt;li&gt;minikube v0.32.0&lt;/li&gt;
&lt;li&gt;kubectl v1.10.3&lt;/li&gt;
&lt;li&gt;helm v2.12.1&lt;/li&gt;
&lt;li&gt;virtualbox&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;準備&#34;&gt;準備&lt;/h2&gt;
&lt;h3 id=&#34;kubectl-と-helm-のインストール&#34;&gt;kubectl と helm のインストール&lt;/h3&gt;
&lt;p&gt;kubctl と helm をインストールします。両者共に homebrew でインストールします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install kubernetes-cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;brew install kubernetes-helm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;minikube-のインストールと起動&#34;&gt;minikube のインストールと起動&lt;/h3&gt;
&lt;p&gt;minikube をインストールして起動します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker,Test-Kitchen,Ansible でクラスタを構成する</title>
      <link>https://jedipunkz.github.io/post/test-kitchen-cluster/</link>
      <pubDate>Sun, 02 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/test-kitchen-cluster/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;以前、&amp;ldquo;Test-Kitchen, Docker で Ansible Role 開発サイクル高速化！&amp;rdquo; ってタイトルで Ansible Role の開発を test-kitchen を使って行う方法について記事にしたのですが、やっぱりローカルで Docker コンテナ立ち上げてデプロしてテストして.. ってすごく楽というか速くて今の現場でも便利につかっています。前の記事の URL は下記です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jedipunkz.github.io/blog/2016/07/14/test-kitchen-with-ansible/&#34;&gt;https://jedipunkz.github.io/blog/2016/07/14/test-kitchen-with-ansible/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;最近？は ansible container って技術もあるけど、僕らが Docker 使う目的はコンテナでデプロイするのではなくて単に Ansible を実行するローカル環境が欲しいってこととか、Serverspec をローカル・実機に実行する環境が欲しいってことなので、今でも test-kitchen 使っています。&lt;/p&gt;
&lt;p&gt;で、最近になって複数ノードの構成の Ansible Role を test-kitchen, Docker を使って開発できることに気がついたので記事にしようと思います。これができるとローカルで Redis Master + Redis Slave(s) + Sentinel って環境も容易にできると思います。&lt;/p&gt;
&lt;h2 id=&#34;使うソフトウェア&#34;&gt;使うソフトウェア&lt;/h2&gt;
&lt;p&gt;前提は macOS ですが Linux マシンでも問題なく動作するはずです。&lt;/p&gt;
&lt;p&gt;ほぼ前回と同じです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ansible&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;test-kitchen&lt;/li&gt;
&lt;li&gt;kitchen-docker (test-kitchen ドライバ)&lt;/li&gt;
&lt;li&gt;kitchen-ansible (test-kitchen ドライバ)&lt;/li&gt;
&lt;li&gt;Serverspec&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;
&lt;p&gt;ソフトウェアののインストール方法については前回の記事を見てもらうこととして割愛します。&lt;/p&gt;
&lt;h2 id=&#34;test-kitchen-の環境を作る&#34;&gt;test-kitchen の環境を作る&lt;/h2&gt;
&lt;p&gt;test-kitchen の環境を作ります。&amp;lsquo;kitchen init&amp;rsquo; を実行して基本的には生成された .kitchen.yml を弄るんじゃなくて .kitchen.local.yml を修正していきます。こちらの記述が必ず上書きされて優先されます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GCP ロードバランサと GKE クラスタを Terraform を使って構築する</title>
      <link>https://jedipunkz.github.io/post/gke-lb/</link>
      <pubDate>Thu, 13 Apr 2017 14:53:37 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/gke-lb/</guid>
      <description>GCP ロードバランサと GKE クラスタを Terraform を使って構築自動化</description>
    </item>
    <item>
      <title>Serverless on Kubernetes : Fission を使ってみた</title>
      <link>https://jedipunkz.github.io/post/serverless-fission/</link>
      <pubDate>Sun, 12 Feb 2017 14:55:01 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/serverless-fission/</guid>
      <description>Kubernetes 上で Serverless を実現する Fission を使ってみた</description>
    </item>
    <item>
      <title>Kubernetes Deployments を使ってみた！</title>
      <link>https://jedipunkz.github.io/post/kubernetes-deployments/</link>
      <pubDate>Fri, 13 Jan 2017 20:29:07 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/kubernetes-deployments/</guid>
      <description>Kubernetes Replication Controller の次世代版 Deployments を使ってみました</description>
    </item>
    <item>
      <title>fluentd-sidecar-gcp と Kubernetes Volumes で Cloud Logging ログ転送</title>
      <link>https://jedipunkz.github.io/post/fluentd-sidecar-gcp/</link>
      <pubDate>Thu, 29 Dec 2016 09:43:18 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/fluentd-sidecar-gcp/</guid>
      <description>fluentd-sidecar-gcp と Kubernetes Volumes で Cloud Logging へログ転送</description>
    </item>
    <item>
      <title>Google Cloud CDN を使ってみた</title>
      <link>https://jedipunkz.github.io/post/cloud-cdn/</link>
      <pubDate>Thu, 29 Dec 2016 09:32:49 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/cloud-cdn/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;今回は Google Cloud Platform の Google CloudCDN について調べてみたので記したいと思います。&lt;/p&gt;
&lt;p&gt;CloudCDN は GCP のロードバランサのバックエンドサービスに紐付けられるサービスです。このバックエンドサービスで CloudCDN を有効にしていると CDN サービスを機能させることが出来ます。先に書いておくとこの CloudCDN はとてもシンプルで扱いやすいサービスだと判りました。高機能な他の CDN サービスと比べると機能が足らない感ありますが、必要最低限なところを抑えているのと、価格がとても安いです。(価格は下記の URL 参照)&lt;/p&gt;
&lt;p&gt;価格表 : &lt;a href=&#34;https://cloud.google.com/cdn/pricing&#34;&gt;https://cloud.google.com/cdn/pricing&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;構成と構成の特徴です。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+----------+                                    +---------+
| instance |--+                               +-| EndUser |
+----------+  |  +------------+  +----------+ | +---------+
              +--|LoadBalancer|--| CloudCDN |-+-| EndUser |
+----------+  |  +------------+  +----------+ | +---------+
| instance |--+                               +-| EndUser |
+----------+                                    +---------+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;コンテンツが初めてリクエストされた場合キャッシュミスする&lt;/li&gt;
&lt;li&gt;キャッシュミスした際に近くにあるキャッシュからコンテンツを取得しようと試みる&lt;/li&gt;
&lt;li&gt;近くのキャッシュがコンテンツがある場合、最初のキャッシュにコンテンツが送信される&lt;/li&gt;
&lt;li&gt;近くのキャッシュにコンテンツがない場合、HTTP ロードバランサにリクエストが転送される&lt;/li&gt;
&lt;li&gt;その後のリクエストはキャッシュが応答する(キャッシュヒット)&lt;/li&gt;
&lt;li&gt;キャッシュ間のフィルは EndUser のリクエストに応じて実行される&lt;/li&gt;
&lt;li&gt;キャッシュを事前に読み込むことできない&lt;/li&gt;
&lt;li&gt;キャッシュは世界各地に配置されている&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cloudcdn-を導入する方法&#34;&gt;CloudCDN を導入する方法&lt;/h2&gt;
&lt;p&gt;導入する方法は簡単で下記のとおりです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>coreos の etcd operator を触ってみた</title>
      <link>https://jedipunkz.github.io/post/etcd-operator/</link>
      <pubDate>Sun, 27 Nov 2016 21:00:45 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/etcd-operator/</guid>
      <description>coreos が最近アナウンスした etcd operator を触ってみた</description>
    </item>
    <item>
      <title>Helm を使って Kubernetes を管理する</title>
      <link>https://jedipunkz.github.io/post/helm/</link>
      <pubDate>Sun, 20 Nov 2016 11:27:00 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/helm/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;今回は Helm という kubernetes のパッケージマネージャ的なソフトウェアを使ってみたので記事にしたいと思います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公式サイト : &lt;a href=&#34;https://helm.sh/&#34;&gt;https://helm.sh/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes を仕事で使っているのですが &amp;ldquo;レプリケーションコントローラ&amp;rdquo; や &amp;ldquo;サービス&amp;rdquo; といった単位を使って Pod, Service を管理しています。Helm を使うことでこれらの管理方法が変わるのか調べたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;依存するソフトウェア&#34;&gt;依存するソフトウェア&lt;/h2&gt;
&lt;p&gt;今回は MacOS を使って環境を整えます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;virtualbox&lt;/li&gt;
&lt;li&gt;minikube&lt;/li&gt;
&lt;li&gt;kubectl&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらのソフトウェアをインストールしていきます。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ brew cask install virtualbo
$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.12.2/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/
$ brew install kubectl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;minikube を使って簡易的な kubernetes 環境を起動します。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ minikube start
$ eval $(minikube docker-env)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;helm-を使ってみる&#34;&gt;Helm を使ってみる&lt;/h2&gt;
&lt;p&gt;Helm は Charts という単位で Kubernetes をパッケージングします。Charts の一覧を見てみましょう。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ helm search
NAME                    VERSION         DESCRIPTION
stable/drupal           0.3.7           One of the most versatile open source content m...
stable/factorio         0.1.1           Factorio dedicated server.
stable/ghost            0.4.0           A simple, powerful publishing platform that all...
stable/jenkins          0.1.1           A Jenkins Helm chart for Kubernetes.
stable/joomla           0.4.0           PHP content management system (CMS) for publish...
stable/mariadb          0.5.3           Chart for MariaDB
stable/mediawiki        0.4.0           Extremely powerful, scalable software and a fea...
stable/memcached        0.4.0           Chart for Memcached
stable/minecraft        0.1.0           Minecraft server
stable/mysql            0.2.1           Chart for MySQL
stable/phpbb            0.4.0           Community forum that supports the notion of use...
stable/postgresql       0.2.0           Chart for PostgreSQL
stable/prometheus       1.3.1           A Prometheus Helm chart for Kubernetes. Prometh...
stable/redis            0.4.1           Chart for Redis
stable/redmine          0.3.5           A flexible project management web application.
stable/spark            0.1.1           A Apache Spark Helm chart for Kubernetes. Apach...
stable/spartakus        1.0.0           A Spartakus Helm chart for Kubernetes. Spartaku...
stable/testlink         0.4.0           Web-based test management system that facilitat...
stable/traefik          1.1.0-rc3-a     A Traefik based Kubernetes ingress controller w...
stable/uchiwa           0.1.0           Dashboard for the Sensu monitoring framework
stable/wordpress        0.3.2           Web publishing platform for building blogs and ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;各アプリケーションの名前で Charts が管理されていることが分かります。
ここでは stable/mysql を使って kubernetes の中に MySQL 環境を作ってみます。まず stable/mysql に設定できるパラメータ一覧を取得します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>kubernetes1.4 で実装された ScheduledJob を試してみた！</title>
      <link>https://jedipunkz.github.io/post/kubernetes-scheduledjob/</link>
      <pubDate>Thu, 03 Nov 2016 09:08:48 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/kubernetes-scheduledjob/</guid>
      <description>&lt;p&gt;こんにちは、@jedipunkz です。今回は Kubernetes1.4 から実装された ScheduledJob を試してみたのでその内容を記したいと思います。&lt;/p&gt;
&lt;p&gt;ScheduledJob はバッチ的な処理を Kubernetes の pod を使って実行するための仕組みです。現在は alpha バージョンとして実装されています。
kubernetes の pod, service は通常、永続的に立ち上げておくサーバなどを稼働させるものですが、それに対してこの scheduledJob は cron 感覚でバッチ処理を pod に任せることができます。&lt;/p&gt;
&lt;p&gt;Alpha バージョンということで今回の環境構築は minikube を使って簡易的に Mac 上に構築しました。Docker がインストールされていれば Linux でも環境を作れます。&lt;/p&gt;
&lt;h2 id=&#34;参考-url&#34;&gt;参考 URL&lt;/h2&gt;
&lt;p&gt;今回利用する yaml ファイルなどは下記のサイトを参考にしています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kubernetes.io/docs/user-guide/scheduled-jobs/&#34;&gt;http://kubernetes.io/docs/user-guide/scheduled-jobs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;https://github.com/kubernetes/minikube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;p&gt;私の環境では下記の環境を利用しました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OSX&lt;/li&gt;
&lt;li&gt;Docker-machine or Docker for Mac&lt;/li&gt;
&lt;li&gt;minikube&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-14-以降の構成を-minikube-で構築する&#34;&gt;kubernetes 1.4 以降の構成を minikube で構築する&lt;/h2&gt;
&lt;p&gt;まず minikube のインストールを行います。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.12.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;早速 minikube を起動します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Minikube で簡易 kubernetes 環境構築</title>
      <link>https://jedipunkz.github.io/post/minikube/</link>
      <pubDate>Mon, 25 Jul 2016 23:18:16 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/minikube/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;kubernetes の環境を簡易的に作れる Minikube (&lt;a href=&#34;https://github.com/kubernetes/minikube&#34;&gt;https://github.com/kubernetes/minikube&lt;/a&gt;) が2ヶ月前ほどにリリースになっていました。簡単ですが少し触ってみたのでその際のメモを記したいと思います。VirtualBox もしくは VMware Fusion がインストールされていればすぐにでも稼働可能です。私は Kubernetes 初心者ですが何も考えずに kubernetes を動かすことが出来ました。&lt;/p&gt;
&lt;h2 id=&#34;前提&#34;&gt;前提&lt;/h2&gt;
&lt;p&gt;前提として下記の環境が必要になります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OSX がインストールされていること&lt;/li&gt;
&lt;li&gt;VirtualBox もしくは VMware Fusion がインストールされていること&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;minikube-をインストール&#34;&gt;minikube をインストール&lt;/h2&gt;
&lt;p&gt;minikube をインストールします。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.6.0/minikube-darwin-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;kubetl-をインストール&#34;&gt;kubetl をインストール&lt;/h2&gt;
&lt;p&gt;次に kubectl をインストールします。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ curl -k -o kubectl https://kuar.io/darwin/kubectl &amp;amp;&amp;amp; chmod +x kubectl &amp;amp;&amp;amp; sudo mv kubectl /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;minikube-で-kurbernates-を稼働&#34;&gt;Minikube で Kurbernates を稼働&lt;/h2&gt;
&lt;p&gt;Minikube を使って Kubernetes を稼働してみます。下記のコマンドを実行すると Virtualbox 上で仮想マシンが稼働し Kubernetes 一式も立ち上がります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Go言語とInfluxDBで監視のコード化</title>
      <link>https://jedipunkz.github.io/post/influxdb-go/</link>
      <pubDate>Sat, 23 Jul 2016 02:40:11 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/influxdb-go/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今日は Go 言語でサーバのメトリクスデータを InfluxDB に入れてリソース監視を行う方法について書きます。&lt;/p&gt;
&lt;p&gt;Ansible, Terraform, Chef などのソフトウェアを使ってインフラを定義するのが当たり前になった現在ですが、本当の意味でのソフトウェアによるインフラの定義ってなんだろと最近考えています。aws-sdk や fog などを使ったネイティブな言語でインフラを定義することの意味もあるように感じているからです。某サービスプロバイダのエンジニアはこうした言語によるインフラの定義の一番大きなメリットとして &amp;ldquo;再利用性&amp;rdquo; をあげていました。こうしたソフトウェアによるインフラの定義や構成を行う上で監視についてもコード化できるのでは？と考えて今回の記事に至りました。&lt;/p&gt;
&lt;h2 id=&#34;使うモノ&#34;&gt;使うモノ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/influxdata/influxdb/tree/master/client&#34;&gt;https://github.com/influxdata/influxdb/tree/master/client&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;公式の InfluxDB Go Client です。InfluxDB 自体が Go 言語で書かれていますがクライアントも Go 言語で記述することができます。ここにあるサンプルコードをすこしいじって、今回の記事を書こうと思います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/shirou/gopsutil&#34;&gt;https://github.com/shirou/gopsutil&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;@shirou さんが作られた psutil の Go 言語版です。CPU, Mem などリソースをモニタするのに便利なので利用します。&lt;/p&gt;
&lt;h2 id=&#34;環境構築&#34;&gt;環境構築&lt;/h2&gt;
&lt;p&gt;環境を作っていきます。InfluxDB と Chronograf を構築するのですが Docker で構築するのが簡単なのでこれを利用します。Chronograf は InfluxDB 内のデータを可視化するためのソフトウェアです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;InfluxDB の起動&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;InfluxDB のコンテナを起動します。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -p 8083:8083 -p 8086:8086 \
      -v $PWD:/var/lib/influxdb \
      influxdb
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Chronograf の起動&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Chronograf のコンテナを起動します。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -p 10000:10000 chronograf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;この時点で http://${DOCKER_HOST}:10000/ にアクセスすると Chronograf の UI を確認できます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Test-Kitchen, Docker で Ansible Role 開発サイクル高速化！</title>
      <link>https://jedipunkz.github.io/post/test-kitchen-with-ansible/</link>
      <pubDate>Thu, 14 Jul 2016 09:10:57 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/test-kitchen-with-ansible/</guid>
      <description>test-kitchen with ansible, docker</description>
    </item>
    <item>
      <title>イベントドリブンな StackStorm で運用自動化</title>
      <link>https://jedipunkz.github.io/post/stackstorm/</link>
      <pubDate>Sat, 02 Jul 2016 23:37:17 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/stackstorm/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は StackStorm (&lt;a href=&#34;https://stackstorm.com/&#34;&gt;https://stackstorm.com/&lt;/a&gt;) というイベントドリブンオートメーションツールを使ってみましたので
紹介したいと思います。&lt;/p&gt;
&lt;p&gt;クラウドとプロビジョニングツールの登場で昨今はエンジニアがほぼ全ての操作を自動化出来るようになりました。
ですが監視についてはどうでしょうか？監視システムを自動で構築することが出来ても障害発生時に対応を行う
のは手動になっていませんでしょうか。もちろんクラスタ組んでいれば大抵のアラートは放置出来ますが、クラスタ
を組むことが出来ないような箇所はクラウドを使ってもどうしても出てきます。&lt;/p&gt;
&lt;p&gt;そこで登場するのが今回紹介する StackStorm のようなツールかなぁと考えるようになりました。&lt;/p&gt;
&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;
&lt;p&gt;インストール手順は下記の URL にあります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.stackstorm.com/install/index.html&#34;&gt;https://docs.stackstorm.com/install/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;自分は CentOS7 を使ったので下記のワンライナーでインストールできました。
password は任意のものを入れてください。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;curl -sSL https://stackstorm.com/packages/install.sh | bash -s -- --user=st2admin --password=foo
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MongoDB, postgreSQL が依存してインストールされます。&lt;/p&gt;
&lt;p&gt;80番ポートで下記のような WEB UI も起動します。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.io/pix/stackstorm.png&#34; width=&#34;70%&#34;&gt;
&lt;h2 id=&#34;stackstorm-の基本&#34;&gt;StackStorm の基本&lt;/h2&gt;
&lt;p&gt;基本を知るために幾つかの要素について説明していきます。&lt;/p&gt;
&lt;p&gt;まず CLI で操作するために TOKEN を取得して環境変数にセットする必要があります。
上記で設定したユーザ名・パスワードを入力してください。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export ST2_AUTH_TOKEN=`st2 auth -t -p foo st2admin`
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Action&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Action はイベントが発生した際に実行できるアクションになります。早速アクションの一覧を取得してみましょう。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ st2 action list
+---------------------------------+---------+-------------------------------------------------------------+
| ref                             | pack    | description                                                 |
+---------------------------------+---------+-------------------------------------------------------------+
| chatops.format_execution_result | chatops | Format an execution result for chatops                      |
| chatops.post_message            | chatops | Post a message to stream for chatops                        |
| chatops.post_result             | chatops | Post an execution result to stream for chatops              |
&amp;lt;省略&amp;gt;
| core.http                       | core    | Action that performs an http request.                       |
| core.local                      | core    | Action that executes an arbitrary Linux command on the      |
|                                 |         | localhost.                                                  |
| core.local_sudo                 | core    | Action that executes an arbitrary Linux command on the      |
|                                 |         | localhost.                                                  |
| core.remote                     | core    | Action to execute arbitrary linux command remotely.         |
| core.remote_sudo                | core    | Action to execute arbitrary linux command remotely.         |
| core.sendmail                   | core    | This sends an email                                         |
| core.windows_cmd                | core    | Action to execute arbitrary Windows command remotely.       |
&amp;lt;省略&amp;gt;
| linux.cp                        | linux   | Copy file(s)                                                |
| linux.diag_loadavg              | linux   | Diagnostic workflow for high load alert                     |
| linux.dig                       | linux   | Dig action                                                  |
&amp;lt;省略&amp;gt;
| st2.kv.get                      | st2     | Get value from datastore                                    |
| st2.kv.set                      | st2     | Set value in datastore                                      |
+---------------------------------+---------+-------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上記のように Linux のコマンドや ChatOps, HTTP でクエリを投げるもの、Key Value の読み書きを行うモノまであります。
上記はかなり咲楽して貼り付けたので本来はもっと沢山のアクションがあります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vagrant で Mesosphere DC/OS を構築</title>
      <link>https://jedipunkz.github.io/post/mesos-dcos-vagrant/</link>
      <pubDate>Tue, 21 Jun 2016 17:05:25 +0900</pubDate>
      <guid>https://jedipunkz.github.io/post/mesos-dcos-vagrant/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は DC/OS (&lt;a href=&#34;https://dcos.io/&#34;&gt;https://dcos.io/&lt;/a&gt;) を Vagrant を使って構築し評価してみようと思います。
DC/OS はその名の通りデータセンタ OS として利用されることを期待され開発された OS で内部で
Docker と Mesos が稼働しています。&lt;/p&gt;
&lt;p&gt;一昔前に Mesos のマルチノード構成は構築したことあったのですが、DC/OS はデプロイ方法が全く変わっていました。
はじめに想定する構成から説明していきます。&lt;/p&gt;
&lt;h2 id=&#34;想定する構成&#34;&gt;想定する構成&lt;/h2&gt;
&lt;p&gt;本来 DC/OS は public, private ネットワーク構成ですが利用するレポジトリではこのような構成が想定されていました。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+----+ +----+ +----+ +------+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| m1 | | a1 | | p1 | | boot |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+----+ +----+ +----+ +------+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|      |      |      |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+------+------+------+--------- 192.168.65/24
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;各ノードは下記の通り動作します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;m1 : Mesos マスタ, Marathon&lt;/li&gt;
&lt;li&gt;a1 : Mesos スレーブ(Private Agent)&lt;/li&gt;
&lt;li&gt;p1 : Mesos スレーブ(Public Agent)&lt;/li&gt;
&lt;li&gt;boot : DC/OS インストレーションノード&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;p&gt;Vagrant が動作するマシンであれば問題ないと思いますが私は下記の構成で利用しました。
比較的たくさんのマシンリソースを使うのでメモリ 8GB はほしいところです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chronograf, Telegraf, Influxdbでサーバとコンテナ情報を可視化する</title>
      <link>https://jedipunkz.github.io/post/2015/12/28/chronograf-telegraf-influxdb/</link>
      <pubDate>Mon, 28 Dec 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/12/28/chronograf-telegraf-influxdb/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Influxdb が Influxdata (&lt;a href=&#34;https://influxdata.com/&#34;&gt;https://influxdata.com/&lt;/a&gt;) として生まれ変わり公式の
メトリクス送信エージェント Telegraf と可視化ツール Chronograf をリリースしたので
使ってみました。&lt;/p&gt;
&lt;p&gt;3つのツールの役割は下記のとおりです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chronograf : 可視化ツール, Grafana 相当のソフトウェアです&lt;/li&gt;
&lt;li&gt;Telegraf : メトリクス情報を Influxdb に送信するエージェント&lt;/li&gt;
&lt;li&gt;Influxdb : メトリクス情報を格納する時系列データベース&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以前に cAdvisor, influxdb, grafana を使って Docker コンテナのメトリクスを可視
化する記事を書きましたが telegraf を使うとサーバ情報と合わせて Docker コンテナ
のメトリクスも influxdb に送信することが出来ます。個人的にはそのコンテナ情報の
扱いもサーバ情報と同様に扱ってくれる点に期待しつつ、評価してみました。&lt;/p&gt;
&lt;h2 id=&#34;今回の環境&#34;&gt;今回の環境&lt;/h2&gt;
&lt;p&gt;今回は Ubuntu 15.04 vivid64 を使ってテストしています。&lt;/p&gt;
&lt;h2 id=&#34;influxdb-をインストールして起動&#34;&gt;influxdb をインストールして起動&lt;/h2&gt;
&lt;p&gt;最新リリース版の deb パッケージが用意されていたのでこれを使いました。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget http://influxdb.s3.amazonaws.com/influxdb_0.9.5.1_amd64.deb
sudo dpkg -i influxdb_0.9.5.1_amd64.deb
sudo service influxdb start
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;telegraf-のインストールと起動&#34;&gt;telegraf のインストールと起動&lt;/h2&gt;
&lt;p&gt;こちらも deb パッケージで。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget http://get.influxdb.org/telegraf/telegraf_0.2.4_amd64.deb
sudo dpkg -i telegraf_0.2.4_amd64.deb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;コンフィギュレーションですが今回は CPU, Disk, Net, Docker のメトリクス情報を送
信するようにしました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weave を使った Docker ネットワーク</title>
      <link>https://jedipunkz.github.io/post/2015/12/22/weave-docker-network/</link>
      <pubDate>Tue, 22 Dec 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/12/22/weave-docker-network/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は Weave というコンテナ間のネットワークを提供してくれる Docker のネットワークプラ
グインを使ってみました。下記のような沢山の機能があるようです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fast Data Path&lt;/li&gt;
&lt;li&gt;Docker Network Plugin&lt;/li&gt;
&lt;li&gt;Security&lt;/li&gt;
&lt;li&gt;Dynamic Netwrok Attachment&lt;/li&gt;
&lt;li&gt;Service Binding&lt;/li&gt;
&lt;li&gt;Fault Tolerance&lt;/li&gt;
&lt;li&gt;etc &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この記事では上から幾つか抜粋して、Weave ってどのように動かせるのか？を解説します。
そこから Weave が一体ナニモノなのか理解できればなぁと思います。&lt;/p&gt;
&lt;h2 id=&#34;vagrant-を使った構成&#34;&gt;Vagrant を使った構成&lt;/h2&gt;
&lt;p&gt;この記事では下記の構成を作って色々と試していきます。使う技術は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vagrant&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Weave&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;です。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+---------------------+ +---------------------+ +---------------------+
| docker container a1 | | docker container a2 | | docker container a3 |
+---------------------+ +---------------------+ +---------------------+
|    vagrant host 1   | |    vagrant host 2   | |    vagrant host 3   |
+---------------------+-+---------------------+-+---------------------+
|                          Mac or Windows                             |
+---------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;特徴としては&lt;/p&gt;</description>
    </item>
    <item>
      <title>CodeDeploy, S3 を併用して CircleCI により VPC にデプロイ</title>
      <link>https://jedipunkz.github.io/post/2015/11/15/circleci-codedeploy/</link>
      <pubDate>Sun, 15 Nov 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/11/15/circleci-codedeploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;最近、業務で CircleCI を扱っていて、だいぶ &amp;ldquo;出来ること・出来ないこと&amp;rdquo; や &amp;ldquo;出来ないこと
に対する回避方法&amp;rdquo; 等のノウハウが若干溜まってきたので共有したいなと思います。&lt;/p&gt;
&lt;h2 id=&#34;この記事の前提&#34;&gt;この記事の前提&amp;hellip;&lt;/h2&gt;
&lt;p&gt;ここでは CodeDeploy の設定方法や、CircleCIの設定方法等に関しては記述しませ
ん。あくまで、Tips 的な内容にしています。また運用する上で想定できる問題点と、
それの回避方法等&amp;hellip;についてまとめています。&lt;/p&gt;
&lt;h2 id=&#34;cirlceci-と併用するサービスについて&#34;&gt;CirlceCI と併用するサービスについて&lt;/h2&gt;
&lt;p&gt;CircleCI は Github と連携してレポジトリ内の制御ファイル circle.yml に従ってテ
スト・ビルド・デプロイを実施してくれる CI サービスです。ただ CircleCI は自分た
ちの管理しているシステム外にあるので、AWS VPC を用いていると VPC 内のプライベー
トインスタンスにデプロイするのが難しいです。プロキシ挟んで・・ってことは出来そ
うですがプロキシの運用もしたくない、AWS のインフラリソースに任せることが出来た
らインスタンス・インスタンス上のミドルウェアを運用しなくて済むので運用コストが
省けそう。ってことで&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS S3 (&lt;a href=&#34;https://aws.amazon.com/jp/s3/&#34;&gt;https://aws.amazon.com/jp/s3/&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;AWS CodeDeploy (&lt;a href=&#34;https://aws.amazon.com/jp/codedeploy/&#34;&gt;https://aws.amazon.com/jp/codedeploy/&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を併用することを考えました。&lt;/p&gt;
&lt;p&gt;S3 は皆さんご存知のオブジェクトストレージです。CircleCI 用のバケットを作って、
ビルドした結果を格納します。私の務めている会社ではプログラミング言語として
Scala を用いているので SBT というツールを使ってビルドします。その結果もバージョ
ニングしつつ S3 バケットに格納できれば、万が一問題が発生した時にバイナリ毎切り
戻すことが出来そうです。&lt;/p&gt;
&lt;p&gt;また CodeDeploy は EC2 インスタンス・またオンプレのインスタンスへコードのデプ
ロイが可能になるサービスです。東京リージョンでは 2015/08 から利用が可能になり
ました。これの便利なところは CircleCI 等の CI サービスから簡単に叩けて、VPC 内
のインスタンスに対してもデプロイが可能なところです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>cAdvisor/influxDB/GrafanaでDockerリソース監視</title>
      <link>https://jedipunkz.github.io/post/2015/09/12/cadvisor-influxdb-grafana-docker/</link>
      <pubDate>Sat, 12 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/09/12/cadvisor-influxdb-grafana-docker/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は Docker ネタです。Docker 導入するにしても監視はどうする？という話になる
と思うのですが、各 Monitoring as a Service を使うにしてもエージェント入れない
といけないしお金掛かることもあるし..で、調べていたら cAdvisor というキーワード
が出てきました。今回は cAdvisor を使ってコンテナの監視が出来ないか、について書
いていきたいと想います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cAdvisor とは ?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cAdvisor は Kubernates で用いられているコンポーネントで単体でも利用可能とのこ
と。Google が開発しています。また Docker コンテナの監視においてこの cAdvisor
は一般化しつつあるようです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/google/cadvisor&#34;&gt;https://github.com/google/cadvisor&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;収集したメトリクスの保存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cAdvisor 自体も Docker で起動して、同ホスト上に起動している Docker コンテナの
リソースをモニタリングしてくれます。そのメトリクスデータは幾つかの DB に保存出
来るのですが、そのうちの一つが influxDB です。influxDB は時系列データベースで
す。システムのメトリクスデータを収めるのにちょうどいいデータベースになります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://influxdb.com/&#34;&gt;https://influxdb.com/&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DB に収めたメトリクスの可視化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;influxDB に収めたメトリクスデータを可視化するのが Grafana です。Grafana のデー
タソースは influxDB の他にも幾つかあり Elasticsearch, KairosDB, Graphite 等が
それです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://grafana.org/&#34;&gt;http://grafana.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;では早速試してみましょう。&lt;/p&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;p&gt;今回は Vagrant を使います。また Vagrant 上で上記の3つのソフトウェアを Docker
で稼働します。またどうせなので docker-compose を使って3つのコンテナを一斉に立
ち上げてみましょう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Knife-ZeroでOpenStack Kiloデプロイ(複数台編)</title>
      <link>https://jedipunkz.github.io/post/2015/07/20/knife-zero-openstack-kilo/</link>
      <pubDate>Mon, 20 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/07/20/knife-zero-openstack-kilo/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;前回 OpenStack Kilo のオールインワン構成を Chef-Zero を使ってデプロイする方法
を書きましたが、複数台構成についても調べたので結果をまとめていきます。&lt;/p&gt;
&lt;p&gt;使うのは openstack/openstack-chef-repo です。下記の URL にあります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openstack/openstack-chef-repo&#34;&gt;https://github.com/openstack/openstack-chef-repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この中に Vagrant を使ったファイルが存在しますが、実機でのデプロイには全く役に
立ちません。自分で Environment ファイルを作成する必要があります。今回は前提の
構成を作って、それに合わせた Environment ファイルを記します。ほぼスタンダード
な構成にしましたので、自分の環境に合わせて修正するのも比較的簡単だと想います。
参考にしてください。&lt;/p&gt;
&lt;p&gt;今回は knife-zero を使ってデプロイします。Chef サーバが必要なく、knife-zero を
使うホスト上のオンメモリで Chef サーバが稼働するので準備がほとんど必要ありません。&lt;/p&gt;
&lt;p&gt;早速ですが、構成と準備・そしてデプロイ作業を記していきます。&lt;/p&gt;
&lt;h2 id=&#34;前提の構成&#34;&gt;前提の構成&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;   +------------+
   | GW Router  |
+--+------------+
|  |
|  +--------------+--------------+---------------------------- public network
|  | eth0         | eth0
|  +------------+ +------------+ +------------+ +------------+
|  | Controller | |  Network   | |  Compute   | | Knife-Zero | 
|  +------------+ +-------+----+ +------+-----+ +------------+
|  | eth1         | eth1  |      | eth1 |       | eth1 
+--+--------------+-------)------+------)-------+------------- api/management network
                          | eth2        | eth2
                          +-------------+--------------------- guest network
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;特徴としては&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef-ZeroでOpenStack Kiloデプロイ(オールインワン編)</title>
      <link>https://jedipunkz.github.io/post/2015/07/16/chef-zero-openstack-allinone/</link>
      <pubDate>Thu, 16 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/07/16/chef-zero-openstack-allinone/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;久々に openstack-chef-repo を覗いてみたら &amp;lsquo;openstack/openstack-chef-repo&amp;rsquo; とし
て公開されていました。今まで stackforge 側で管理されていましたが &amp;lsquo;openstack&amp;rsquo;
の方に移動したようです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openstack/openstack-chef-repo&#34;&gt;https://github.com/openstack/openstack-chef-repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;結構安定してきているのかな？と想い、ちらっと試したのですが案の定、簡単に動作さ
せることが出来ました。&lt;/p&gt;
&lt;p&gt;今回はこのレポジトリを使ってオールインワン構成の OpenStack Kilo を作る方法をま
とめていきます。&lt;/p&gt;
&lt;h2 id=&#34;前提の構成&#34;&gt;前提の構成&lt;/h2&gt;
&lt;p&gt;このレポジトリは Vagrant で OpenStack を作るための環境一式が最初から用意されて
いますが、Vagrant では本番環境を作ることは出来ないため、Ubuntu ホストを前提と
した記述に差し替えて説明していきます。前提にする構成は下記のとおりです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uuntu Linux 14.04 x 1 台&lt;/li&gt;
&lt;li&gt;ネットワークインターフェース x 3 つ&lt;/li&gt;
&lt;li&gt;eth0 : External ネットワーク用&lt;/li&gt;
&lt;li&gt;eth1 : Internal (API, Manage) ネットワーク用&lt;/li&gt;
&lt;li&gt;eth2 : Guest ネットワーク用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特徴としては上記なのですが、eth2 に関してはオールインワンなので必ずしも必要と
いうわけではありません。複数台構成を考慮した設定になっています。&lt;/p&gt;
&lt;h2 id=&#34;前提のip-アドレス&#34;&gt;前提のIP アドレス&lt;/h2&gt;
&lt;p&gt;この記事では下記の IP アドレスを前提にします。お手持ちの環境の IP アドレスが違
い場合はそれに合わせて後に示す json ファイルを変更してください。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10.0.1.10 (eth0) : external ネットワーク&lt;/li&gt;
&lt;li&gt;10.0.2.10 (eth1) : api/management ネットワーク&lt;/li&gt;
&lt;li&gt;10.0.3.10 (eth2) : Guest ネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事前の準備&#34;&gt;事前の準備&lt;/h2&gt;
&lt;p&gt;事前に対象ホスト (OpenStack ホスト) に chef, berkshelf をインストールします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>オブジェクトストレージ minio を使ってみる</title>
      <link>https://jedipunkz.github.io/post/2015/06/25/minio/</link>
      <pubDate>Thu, 25 Jun 2015 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2015/06/25/minio/</guid>
      <description>&lt;p&gt;こんにちは、@jedipunkz です。&lt;/p&gt;
&lt;p&gt;久々にブログ更新になりましたが、ウォーミングアップで minio というオブジェクト
ストレージを使ってみたメモを記事にしたいと想います。&lt;/p&gt;
&lt;p&gt;minio は Minimal Object Storage の名の通り、最小限の小さなオブジェクトストレー
ジになります。公式サイトは下記のとおりです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://minio.io/&#34;&gt;http://minio.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Golang で記述されていて Apache License v2 の元に公開されています。&lt;/p&gt;
&lt;p&gt;最近、資金調達の話も挙がっていたので、これから一般的になってくるのかもしれません。&lt;/p&gt;
&lt;p&gt;早速ですが、minio を動かしてみます。&lt;/p&gt;
&lt;h2 id=&#34;minio-を起動する&#34;&gt;Minio を起動する&lt;/h2&gt;
&lt;p&gt;方法は mithub.com/minio/minio の README に書かれていますが、バイナリを持ってき
て実行権限を与えるだけのシンプルな手順になります。&lt;/p&gt;
&lt;p&gt;Linux でも Mac でも動作しますが、今回私は Mac 上で動作させました。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% wget https://dl.minio.io:9000/updates/2015/Jun/darwin-amd64/minio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% chmod +x minio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ./minio mode memory limit 512MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Starting minio server on: http://127.0.0.1:9000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Starting minio server on: http://192.168.1.123:9000
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;起動すると Listening Port と共に EndPoint の URL が表示されます。&lt;/p&gt;
&lt;p&gt;次に mc という minio client を使って動作確認します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>VyOS で VXLAN を使ってみる</title>
      <link>https://jedipunkz.github.io/post/2014/12/16/vyos-vxlan/</link>
      <pubDate>Tue, 16 Dec 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/12/16/vyos-vxlan/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;VyOS に VXLAN が実装されたと聞いて少し触ってみました。この情報を知ったきっかけ
は @upaa さんの下記の資料です。&lt;/p&gt;
&lt;p&gt;参考資料 : &lt;a href=&#34;http://www.slideshare.net/upaa/vyos-users-meeting-2-vyosvxlan&#34;&gt;http://www.slideshare.net/upaa/vyos-users-meeting-2-vyosvxlan&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;VyOS は御存知の通り実体は Debian Gnu/Linux 系の OS でその上に OSS なミドル
ウェアが搭載されていて CLI でミドルウェアのコンフィギュレーション等が行えるモ
ノになっています。Linux で VXLAN といえば OVS を使ったモノがよく知られています
が VyOS の VXLAN 機能は Linux Kernel の実装を使っているようです。&lt;/p&gt;
&lt;h2 id=&#34;要件&#34;&gt;要件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;トンネルを張るためのセグメントを用意&lt;/li&gt;
&lt;li&gt;VyOS 1.1.1 (現在最新ステーブルバージョン) が必要&lt;/li&gt;
&lt;li&gt;Ubuntu Server 14.04 LTS (同じく Linux VXLAN 搭載バージョン)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;特徴&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;マネージメント用セグメント 10.0.1.0/24 を用意&lt;/li&gt;
&lt;li&gt;GRE と同じくトンネル終端が必要なのでそのためのセグメント 10.0.2.0/24 を用意&lt;/li&gt;
&lt;li&gt;各 eth1 は IP reachable である必要があるので予め IP アドレスの設定と疎通を確認&lt;/li&gt;
&lt;li&gt;VXLAN を喋れる Ubuntu 14.04 LTS x 1 台と VyOS 1.1.1 x 2 台で相互に疎通確認&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-------------+-------------+------------ Management 10.0.1.0/24
|10.0.0.254   |10.0.0.253   |10.0.0.1
|eth0         |eth0         |eth0
+----------+  +----------+  +----------+ 
|  vyos01  |  |  vyos02  |  |  ubuntu  |
+-+--------+  +----------+  +----------+ 
| |eth1       | |eth1       | |eth1
| |10.0.2.254 | |10.0.2.253 | |10.0.2.1
| +-----------)-+-----------)-+---------- Tunneling 10.0.2.0/24
|             |             |
+-------------+-------------+------------ VXLAN(eth1にlink) 10.0.1.0/24
10.0.1.254     10.0.1.253    10.0.1.1
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;設定を投入&#34;&gt;設定を投入&lt;/h2&gt;
&lt;p&gt;vyos01 の設定を行う。VXLAN の設定に必要なものは&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Aviator でモダンに OpenStack を操作する</title>
      <link>https://jedipunkz.github.io/post/2014/12/13/aviator-openstack/</link>
      <pubDate>Sat, 13 Dec 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/12/13/aviator-openstack/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;自分は Ruby を普段使うのでいつも Fog というライブラリを使って OpenStack, AWS
を操作していました。Fog を使うとクラウドの操作が Ruby のネイティブコードで行え
るのでシステムコマンド打つよりミス無く済みます。&lt;/p&gt;
&lt;p&gt;Fog より後発で Aviator というライブラリが登場してきたので少し使ってみたのです
がまだ未完成なところがあるものの便利な点もあって今後に期待だったので紹介します。&lt;/p&gt;
&lt;h2 id=&#34;認証情報を-yaml-ファイルに記す&#34;&gt;認証情報を yaml ファイルに記す&lt;/h2&gt;
&lt;p&gt;接続に必要な認証情報を yaml ファイルで記述します。名前を &amp;lsquo;aviator.yml&amp;rsquo; として
保存。この時に下記のように環境毎に認証情報を別けて書くことができます。こうする
ことでコードの中で開発用・サービス用等と使い分けられます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;production&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;provider&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;openstack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;auth_service&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;host_uri&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Auth URL&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;request&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;create_token&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;validator&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;list_tenants&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;auth_credentials&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;User Name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;password&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Password&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;tenant_name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Tenant Name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;development&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;provider&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;openstack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;auth_service&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;host_uri&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Auth URL&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;request&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;create_token&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;validator&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;list_tenants&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;auth_credentials&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;User Name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;password&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Password&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;tenant_name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;Tenant Name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;シンタックス確認
+++&lt;/p&gt;
&lt;p&gt;次に aviator のシンタックスを確認します。Fog に無い機能で、コマンドラインでシ
ンタックスを確認できてしかも指定可能はパラメータと必須なパラメータと共にサンプ
ルコードまで提供してくれます。公式サイトに&amp;rsquo;サーバ作成&amp;rsquo;のメソッドが掲載されてい
るので、ここでは仮想ディスクを作るシンタックスを確認してみます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% gem install aviator
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% aviator describe openstack volume &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;-- 利用可能な機能を確認&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Available requests &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; openstack volume_service:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public list_volume_types
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public list_volumes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public delete_volume
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public create_volume
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public get_volume
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v1 public update_volume
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  v1 public root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% aviator describe openstack volume v1 public create_volume &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;-- シンタックスを確認&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;:Request &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;gt; create_volume
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Parameters:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; +---------------------+-----------+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | NAME                | REQUIRED? |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; +---------------------+-----------+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | availability_zone   |     N     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | display_description |     Y     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | display_name        |     Y     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | metadata            |     N     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | size                |     Y     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | snapshot_id         |     N     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; | volume_type         |     N     |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; +---------------------+-----------+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Sample Code:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  session.volume_service.request&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;:create_volume&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; |params|
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.volume_type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.availability_zone &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.snapshot_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.metadata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.display_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.display_description &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    params.size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  end
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;このように create_volume というメソッドが用意されていて、指定出来るパラメータ・
必須なパラメータが確認できます。必須なモノには &amp;ldquo;Y&amp;rdquo; が REQUIRED に付いています。
またサンプルコードが出力されるので、めちゃ便利です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef-Zero でお手軽に OpenStack Icehouse を作る</title>
      <link>https://jedipunkz.github.io/post/2014/11/15/chef-zero-openstack-icehouse/</link>
      <pubDate>Sat, 15 Nov 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/11/15/chef-zero-openstack-icehouse/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;OpenStack Juno がリリースされましたが、今日は Icehouse ネタです。&lt;/p&gt;
&lt;p&gt;icehouse 以降、自分の中で OpenStack を自動で作る仕組みが無くなりつつあり、気軽
に OpenStack を作って色々試したい！ッていう時に手段が無く困っていました。例え
ば仕事でちょっと OpenStack 弄りたい！って時に DevStack, RDO しかなく。DevStack
は御存知の通り動かない可能性が結構あるし RDO は Ubuntu/Debian Gnu Linux ベース
じゃないし。&lt;/p&gt;
&lt;p&gt;ってことで、以前にも紹介した stackforge 管理の openstack-chef-repo と
Chef-Zero を使って OpenStack Icehouse (Neutron) のオールインワン構成を作る方法
を書きます。ちなみに最近 Chef-Solo が Chef-Zero に置き換わりつつあるらしいです。
Chef-Zero はオンメモリで Chef サーバを起動する仕組みです。Chef-Solo と違って Chef
サーバを扱う時と何も変更無く操作が出来るのでとても楽です。また、Chef サーバを
別途構、構築・管理しなくて良いので、気軽に OpenStack が作れます。&lt;/p&gt;
&lt;p&gt;ちなみに stackforge/openstack-chef-repo の README.md に Chef-Zero での構築方法
が書いてありますが、沢山の問題があります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nova-network 構成&lt;/li&gt;
&lt;li&gt;API の Endpoint が全て localhost に向いてしまうため外部から操作不可能&lt;/li&gt;
&lt;li&gt;各コンポーネントの bind_address が localhost を向いてしまう&lt;/li&gt;
&lt;li&gt;berkshelf がそのままでは入らない&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;よって、今回はこれらの問題を解決しつつ &amp;ldquo;オールインワンな Neutron 構成の
Icehouse OpenStack を作る方法&amp;rdquo; を書いていきます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>MidoStack を動かしてみる</title>
      <link>https://jedipunkz.github.io/post/2014/11/04/midostack/</link>
      <pubDate>Tue, 04 Nov 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/11/04/midostack/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;昨晩 Midokura さんが Midonet を OSS 化したとニュースになりました。公式サイトは
下記の URL になっています。Midonet は OpenStack Neutron のプラグインとして動作
するソフトウェアです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.midonet.org&#34;&gt;http://www.midonet.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下記のGithub 上でソースを公開しています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/midonet&#34;&gt;https://github.com/midonet&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本体の midonet と共に midostack というレポジトリがあってどうやら公式サイトの
QuickStart を見ても devstack を交えての簡単な midonet の動作が確認できそう。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/midonet/midostack&#34;&gt;https://github.com/midonet/midostack&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;早速使ってみる&#34;&gt;早速使ってみる&lt;/h2&gt;
&lt;p&gt;早速 midostack を使って midonet を体験してみましょう。QuickStart には
Vagrant + VirtualBox を用いた使い方が改定ありますが手元の PC 端末だとリソース
が足らなくて CirrOS VM 一個すら立ち上がりませんでした。よって普通にリソースの
沢山あるサーバで稼働してみます。Vagrantfile 見ても&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;config.vm.synced_folder &amp;#34;./&amp;#34;, &amp;#34;/midostack&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;としているだけなので、Vagrant ではなくても大丈夫でしょう。&lt;/p&gt;
&lt;p&gt;Ubuntu Server 14.04 をインストールしたマシンを用意して midostack を取得します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% git clone https://github.com/midonet/midostack.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;midonet_stack.sh を実行します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd midostack
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ./midonet_stack.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;暫く待つと Neutron Middonet Plugin が有効になった OpenStack が立ち上がります。
Horizon にアクセスしましょう。ユーザ名 : admin, パスワード : gogomid0 (デフォ
ルト) です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef-Container Beta を使ってみる</title>
      <link>https://jedipunkz.github.io/post/2014/07/16/chef-container/</link>
      <pubDate>Wed, 16 Jul 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/07/16/chef-container/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;昨晩 Chef が Chef-Container を発表しました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.getchef.com/blog/2014/07/15/release-chef-container-0-2-0-beta/&#34;&gt;http://www.getchef.com/blog/2014/07/15/release-chef-container-0-2-0-beta/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.opscode.com/containers.html&#34;&gt;http://docs.opscode.com/containers.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;まだ Beta リリースでバージョンは 0.2.0 です。(gem だと 0.1.1)&lt;/p&gt;
&lt;p&gt;Docker を代表とするコンテナ周りの技術が最近、盛んにリリースされていますし、今
後クラウドプラットフォーム上でコンテナを使ってアプリを動かすケースも増えてくる
のではないでしょうか。Dockerfile を使っても Chef-Solo を使ってソフトウェアをデ
プロイ出来るのだけどそれだけだとしんどいので、コンテナに特化した Chef が出てき
たってことだと思います。特徴として SSH でログインしてブートストラップするので
はなくて Runit + Chef-init を用いてコンテナにデプロイすることが挙げられます。&lt;/p&gt;
&lt;p&gt;では実際に使ってみたのでその時の手順をまとめてみます。&lt;/p&gt;
&lt;h2 id=&#34;事前に用意する環境&#34;&gt;事前に用意する環境&lt;/h2&gt;
&lt;p&gt;下記のソフトウェアを予めインストールしておきましょう。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;li&gt;chef&lt;/li&gt;
&lt;li&gt;berkshelf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ここで注意なのですが後に knife コマンドを使って Docker イメージをビルドします。
つまり root 権限が必要です。rbenv 等を使って ruby, chef をインストールすると、
辛いかもしれませんので OS のパッケージを使ってインストールすると良いと思います。
この辺りは今後改善策が出てくるかも&amp;hellip;。&lt;/p&gt;
&lt;p&gt;尚、インストール方法はここでは割愛します。&lt;/p&gt;
&lt;h2 id=&#34;chef-container-のインストール&#34;&gt;Chef-Container のインストール&lt;/h2&gt;
&lt;p&gt;下記の2つの Gems をインストールします。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;knife-container&lt;/li&gt;
&lt;li&gt;chef-container&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo gem install knife-container
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo gem install chef-container
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;使用方法&#34;&gt;使用方法&lt;/h2&gt;
&lt;p&gt;まず knife コマンドを使って操作に必要なディレクトリとファイルを生成します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>JTF2014 で Ceph について話してきた！</title>
      <link>https://jedipunkz.github.io/post/2014/06/22/jtf2014-ceph/</link>
      <pubDate>Sun, 22 Jun 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/06/22/jtf2014-ceph/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今日、JTF2014 (July Tech Festa 2014) というイベントで Ceph のことを話してきま
した。Ceph ユーザ会の会員として話してきたのですが Ceph ユーザ会は実は最近発足
したばかりのユーザ会で、まだまだ活動が活発ではありません。もし興味がある方いらっ
しゃいましたら是非参加よろしくお願いしますー。下記の Google Groups になります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/ceph-jp&#34;&gt;https://groups.google.com/forum/#!forum/ceph-jp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ユーザ会としての勉強会として初になるのですが、今回このイベントで自分は
Ceph-Deploy について話してきました。とりあえず皆さんに使ってもらいたかったので
この話をしてきました。が、予定時間がメチャ短かったので超絶早口で頑張った分、皆
さんに理解してもらえなかった気がしてちょっと反省&amp;hellip;。なので、このブログを利用
して少し細くさせてもらいます。&lt;/p&gt;
&lt;p&gt;今日の発表資料はこちらです！&lt;/p&gt;
&lt;script async class=&#34;speakerdeck-embed&#34;
data-id=&#34;592a0b90ceb30131a5d25ae3f95c3a1a&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;今日のテーマは 「Ceph-Deploy を使って Ceph を構築してみる」だったのですが、下
記のテーマを持って資料を作っています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;単にミニマム構成ではなく運用を考慮した実用性のある構成&lt;/li&gt;
&lt;li&gt;OSD, MON, MDS の各プロセスとノード・ディスクの数の関係を知ってもらう&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特に「実用性のある..」は意識したつもりでした。そのために前提とした構成に下記の
特徴を持たせています。(資料 6 ページ目に構成図があります。確認してみてください。)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;オブジェクト格納用ディスクは複数/ノードを前提&lt;/li&gt;
&lt;li&gt;OSD レプリケーションのためのクラスタネットワークを用いる構成&lt;/li&gt;
&lt;li&gt;OSD の扱うジャーナル格納用ディスクは高速な SSD を用いる&lt;/li&gt;
&lt;li&gt;MDS は利用する HW リソースの特徴が異なるので別ノードへ配置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ストレージ全体を拡張したければ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;図中 ceph01-03 の様なノードを増設する&lt;/li&gt;
&lt;li&gt;ceph01-03 にディスクとそれに対する OSD を増設する&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ですが、前者がベストでしょう。ノード増設の場合 ceph-deploy を用いて&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ceph-deploy mon create &amp;lt;新規ホスト名&amp;gt; で MON を稼働&lt;/li&gt;
&lt;li&gt;ceph-dploy disk zap, osd create で OSD を稼働&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;で簡単に可能です。MDS の増設も負荷状況を見ながらするといいでしょう。自分はまだ
Ceph を運用していないので、各プロセスがどのようなリソースの消費の仕方をするの
か知りません。MDS がどのような数で運用していくべきなのか。早く運用から得たノウ
ハウが共有されないかなぁと期待しています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mesos &#43; Marathon &#43; Deimos &#43; Docker を試してみた!</title>
      <link>https://jedipunkz.github.io/post/2014/06/13/mesos-marathon-deimos-docker/</link>
      <pubDate>Fri, 13 Jun 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/06/13/mesos-marathon-deimos-docker/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;以前 Mesos, Docker について記事にしました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/09/28/mesos-architecture-number-1/&#34;&gt;http://jedipunkz.github.io/blog/2013/09/28/mesos-architecture-number-1/&lt;/a&gt;
&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/10/01/methos-architecture-number-2-docker-on-mesos/&#34;&gt;http://jedipunkz.github.io/blog/2013/10/01/methos-architecture-number-2-docker-on-mesos/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Twitter で Docker 関連のオーケストレーションツールについて呟いていたら @everpeace さんから
こんな情報をもらいました。&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; 元々meos-dockerっていうmesos executorがあったんですけど、mesosがcontainer部分をpluggableにしたので、それに合わせてdeimosっていうmesos用のexternal containerizer が作られました。&lt;/p&gt;&amp;mdash; Shingo Omura (@everpeace) &lt;a href=&#34;https://twitter.com/everpeace/statuses/476998842383347712&#34;&gt;2014, 6月 12&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Deimos !!! 知らなかった。Mesos の Docker プラグインらしく下記の場所にありました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mesosphere/deimos&#34;&gt;https://github.com/mesosphere/deimos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;色々調べいたら、こんな資料が見つかりました。どうやらまだ公開されて4日しか経っていないようです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://mesosphere.io/learn/run-docker-on-mesosphere/&#34;&gt;http://mesosphere.io/learn/run-docker-on-mesosphere/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mesos + Marathon + Deimos + Docker をオールインワン構成で構築する手順が書かれています。&lt;/p&gt;
&lt;p&gt;内容はほぼ同じですが、一応自分がやってみて理解したことをまとめたいので下記に記していきます。&lt;/p&gt;
&lt;h2 id=&#34;構築してみる&#34;&gt;構築してみる&lt;/h2&gt;
&lt;p&gt;手順をまとめてスクリプトにしました。パッケージは Ubuntu 13.10 用のようですが 14.04 のホスト
で実行出来ました。14.04 のパッケージはまだ見つかっていません。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# disable ipv6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;net.ipv6.conf.all.disable_ipv6 = 1&amp;#39;&lt;/span&gt; | sudo tee -a /etc/sysctl.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;net.ipv6.conf.default.disable_ipv6 = 1&amp;#39;&lt;/span&gt; | sudo tee -a /etc/sysctl.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo sysctl -p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install related tools&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get -y install curl python-setuptools python-pip python-dev python-protobuf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install zookeeper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get -y install zookeeperd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; | sudo dd of&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/var/lib/zookeeper/myid
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install docker&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get -y install docker.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ln -sf /usr/bin/docker.io /usr/local/bin/docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo sed -i &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;$acomplete -F _docker docker&amp;#39;&lt;/span&gt; /etc/bash_completion.d/docker.io
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo docker pull libmesos/ubuntu
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install mesos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -fL http://downloads.mesosphere.io/master/ubuntu/13.10/mesos_0.19.0-xcon3_amd64.deb -o /tmp/mesos.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dpkg -i /tmp/mesos.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo mkdir -p /etc/mesos-master
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo in_memory  | sudo dd of&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/mesos-master/registry
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -fL http://downloads.mesosphere.io/master/ubuntu/13.10/mesos_0.19.0-xcon3_amd64.egg -o /tmp/mesos.egg
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo easy_install /tmp/mesos.egg
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install marathon&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -fL http://downloads.mesosphere.io/marathon/marathon_0.5.0-xcon2_noarch.deb -o /tmp/marathon.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dpkg -i /tmp/marathon.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# restart each services&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo service docker.io restart
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo service zookeeper restart
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo service mesos-master restart
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo service mesos-slave restart
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# install deimos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install deimos
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo mkdir -p /etc/mesos-slave
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## Configure Deimos as a containerizer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo /usr/bin/deimos  | sudo dd of&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/mesos-slave/containerizer_path
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo external     | sudo dd of&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/mesos-slave/isolation
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;プロセスの確認&#34;&gt;プロセスの確認&lt;/h2&gt;
&lt;p&gt;実行が終わると各プロセスが確認出来ます。オプションでどのプロセスが何を見ているか大体
わかりますので見ていきます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>クラウドライブラリ Fog で AWS を操作！..のサンプル</title>
      <link>https://jedipunkz.github.io/post/2014/05/29/fog-aws-ec2-elb/</link>
      <pubDate>Thu, 29 May 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/05/29/fog-aws-ec2-elb/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;最近 OpenStack でサービスを開発！.. じゃなくて AWS でプロトタイプサービス作っ
ているのですが、Ruby で開発したかったので Fog を使っています。EC2 と ELB の
API を叩くコードになりつつあるのですが、サンプルコードって世の中に中々無いと気
がついたので、このブログ記事にサンプルコードを載せたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;fog-とは-&#34;&gt;Fog とは ?&lt;/h2&gt;
&lt;p&gt;Fog &lt;a href=&#34;http://fog.io/&#34;&gt;http://fog.io/&lt;/a&gt; はクラウドライブラリソフトウェアです。AWS, Rackspace,
CloudStack, OpenStack .. と数ある世の中のクラウドプラットフォームを扱うために
用意されたソフトウェアです。対応しているプラットフォームの種別は下記を見ると参
考になります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://fog.io/about/provider_documentation.html&#34;&gt;http://fog.io/about/provider_documentation.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ドキュメントがまだまだ揃っていなく、Fog のコードを覗きながら実装するしかない状
況です。なので「こう使えば良い！」というお手本があまりネット上にも無い気がしま
す。&lt;/p&gt;
&lt;p&gt;ドキュメントは一応下記にあります。
が使い方がよくわからない・・！(´；ω；｀)ﾌﾞﾜｯ&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://rubydoc.info/gems/fog/frames/index&#34;&gt;http://rubydoc.info/gems/fog/frames/index&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ec2-インスタンスを使ってみる&#34;&gt;EC2 インスタンスを使ってみる&lt;/h2&gt;
&lt;p&gt;まずは AWS EC2 の API を叩いて t1.micro インスタンスを立ち上げてみましょう。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fog&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;compute &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Fog&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Compute&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;new({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:provider&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;AWS&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:aws_access_key_id&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;....&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:aws_secret_access_key&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;....&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:region&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ap-northeast-1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;server &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; compute&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;servers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:image_id&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ami-cedaa2bc&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:flavor_id&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t1.micro&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:key_name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_key&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:tags&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;:groups&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ssh-secgroup&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;server&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;wait_for { print &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;; ready? }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;puts &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;created instance name :&amp;#34;&lt;/span&gt;, server&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dns_name
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;解説&#34;&gt;解説&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;compute = &amp;hellip; とあるところで接続情報を記しています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;ldquo;ACCESS_KEY_ID&amp;rdquo; や &amp;ldquo;SECRET_ACCESS_KEY&amp;rdquo; はみなさん接続する時にお持ちですよね。それ
とリージョン名やプロバイダ名 (ここでは AWS) を記して AWS の API に接続します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>stackforge/openstack-chef-repo で OpenStack Icehouse デプロイ</title>
      <link>https://jedipunkz.github.io/post/2014/04/25/stackforge-openstack-chef-repo-icehouse-deploy/</link>
      <pubDate>Fri, 25 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/04/25/stackforge-openstack-chef-repo-icehouse-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;またまた OpenStack のデプロイをどうするか？についてです。&lt;/p&gt;
&lt;p&gt;今まで自分の中では Rackspace Private Cloud で使われている Rackspace 管理の
rcbops/chef-cookbooks が今現在使うならベストの選択だと思っていました。これは内
部で Chef が使われていてしかも Cookbooks が Github 上で公開されています。
Apache ライセンスで使えるので、サービス構築にも使えちゃうというモノ。&lt;/p&gt;
&lt;p&gt;先日、ある OpenStack コアデベロッパーの方から「jedipunkz さん、やっぱり rcbops
がいいですか？運営とかどうなっているんでしょう？マージの規準とかどうなのかな？」
と質問受けました。確かにマージの基準は Rackspace Private Cloud がベースになり
ますし、管理しているエンジニアの一覧を見ていると Rackspace 社のエンジニアがメ
インですし、今後どうなるのか分からない&amp;hellip;。&lt;/p&gt;
&lt;p&gt;逃げ道は用意したほうが良さそう。&lt;/p&gt;
&lt;p&gt;ということで、以前自分も暑かったことのある StackForge の openstack-chef-repo
を久々に使ってみました。Icehouse 構成がこの時点で既に組めるようになっていて、
以前よりだい〜ぶ完成度増した感があります。今回は nova-network 構成を作ってみた
のですが、Neutron 構成ももちろん出来そうなので後に調べてまた公開したいです。&lt;/p&gt;
&lt;h2 id=&#34;stackforge-とは&#34;&gt;StackForge とは&lt;/h2&gt;
&lt;p&gt;StackForge は OpenStack のデプロイ・CI の仕組みとして公式に用いられているもの。
公式サイトは下記の場所にある。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://ci.openstack.org/stackforge.html&#34;&gt;http://ci.openstack.org/stackforge.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;StackForge の openstack-chef-repo は下記の場所にある。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/stackforge/openstack-chef-repo&#34;&gt;https://github.com/stackforge/openstack-chef-repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;openstack-chef-repo はまだ &amp;lsquo;stable/icehouse&amp;rsquo; ブランチが生成されていない。が直
ちに master からブランチが切られる様子。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mirantis OpenStack (Neutron GRE)を組んでみた！</title>
      <link>https://jedipunkz.github.io/post/2014/04/23/mirantis-openstack/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/04/23/mirantis-openstack/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;皆さん、Mirantis OpenStack はご存知ですか？ OpenStack ディストリビューションの
1つです。以下、公式サイトです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://software.mirantis.com/main/&#34;&gt;http://software.mirantis.com/main/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この Mirantis OpenStack を使って OpenStack Havana (Neutron GRE) 構成を作ってみ
ました。その時のメモを書いていきたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;構成は&#34;&gt;構成は?&lt;/h2&gt;
&lt;p&gt;構成は下記の通り。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.io/pix/mirantis_gre.jpg&#34;&gt;
&lt;p&gt;※ CreativeCommon&lt;/p&gt;
&lt;p&gt;特徴は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Administrative Network : Fuel Node, DHCP + PXE ブート用&lt;/li&gt;
&lt;li&gt;Management Network : 各コンポーネント間 API 用&lt;/li&gt;
&lt;li&gt;Public/Floating IP Network : パブリック API, VM Floating IP 用&lt;/li&gt;
&lt;li&gt;Storage Network : Cinder 配下ストレージ &amp;lt;-&amp;gt; インスタンス間用&lt;/li&gt;
&lt;li&gt;要インターネット接続 : Public/Floating Networks&lt;/li&gt;
&lt;li&gt;Neutron(GRE) 構成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;です。タグ VLAN 使って物理ネットワークの本数を減らすことも出来るはずですが、僕
の環境では何故かダメだったので上記の4つの物理ネットワークを別々に用意しました。&lt;/p&gt;
&lt;h2 id=&#34;fuel-ノードの構築&#34;&gt;Fuel ノードの構築&lt;/h2&gt;
&lt;p&gt;Fuel ノードとは、OpenStack の各ノードをデプロイするための管理ノードのことです。
DHCP + PXE を管理する Cobbler やデプロイツールの Puppet が内部で稼働し、
Administrative Network 上で稼働したノードを管理・その後デプロイします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Geard のポートマッピングについて調べてみた</title>
      <link>https://jedipunkz.github.io/post/2014/04/22/geard-port-mapping/</link>
      <pubDate>Tue, 22 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/04/22/geard-port-mapping/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;今週 Redhat が &amp;lsquo;Redhat Enterprise Linux Atomic Host&amp;rsquo; しましたよね。Docker を特
徴としたミニマムな OS だとのこと。その内部で用いられている技術 Geard について
少し調べてみました。複数コンテナの関連付けが可能なようです。ここでは調べた結果
について簡単にまとめていきます。&lt;/p&gt;
&lt;h2 id=&#34;参考資料&#34;&gt;参考資料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://openshift.github.io/geard/deploy_with_geard.html&#34;&gt;http://openshift.github.io/geard/deploy_with_geard.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;利用方法&#34;&gt;利用方法&lt;/h2&gt;
&lt;p&gt;ここではホスト OS に Fedora20 を用意します。&lt;/p&gt;
&lt;p&gt;まず Geard をインストール&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo yum install --enablerepo&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;updates-testing geard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下記の json ファイルを作成します。ここにはコンテナをデプロイするための情報と関
連付けのための情報を記します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;{&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;EDITOR&lt;/span&gt;} &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;rockmongo_mongodb.json&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;containers&amp;#34;&lt;/span&gt;:[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rockmongo&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;count&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;image&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;derekwaynecarr/rockmongo&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;publicports&amp;#34;&lt;/span&gt;:[{&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;internal&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;external&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;6060&lt;/span&gt;}],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;links&amp;#34;&lt;/span&gt;:[{&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;to&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mongodb&amp;#34;&lt;/span&gt;}]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    },
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mongodb&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;count&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;image&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ccoleman/ubuntu-mongodb&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;publicports&amp;#34;&lt;/span&gt;:[{&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;internal&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;27017&lt;/span&gt;}]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上記のファイルの解説。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;コンテナ &amp;lsquo;rockmongo&amp;rsquo; と &amp;lsquo;mongodb&amp;rsquo; を作成&lt;/li&gt;
&lt;li&gt;それぞれ1個ずつコンテナを作成&lt;/li&gt;
&lt;li&gt;&amp;lsquo;image&amp;rsquo; パラメータにて docker イメージの指定&lt;/li&gt;
&lt;li&gt;&amp;lsquo;publicports&amp;rsquo; パラメータにてコンテナ内部とホスト側のポートマッピングを行う&lt;/li&gt;
&lt;li&gt;&amp;rsquo;links&amp;rsquo; パラメータで &amp;lsquo;rockmongo&amp;rsquo; を &amp;lsquo;mongodb&amp;rsquo; に関連付け&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;では、デプロイ開始します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Havana Cinder,Glance の分散ストレージ Ceph 連携</title>
      <link>https://jedipunkz.github.io/post/2014/04/04/openstack-havana-cinder-glance-ceph/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/04/04/openstack-havana-cinder-glance-ceph/</guid>
      <description>&lt;p&gt;こんにちは！&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回は Havana 版の OpenStack Glance, Cinder と分散ストレージの Ceph を連携させ
る手順を書いていきます。元ネタはこちら。下記の Ceph の公式サイトに手順です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ceph.com/docs/master/rbd/rbd-openstack/&#34;&gt;https://ceph.com/docs/master/rbd/rbd-openstack/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この手順から下記の変更を行って、ここでは記していきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nova + Ceph 連携させない&lt;/li&gt;
&lt;li&gt;cinder-backup は今のところ動作確認出来ていないので省く&lt;/li&gt;
&lt;li&gt;諸々の手順がそのままでは実施出来ないので補足を入れていく。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cinder-backup は Cinder で作成した仮想ディスクのバックアップを Ceph ストレージ
上に取ることが出来るのですが、そもそも Ceph 上にある仮想ディスクを Ceph にバッ
クアップ取っても意味が薄いですし、まだ動いていないので今回は省きます。LVM やそ
の他ストレージを使った Cinder 連携をされている方にとっては cinder-backup の
Ceph 連携は意味が大きくなってくると思います。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;下記の通りの物理ネットワーク6つの構成です。
OpenStack, Ceph 共に最小構成を前提にします。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                  +--------------------------------------------------------------------- external
                  |
+--------------+--(-----------+--------------+------------------------------------------ public
|              |  |           |              |
+------------+ +------------+ +------------+ +------------+ +------------+ +------------+
| controller | |  network   | |  compute   | |   ceph01   | |   ceph02   | |   ceph03   |
+------------+ +------------+ +------------+ +------------+ +------------+ +------------+
|  |           |  |           |  |  |        |  |  |        |  |  |        |  |  |
+--------------+--(-----------+--(-----------+--(--(--------+--(--(--------+--(--(------- management
   |              |              |  |           |  |           |  |           |  |
   |              +--------------+--(-----------(--(-----------(--(-----------(--(------- guest
   |                                |           |  |           |  |           |  |
   +--------------------------------+-----------+--(-----------+--(-----------+--(------- storage
                                                   |              |              |
                                                   +--------------+--------------+------- cluster
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;特徴&lt;/p&gt;</description>
    </item>
    <item>
      <title>rcbops/chef-cookbooks で Keystone 2013.2.2(Havana) &#43; Swift 1.10.0 を構築</title>
      <link>https://jedipunkz.github.io/post/2014/03/16/rcbops-chef-cookbooks-keystone-havana-swift-1-10-0.deploy/</link>
      <pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/03/16/rcbops-chef-cookbooks-keystone-havana-swift-1-10-0.deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;h4 id=&#34;追記&#34;&gt;追記&lt;/h4&gt;
&lt;p&gt;2014/03/20 : 一旦削除していた記事なのですが、無事動作が確認出来たので再度アッ
プします！&lt;/p&gt;
&lt;p&gt;第17回 OpenStack 勉強会で rcbops/chef-cookbooks の話をしてきたのですが会場から
質問がありました。「Havana の Swift 構成を作る Cookbooks はどこにありますか？」
と。私が試したのが Grizzly 時代のモノで、よく rcbops/chef-cookbooks を見てみる
と Havana ブランチ又は Havana に対応したリリースタグのファイル構成に Swift が
綺麗サッパリ消えているではありませんか・・！下記の Swift の Cookbooks は幸い
github 上に残っていました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/rcbops-cookbooks/swift&#34;&gt;https://github.com/rcbops-cookbooks/swift&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;が rcbops/chef-cookbooks との関連付けが切れています・・。ぐあぁ。&lt;/p&gt;
&lt;p&gt;ということで Havana 構成の Keystone 2013.2.2 と Swift 1.10.0 の構成を Chef で
作らねば！と思い色々試していたら結構あっさりと出来ました。今回はその方法を書い
ていきたいと思います！&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;構成は&amp;hellip;以前の記事 &lt;a href=&#34;http://jedipunkz.github.io/blog/2013/10/27/swift-chef/&#34;&gt;http://jedipunkz.github.io/blog/2013/10/27/swift-chef/&lt;/a&gt; と同じです。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-----------------+
|  load balancer  |
+-----------------+
|
+-------------------+-------------------+-------------------+-------------------+---------------------- proxy network
|                   |                   |                   |                   |                   
+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+
|   chef server   | | chef workstation| |   swift-mange   | |  swift-proxy01  | |  swift-proxy02  | 
+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+ ...&amp;gt; scaling
|                   |                   |                   |                   |                   
+-------------------+-------------------+-------------------+-------------------+-------------------+-- storage network
|                   |                   |                   |                   |                   |
+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+ 
| swift-storage01 | | swift-storage02 | | swift-storage03 | | swift-account01 | | swift-account02 | | swift-account03 |
+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+ ..&amp;gt; scaling
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;
&lt;p&gt;では早速手順を記していきますね。毎回なのですが Chef ワークステーション・Chef
サーバの環境構築については割愛します。オムニバスインストーラを使えば Chef サー
バの構築は簡単ですし、ワークステーションの構築も Ruby インストール -&amp;gt; gem で
Chef をインストール -&amp;gt; .chef 配下を整える、で出来ます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sensu,Chef,OpenStack,Fog を使ったオレオレオートスケーラを作ってみた！</title>
      <link>https://jedipunkz.github.io/post/2014/03/05/sensu-chef-openstack-fog-autoscaler/</link>
      <pubDate>Wed, 05 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/03/05/sensu-chef-openstack-fog-autoscaler/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;今まで監視システムの Sensu やクラウドプラットフォームの OpenStack、コンフィギュ
レーションマネージメントツールの Chef やクラウドライブラリの Fog 等使ってきま
したが、これらを組み合わせるとオレオレオートスケーラ作れるんじゃないか？と思い、
ちょろっと作ってみました。&lt;/p&gt;
&lt;p&gt;ちなみに自分はインフラエンジニアでしかも運用の出身なので Ruby に関しては初心者
レベルです。Chef で扱っているのと Rails アプリを作った経験はありますが、その程
度。Fog というクラウドライブラリにコントリビュートしたことはアリますが..。ちな
みに Fog のコントリビュート内容は OpenStack Neutron(当時 Quantum) の仮想ルータ
の操作を行う実装です。&lt;/p&gt;
&lt;p&gt;そんな自分ですが&amp;hellip;設計1周間・実装1周間でマネージャと CLI が出来ました。
また暫く放置していたマネージャと CLI に WebUI くっつけようかなぁ？と思って
sinatra の学習を始めたのですが、学習を初めて 1.5 日で WebUI が動くところまで行
きました。何故か？Ruby には有用な技術が揃っているから・・！(´；ω；｀)ﾌﾞﾜｯ&lt;/p&gt;
&lt;h2 id=&#34;オレオレオートスケーラ-sclman-の置き場所&#34;&gt;オレオレオートスケーラ &amp;lsquo;sclman&amp;rsquo; の置き場所&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/sclman&#34;&gt;https://github.com/jedipunkz/sclman&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;スクリーンショット
+++&lt;/p&gt;
&lt;img src=&#34;https://raw.github.com/jedipunkz/sclman/master/pix/sclman.png&#34; width=&#34;600&#34;&gt;
&lt;h2 id=&#34;構成は&#34;&gt;構成は？&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-------------- public network                  +-------------+
|                                               |sclman-api.rb|
+----+----+---+                                 |  sclman.rb  |
| vm | vm |.. |                                 |sclman-cli.rb|
+-------------+ +-------------+ +-------------+ +-------------+
|  openstack  | | chef server | | sensu server| | workstation |
+-------------+ +-------------+ +-------------+ +-------------+
|               |               |               |
+---------------+---------------+---------------+--------------- management network
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&amp;lsquo;sclman&amp;rsquo; っていう名前です。上図の workstation ノードで稼働します。処理の流れは&lt;/p&gt;</description>
    </item>
    <item>
      <title>Journal 用 SSD を用いた Ceph 構成の構築</title>
      <link>https://jedipunkz.github.io/post/2014/02/27/journal-ssd-ceph-deploy/</link>
      <pubDate>Thu, 27 Feb 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/02/27/journal-ssd-ceph-deploy/</guid>
      <description>&lt;p&gt;こんにちは、@jedipunkz です。&lt;/p&gt;
&lt;p&gt;前回、&amp;lsquo;Ceph のプロセス配置ベストプラクティス&amp;rsquo; というタイトルで記事を書きました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2014/01/29/ceph-process-best-practice/&#34;&gt;http://jedipunkz.github.io/blog/2014/01/29/ceph-process-best-practice/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今回はこの記事にあるポリシに従って下記のような特徴を持った構成を作る手順を具体
的に書いていきたいと思います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ceph01 - ceph04 の4台構成&lt;/li&gt;
&lt;li&gt;ノードに HDD 2台搭載されていることを前提 (/dev/sdb, /dev/sdc)&lt;/li&gt;
&lt;li&gt;ノードに Journal 用 SSD 1台搭載されていることを前提 (/dev/ssd)&lt;/li&gt;
&lt;li&gt;ceph04 は mds サービス稼働&lt;/li&gt;
&lt;li&gt;ceph05 は ceph-deploy を実行するためのワークステーション&lt;/li&gt;
&lt;li&gt;最終的に ceph04 から Ceph をマウントする&lt;/li&gt;
&lt;li&gt;mon は ノード単位で稼働&lt;/li&gt;
&lt;li&gt;osd は HDD 単位で稼働&lt;/li&gt;
&lt;li&gt;mds は ceph04 に稼働&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;構成--ハードウェアとノードとネットワークの関係&#34;&gt;構成 : ハードウェアとノードとネットワークの関係&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                                                                                      public network
         +-------------------+-------------------+-------------------+-------------------+---------
         |                   |                   |                   |                   |
+--------+--------+ +--------+--------+ +--------+--------+ +--------+--------+ +--------+--------+
|      ceph01     | |      ceph02     | |      ceph03     | |      ceph04     | |      ceph05     |
| +-----+ +-----+ | | +-----+ +-----+ | | +-----+ +-----+ | |                 | |                 |
| | sdb | | sdc | | | | sdb | | sdc | | | | sdb | | sdc | | |                 | |                 |
| +-----+-+-----+ | | +-----+-+-----+ | | +-----+-+-----+ | |                 | |                 |
| |     ssd     | | | |     ssd     | | | |     ssd     | | |                 | |                 |
| +-------------+ | | +-------------+ | | +-------------+ | |                 | |                 |
+--------+--------+ +--------+--------+ +--------+--------+ +-----------------+ +-----------------+
         |                   |                   |                                    cluster network
         +-------------------+-------------------+-------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;構成--プロセスとノードとネットワークの関係&#34;&gt;構成 : プロセスとノードとネットワークの関係&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                                                                                      public network
         +-------------------+-------------------+-------------------+-------------------+---------
         |                   |                   |                   |                   |
+--------+--------+ +--------+--------+ +--------+--------+ +--------+--------+ +--------+--------+
|      ceph01     | |      ceph02     | |      ceph03     | |      ceph04     | |      ceph05     |
| +-----+ +-----+ | | +-----+ +-----+ | | +-----+ +-----+ | | +-------------+ | |                 |
| | osd | | osd | | | | osd | | osd | | | | osd | | osd | | | |     mds     | | |                 |
| +-----+-+-----+ | | +-----+-+-----+ | | +-----+-+-----+ | | +-------------+ | |                 |
| |     mon     | | | |     mon     | | | |     mon     | | |                 | |                 |
| +-------------+ | | +-------------+ | | +-------------+ | |                 | |                 |
+--------+--------+ +--------+--------+ +--------+--------+ +-----------------+ +-----------------+
         |                   |                   |                                    cluster network
         +-------------------+-------------------+-------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意 : 上記の図だと ssd : mon が対に見えますが、そうではありません。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ceph のプロセス配置ベストプラクティス</title>
      <link>https://jedipunkz.github.io/post/2014/01/29/ceph-process-best-practice/</link>
      <pubDate>Wed, 29 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/01/29/ceph-process-best-practice/</guid>
      <description>&lt;p&gt;Ceph はブロック型の分散ストレージファイルシステムです。POSIX のファイルシステ
ムとしてマウント出来ます。Linux の Kernel ドライバや FUSE ドライバを用いてマウ
ントします。またブロックデバイスとしてマウントする方法もあります。&lt;/p&gt;
&lt;p&gt;だいぶ前ですが、Ceph に関する記事を以前下記の通り書きました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/05/25/ceph-cluster-network/&#34;&gt;http://jedipunkz.github.io/blog/2013/05/25/ceph-cluster-network/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/05/11/ceph-deploy/&#34;&gt;http://jedipunkz.github.io/blog/2013/05/11/ceph-deploy/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ceph の構築方法について記したブログだったのですが、今まで mon, osd, mds の各プ
ロセスをそれぞれ何台のノードに対して配置し、またそれぞれのプロセス幾つを何に対
して配置するのか？という疑問が付きまとわっていました。node, disk, process のそ
れぞれの数の関係について知りたいなぁと思っていました。幾つかのドキュメントを読
んでいて、ぼんやり見えてきた事があるのでそれを今回はまとめたいと思います。&lt;/p&gt;
&lt;p&gt;また、皆さん気になるトコロだと思われる容量設計についても軽く触れたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;参考資料&#34;&gt;参考資料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ceph.com/docs/master/rados/configuration/mon-config-ref/&#34;&gt;http://ceph.com/docs/master/rados/configuration/mon-config-ref/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sebastien-han.fr/blog/2013/12/02/ceph-performance-interesting-things-going-on/&#34;&gt;http://www.sebastien-han.fr/blog/2013/12/02/ceph-performance-interesting-things-going-on/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;各要素の数の関係&#34;&gt;各要素の数の関係&lt;/h2&gt;
&lt;p&gt;ハードウェア要素である node, disk(hdd), ssd そしてソフトウェア要素である mon,
osd, mds の数の関係はどのようにするべきか？基本となる関係は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 mds process / node&lt;/li&gt;
&lt;li&gt;1 mon process / node&lt;/li&gt;
&lt;li&gt;1 osd process / disk&lt;/li&gt;
&lt;li&gt;n jornal ssd device / disk / node&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;だと考えられます。僕が今のところ理想かなぁと思っている構成をまとめたいと思いま
す。&lt;/p&gt;
&lt;p&gt;下記の図がそれです。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+------------------------+
|         client         |
+------------------------+
|
+--------------------------+--------------------------+-------------------------------+-------------------------
|                          |                          |                               |            public network
+------------------------+ +------------------------+ +------------------------+      +------------------------+
|          mon           | |          mon           | |          mon           |      |          mds           |
+------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+      +------------------------+
| osd  | | osd  | | osd  | | osd  | | osd  | | osd  | | osd  | | osd  | | osd  |      |                        |
+------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+      |                        |
| disk | | disk | | disk | | disk | | disk | | disk | | disk | | disk | | disk |....&amp;gt; |                        |
+------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+ +------+scale |          node          |
|          ssd           | |          ssd           | |          ssd           |      |                        |
+------------------------+ +------------------------+ +------------------------+      |                        |
|          node          | |          node          | |          node          |      |                        |
+------------------------+ +------------------------+ +------------------------+      +------------------------+
|                          |                          |                               |
+--------------------------+--------------------------+-------------------------------+-------------------------
                                                                                                  cluster network
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;mds-と-node-の関係&#34;&gt;mds と node の関係&lt;/h4&gt;
&lt;p&gt;mds はリモートクライアントへのファイルシステムサービスの提供を行うことや特性が
全く異なることから別ノードに切り出しました。また mds は幾つかのノードで稼働さ
せる事も可能。が、mds はそれぞれのサービスを HA 組む仕組みは持っていないので
どれか一方の mds をクライアントは指し示す必要があり、その mds が停止すれば直
ちに障害に発展します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>第17回 OpenStack 勉強会で話してきました</title>
      <link>https://jedipunkz.github.io/post/2014/01/21/17th-openstack-study/</link>
      <pubDate>Tue, 21 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2014/01/21/17th-openstack-study/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;昨晩、第17回 OpenStack 勉強会が開催されました&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://connpass.com/event/4545/&#34;&gt;http://connpass.com/event/4545/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ここで発表をしてきましたぁ！発表タイトルは &amp;ldquo;rcbops/chef-cookbooks&amp;rdquo; です。&lt;/p&gt;
&lt;script async class=&#34;speakerdeck-embed&#34;
data-id=&#34;27a2739063d601314bce6a232911c4f0&#34; data-ratio=&#34;1.33333333333333&#34;
src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;何を発表したかと言うと詳しくは上記のスライドを見ていただくとして、簡単に言うと
&amp;ldquo;RackSpace 社のエンジニアが管理している Chef Cookbooks でOpenStack 構成を作ろ
う&amp;rdquo; ってことです。&lt;/p&gt;
&lt;p&gt;今日知ったのですがどうも昨晩は初心者向けの勉強会という位置付けだったらしく..少
しだけディープな話題を話してしまったかもしれません！すいません！＞＜&lt;/p&gt;
&lt;p&gt;でもとても楽しく発表出来ましたし、逆に質問のコーナーで最新の情報も教えてもらえ
たり！なんと Havana 対応の v4.2.0 以降では Swift の Cookbooks が消えてしまった
とか！&amp;hellip; 皆 Swift 好きくないの？&amp;hellip;; ;&lt;/p&gt;
&lt;p&gt;rcbops/chef-cookbooks はずっと追っていますが、ものすごいスピードで開発進んでい
るので、今後ぜひみなさん使ってみて下さいー。&lt;/p&gt;
&lt;p&gt;最後に詳しい利用方法を記した僕のブログの URL を貼り付けておきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack Havana を Chef でデプロイ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/11/17/openstack-havana-chef-deploy/&#34;&gt;http://jedipunkz.github.io/blog/2013/11/17/openstack-havana-chef-deploy/&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Swift HA 構成を Chef でデプロイ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/07/26/swift-ha-chef-deploy/&#34;&gt;http://jedipunkz.github.io/blog/2013/07/26/swift-ha-chef-deploy/&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;実用的な Swift 構成を Chef でデプロイ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/10/27/swift-chef/&#34;&gt;http://jedipunkz.github.io/blog/2013/10/27/swift-chef/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef で自律的クラスタを考える</title>
      <link>https://jedipunkz.github.io/post/2013/12/09/chef-autonoumous-cluster/</link>
      <pubDate>Mon, 09 Dec 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/12/09/chef-autonoumous-cluster/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Serf の登場があったり、ここ最近オーケストレーションについて考える人が増えた気
がします。システムをデプロイしてその後各ノード間の連結だったりも同じ Chef,
Puppet 等のコンフィギュレーションツールで行うのか？全く別のツールで？..&lt;/p&gt;
&lt;p&gt;最近 Serf というツールの登場がありました。&lt;/p&gt;
&lt;p&gt;僕も Serf を触ってつい先日ブログに書きました。有用なツールだと思います。シ
ンプルだからこそ応用が効きますし、リアルタイム性もあり、将来的に異なるネットワー
クセグメント上のノードとも連結出来るようになりそうですし、とても期待です。&lt;/p&gt;
&lt;p&gt;話が少し飛びますが..&lt;/p&gt;
&lt;p&gt;いつも Rebuild.fm を楽しく聞いているのですが Immutable Infrastructure の話題の
時にオーケストレーションの話題になって、どうも &amp;lsquo;Chef でも自律的なクラスタを組
むことが認知されていないのでは？&amp;rsquo; と思うようになりました。もちろん Chef でやる
べき！とは言い切りませんし、今後どうなるかわかりません。Opscode の中の人も &amp;lsquo;オー
ケストレーションは自分でやってね&amp;rsquo; というスタンスだったとずいぶん前ですが聞きま
した。Serf を等のオーケストレーションツールを使う使わないの話は今回はしないの
ですが Chef でも自律的クラスタを組むことは出来ますよ〜というのが今回の話題。&lt;/p&gt;
&lt;p&gt;まえがきが長くなりました。&lt;/p&gt;
&lt;p&gt;今回は Chef で自律的クラスタを構成する方法を記したいと思います。&lt;/p&gt;
&lt;p&gt;haproxy 等を利用すれば尚良いと思いますが、よりクラスタを組むのが簡単な nginx
を今回は利用したいと思います。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/opscode-cookbooks/nginx&#34;&gt;https://github.com/opscode-cookbooks/nginx&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;&amp;lsquo;web&amp;rsquo; という Role 名と &amp;rsquo;lb&amp;rsquo; という Role 名で単純な HTTP サーバとしての nginx
ノードを複数台と、ロードバランサとしての nginx ノードを1台でクラスタを構成しま
す。また共に environment 名は同じものを利用します。別の environment 名の場合は
別クラスタという区切りです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>CoreOS etcd のクラスタとその応用性</title>
      <link>https://jedipunkz.github.io/post/2013/12/09/coreos-etcd-cluster/</link>
      <pubDate>Mon, 09 Dec 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/12/09/coreos-etcd-cluster/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;皆さん CoreOS は利用されたことありますか？CoreOS は軽量な docker との相性の良
い OS です。下記が公式サイト。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://coreos.com/&#34;&gt;http://coreos.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;特徴としては下記の3つがあります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;etcd&lt;/li&gt;
&lt;li&gt;systemd&lt;/li&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ここではこの中の etcd について注目していきたいと思います。etcd はクラスタエイ
ブルな KVS データベースです。コンフィギュレーションをクラスタ間で共有すること
がなので、オーケストレーションの分野でも期待出来るのでは？と個人的に感じていま
す。今回は etcd のクラスタ構成構築の手順とその基本動作の確認、またどう応用出来
るのか？について記していきたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;参考-url&#34;&gt;参考 URL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://coreos.com/using-coreos/etcd/&#34;&gt;http://coreos.com/using-coreos/etcd/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;https://github.com/coreos/etcd&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ビルド&#34;&gt;ビルド&lt;/h2&gt;
&lt;p&gt;go 1.1 or later をインストールして etcd のコンパイル準備を行います。Ubuntu
Saucy のパッケージを用いると容易に行えます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% apt-get -y install golang
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;coreos/etcd を取得しビルド&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% git clone https://github.com/coreos/etcd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd coreos
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ./build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% ./etcd --version
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;v0.2.0-rc1-60-g73f04d5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;coreos-の用意&#34;&gt;CoreOS の用意&lt;/h2&gt;
&lt;p&gt;ここではたまたま手元にあった OpenStack を用いて CoreOS のイメージを登録してい
みます。ベアメタルでも可能ですのでその場合は手順を読み替えて作業してみてくださ
い。OpenStack 等クラウドプラットフォームを利用する場合は metadata サービスが必
須となるので注意してください。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ironic でベアメタル OpenStack ！..の一歩手前</title>
      <link>https://jedipunkz.github.io/post/2013/12/05/ironic-openstack-beremetal/</link>
      <pubDate>Thu, 05 Dec 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/12/05/ironic-openstack-beremetal/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;アドベントカレンダーの季節がやって参りました。&lt;/p&gt;
&lt;p&gt;Ironic を使って OpenStack でベアメタルサーバを扱いたい！ということで色々とやっ
ている最中 (今週から始めました..) なのですが、まだまだ incubator プロジェクト
ということもあって実装が追い付いていなかったりドキュメントも揃っていなかったり
とシンドい状況ｗ ここ2日程で集めた情報を整理するためにも 2013年 OpenStack アド
ベントカレンダーに参加させてもらいますー。&lt;/p&gt;
&lt;h2 id=&#34;参考資料のまとめ&#34;&gt;参考資料のまとめ&lt;/h2&gt;
&lt;p&gt;まずは公式 wiki ページ。逆に言うとここに記されている以上の情報は無いんじゃ？あ
とはコード読め！の世界かも..。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.openstack.org/wiki/Ironic&#34;&gt;https://wiki.openstack.org/wiki/Ironic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;devtest_undercloud です。上の資料の中でも手順の中で度々こちらにジャンプしている。
同じく incubator プロジェクトの TrippleO のデベロッパ用ドキュメントになっている。
上記の公式 wiki の情報を合わせ読むことで Ironic を使ったデプロイの手順に仕上がります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org/developer/tripleo-incubator/devtest_undercloud.html&#34;&gt;http://docs.openstack.org/developer/tripleo-incubator/devtest_undercloud.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ソースコードとドキュメント。あとでドキュメント作成方法を記しますが、こちらを取
得して作成します。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/openstack/ironic&#34;&gt;https://github.com/openstack/ironic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ドキュメントサイト。まだ情報が揃っていません。よって上の github から取得したモ
ノからドキュメントを作る方法を後で書きます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org/developer/ironic/&#34;&gt;http://docs.openstack.org/developer/ironic/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;launchpad サイト。全てのバグ情報やブループリント等が閲覧出来ます。まだ絶賛開発
中なので読む必要があると思います。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://launchpad.net/ironic&#34;&gt;https://launchpad.net/ironic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ドキュメントを作る
+++&lt;/p&gt;
&lt;p&gt;公式 ドキュメントサイトは一応、上記の通りあるのですが、ドキュメントも絶賛執筆
中ということで所々抜けがあります。また公式ドキュメントサイトがどのスパンで更新
されているか分からないので、いち早く情報をゲットしたい場合ドキュメントを作る必
要があると思います。ということで、その作り方を記していきます。尚、公式 wiki サ
イトにも手順が載っていますが Vagrant と Apache を用いた方法になっているので、
普通に Ubuntu サーバが手元にある環境を想定して読み替えながら説明していきます。&lt;/p&gt;
&lt;p&gt;必要なパッケージのインストールを行います。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install -y git python-dev swig libssl-dev python-pip &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  libmysqlclient-dev libxml2-dev libxslt-dev libxslt1-dev python-mysqldb &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  libpq-dev
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo pip install virtualenv setuptools-git flake8 tox
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo easy_install nose
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ソースコード・ドキュメントを取得します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>sensu-chef で監視システム Sensu を管理 #2</title>
      <link>https://jedipunkz.github.io/post/2013/11/27/sensu-chef-deploy-2/</link>
      <pubDate>Wed, 27 Nov 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/11/27/sensu-chef-deploy-2/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;以前、Sensu を Chef で管理する方法について書きました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/06/20/sensu-chef-controll/&#34;&gt;http://jedipunkz.github.io/blog/2013/06/20/sensu-chef-controll/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;これは今年(2013)の6月頃の記事ですが、この時はまだ sensu-chef を include して使う別の Chef
Cookbook が必要でした。また Redis 周りの Cookbooks が完成度あまく、またこれも
公式とは別の Cookbooks を改修して再利用する形でした。この作業は結構しんどかっ
た記憶があるのですが、最近 GlideNote さんのブログを読んで( ﾟдﾟ)ﾊｯ!と思い、
sensu-chef を再確認したのですが、だいぶ更新されていました。&lt;/p&gt;
&lt;p&gt;下記が sensu-chef です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/sensu/sensu-chef&#34;&gt;https://github.com/sensu/sensu-chef&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この Chef Cookbook 単体で利用できる形に更新されていて、plugins, checks 等は
Recipe に追記することで対応可能になっていました。早速利用してみたので簡単に使
い方を書いていきます。&lt;/p&gt;
&lt;p&gt;下記が Sensu の管理画面です。最終的にこの画面に監視対象のアラートが上がってきます。&lt;/p&gt;
&lt;p&gt;{% img /pix/sensu.png %}&lt;/p&gt;
&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;
&lt;p&gt;sensu-chef を取得する。chef-repo になっています。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% git clone https://github.com/sensu/sensu-chef.git ~/chef-repo-sensu
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;bundle にて Gemfile に記述の在る gem パッケージをインストールします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd ~/chef-repo-sensu
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% bundle install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;.chef/ 配下の設定は割愛します。chef サーバの情報に合わせて設定します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vyatta で Mac 用 TimeMachine サーバ兼ファイルサーバを構築！</title>
      <link>https://jedipunkz.github.io/post/2013/11/26/vyatta-timemachine-netatalk/</link>
      <pubDate>Tue, 26 Nov 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/11/26/vyatta-timemachine-netatalk/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;自宅ルータを Vyatta で運用しているのですが、諸電力な筐体に交換した際に HDD ス
ロットが余っていたので HDD を一本さしてみました。もったいないので Netatalk を
インストールして Mac 用の TimeMachine サーバにするか！そんでもってファイルサー
バ兼務にしよう！と思い立って作業したら簡単に出来たので共有します。&lt;/p&gt;
&lt;p&gt;Vyatta はご存知の通り Debian Gnu/Linux がベースになっているのでパッケージレポ
ジトリを追加してちょちょいで設定出来ます。&lt;/p&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;
&lt;p&gt;電源を通して Disk を追加します。その後起動。私は 3TB Disk が余っていたのでそれ
を挿しました。&lt;/p&gt;
&lt;p&gt;debian wheezy のパッケージレポジトリを Vyatta に追記します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% configure
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# set system package repository debian url http://ftp.jp.debian.org/debian&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# set system package repository debian distribution wheezy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# set system package repository debian components &amp;#34;main contrib&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# commit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# save&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# exit &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;netatalk, avahi をインストールする。その際に libgcrypt11 のバージョン 1.5.0 が
必要になるのでインストールすること。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Havana を Chef でデプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/11/17/openstack-havana-chef-deploy/</link>
      <pubDate>Sun, 17 Nov 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/11/17/openstack-havana-chef-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;毎度お馴染みになった OpenStack の Chef によるデプロイですが、今回は OpenStack
Havana 構成を Chef でデプロイする方法についてです。使用するのは今回も
rcbops/chef-cookbooks です。ブランチは &amp;lsquo;havana&amp;rsquo; を用います。&lt;/p&gt;
&lt;p&gt;早速ですが構成について。4.1.2 辺りからだと思うのですが構成の前提が物理ネットワー
ク4つを前提にし始めました。public, external (VM) を別ける必要が出てきました。
通信の特性も異なるので (public は public API を。external は VM 用) 、別けるの
が得策かもしれません。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                  +--------------+------------------------------------------------------- external
                  |              |
+--------------+--(-----------+--(-----------+--------------+---------------------------- public
|              |  |           |  |           |              |
+------------+ +------------+ +------------+ +------------+ +------------+ +------------+
| controller | |  network   | |  network   | |  compute   | |  compute   | | workstation|
+------------+ +------------+ +------------+ +------------+ +------------+ +------------+
|              |  |           |  |           |  |           |  |           |
+--------------+--(-----------+--(-----------+--(-----------+--(-----------+------------- management
                  |              |              |              |
                  +--------------+--------------+--------------+------------------------- guest
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;上記の構成の特徴&#34;&gt;上記の構成の特徴&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;4つの物理ネットワークを前提&lt;/li&gt;
&lt;li&gt;public ネットワーク : 外部 API 用ネットワーク&lt;/li&gt;
&lt;li&gt;external ネットワーク : インスタンス外部接続用ネットワーク&lt;/li&gt;
&lt;li&gt;guest ネットワーク : インスタンス内部用ネットワーク&lt;/li&gt;
&lt;li&gt;management ネットワーク : 各コンポーネント接続用ネットワーク&lt;/li&gt;
&lt;li&gt;public, external のみグローバルネットワーク&lt;/li&gt;
&lt;li&gt;controller : 2 nics, network : 4 nics, compute : 3nics の構成&lt;/li&gt;
&lt;li&gt;controller はシングル構成&lt;/li&gt;
&lt;li&gt;network ノードは台数拡張可能, agent 単位でノード間移動可能&lt;/li&gt;
&lt;li&gt;compute ノードも台数拡張可能&lt;/li&gt;
&lt;li&gt;workstation は chef-repo の所在地, management ネットワークに所属&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;各ノードの準備&#34;&gt;各ノードの準備&lt;/h2&gt;
&lt;p&gt;OS インストール後、各ノードのネットワークインターフェースの設定を下記の通り行っ
てください。また LVM を使うのであれば cinder ボリュームの設定も必要になってきます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>第2回 Elasticsearch 勉強会参加レポート</title>
      <link>https://jedipunkz.github.io/post/2013/11/13/elasticsearch-second-study-report/</link>
      <pubDate>Wed, 13 Nov 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/11/13/elasticsearch-second-study-report/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;第2回 Elasticsearch 勉強会に参加してきました。箇条書きですが参加レポートを記し
ておきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;開催日 : 2013/11/12
場所 : 東京駅 グラントウキョウサウスタワー リクルートテクノロジーズさま
URL : http://elasticsearch.doorkeeper.jp/events/6532
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;routing-周りの話&#34;&gt;Routing 周りの話&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;株式会社シーマーク　大谷純さん (@johtani)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;index-構成&#34;&gt;Index 構成&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;cluster の中に index -&amp;gt; type が作成される&lt;/li&gt;
&lt;li&gt;index は shard という部分的な index の集まり&lt;/li&gt;
&lt;li&gt;shard 数は生成時のみ指定可能&lt;/li&gt;
&lt;li&gt;node ごとに replica, primary を別ける&lt;/li&gt;
&lt;li&gt;replica 数は後に変えられる&lt;/li&gt;
&lt;li&gt;doc -&amp;gt; hash 値を shard 数で割って replica, primary に登録&lt;/li&gt;
&lt;li&gt;doc の id の ハッシュ値を利用&lt;/li&gt;
&lt;li&gt;type も含める場合はかの設定を true に&lt;/li&gt;
&lt;li&gt;クライアントはどのノードに対してクエリを投げても OK&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;routing&#34;&gt;routing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;id の代わりに routing (URL パラメータ) で登録&lt;/li&gt;
&lt;li&gt;url リクエストパラメータとして登録時にルーティングパラメータを登録&lt;/li&gt;
&lt;li&gt;id の代わりにパラメータで指定された値のハッシュ値を計算して利用&lt;/li&gt;
&lt;li&gt;検索時 routing 指定で関係のある shard のみを指定出来る&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;スケールアウト&#34;&gt;スケールアウト&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;sharding によるスケールアウト数 = インデックス作成時に指定&lt;/li&gt;
&lt;li&gt;shard によるインデックスの分割以外にインデックス自体を複数持つことによるスケール&lt;/li&gt;
&lt;li&gt;複数のドキュメントをエイリアス書けることが可能&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;所感&#34;&gt;所感&lt;/h4&gt;
&lt;p&gt;個人的には非常に興味のあるところでした。mongodb のような sharding をイメージし
てよいのか？そうでないのか？すら理解出来ていなかったので。sharding を理解する
前提知識の話もあって非常に参考になりました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serf を使ってみた</title>
      <link>https://jedipunkz.github.io/post/2013/11/10/serf/</link>
      <pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/11/10/serf/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;僕は Chef 使いなのですが、Chef はオーケストレーションまで踏み込んだツールでは
ないように思います。せいぜいインテグレーションが出来る程度なのかなぁと。
しかもインテグレーションするにも Cookbooks の工夫が必要です。以前聞いたことの
ある話ですが Opscode 社のエンジニア曰く「オーケストレーション等へのアプローチ
はそれぞれ好きにやってね」だそうです。&lt;/p&gt;
&lt;p&gt;個人的にオーケストレーションをテーマに色々調べようかと考えているのですが、
Serf という面白いツールが出てきました。&amp;lsquo;Serf&amp;rsquo; はオーケストレーションを手助けし
てくれるシンプルなツールになっています。&lt;/p&gt;
&lt;p&gt;もう既にいろんな方が Serf について調べていますが、どのような動きをするのかを自
分なりに理解した点を記しておこうと思います。&lt;/p&gt;
&lt;h2 id=&#34;参考にしたサイト&#34;&gt;参考にしたサイト&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;公式サイト &lt;a href=&#34;http://www.serfdom.io/&#34;&gt;http://www.serfdom.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;クラスメソッド開発者ブログ &lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/serf_on_ec2/&#34;&gt;http://dev.classmethod.jp/cloud/aws/serf_on_ec2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Glidenote さん &lt;a href=&#34;http://blog.glidenote.com/blog/2013/10/30/serf-haproxy/&#34;&gt;http://blog.glidenote.com/blog/2013/10/30/serf-haproxy/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;serf-とは&#34;&gt;Serf とは&lt;/h2&gt;
&lt;p&gt;Serf は gossip protocol をクラスタにブロードキャストする。gossip protocol は
SWIM : Scalable Weakly-consistent Infecton-style process Group Membership
Protocol” をベースとして形成されている。&lt;/p&gt;
&lt;h2 id=&#34;swim-protocol-概略&#34;&gt;SWIM Protocol 概略&lt;/h2&gt;
&lt;p&gt;serf は新しいクラスタとして稼働するか、既存のクラスタに ‘join’ する形で稼働
するかのどちらかで起動する。&lt;/p&gt;
&lt;p&gt;新しいメンバは TCP で状態を &amp;lsquo;full state sync&amp;rsquo; され既存のクラスタ内にて
‘gossipin (噂)される。この ’gosiping’ は UDP で通信されこれはネットワーク使
用量はノード数に比例することになる。&lt;/p&gt;
&lt;p&gt;ランダムなノードとの &amp;lsquo;full state sync&amp;rsquo; は TCP で行われるけどこれは
‘gossiping’ に比べて少い&lt;/p&gt;</description>
    </item>
    <item>
      <title>実用的な Swift 構成を Chef でデプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/10/27/swift-chef/</link>
      <pubDate>Sun, 27 Oct 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/10/27/swift-chef/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;以前、&amp;ldquo;Swift HA 構成を Chef でデプロイ&amp;rdquo; というタイトルで記事を書きました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/07/26/swift-ha-chef-deploy/&#34;&gt;http://jedipunkz.github.io/blog/2013/07/26/swift-ha-chef-deploy/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;こちらですが、Swift-Proxy, MySQL, Keystone をそれぞれ haproxy, keepalived で
HA 組みました。ですが、これは実用的なのかどうか自分でずっと考えていました。&lt;/p&gt;
&lt;p&gt;MySQL と KeepAlived はできればシングル構成にしたいのと、Swift-Proxy は HA で組
みたい。MySQL は Master/Master レプリケーション構成になり、どちらかのノードが
障害を起こし万が一復旧が難しくなった時、構築し直しがしんどくなります。かと言っ
て Swift-Proxy をシングル構成にすると今度はノード追加・削除の作業時にサービス
断が発生します。Swift-Proxy を再起動書ける必要があるからです。なので
Swift-Proxy は引き続き HA 構成にしたい。&lt;/p&gt;
&lt;p&gt;もう一点、見直したいと思っていました。&lt;/p&gt;
&lt;p&gt;日経コンピュータから出版されている &amp;ldquo;仮想化大全 2014&amp;rdquo; の記事を読んでいて
気がついたのですが。Swift には下記の通りそれぞれのサーバがあります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;swift-proxy-server&lt;/li&gt;
&lt;li&gt;swift-account-server&lt;/li&gt;
&lt;li&gt;swift-container-server&lt;/li&gt;
&lt;li&gt;swift-object-server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Swift には下記のような特徴がある事がわかりました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;swift-object&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;swift-object は swift-accout, swift-container とは物理リソースの扱いに全く異な
る特性を持っています。swift-account, swift-container はクライアントからのリクエ
ストに対して &amp;ldquo;アカウントの存在を確認&amp;rdquo;, &amp;ldquo;ACL 情報の確認&amp;rdquo; 等を行うサーバであるの
に対して swift-object はストレージ上のオブジェクトをクライアントに提供、または
逆に格納するサーバです。よって、Disk I/O の利用特性として swift-account,
container は SSD 等、高スループットの Disk を利用するケースが推奨されるのに対
して swift-object はオブジェクトの実体を格納する必要があるため Disk 容量の大き
なストレージを要する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>test-kitchen と OpenStack で Chef Cookbooks テスト (後篇)</title>
      <link>https://jedipunkz.github.io/post/2013/10/20/test-kitchen-openstack-chef-cookbooks-test-2/</link>
      <pubDate>Sun, 20 Oct 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/10/20/test-kitchen-openstack-chef-cookbooks-test-2/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;前回、OpenStack と test-kitchen を使った環境構築方法を書きました。下記の記事で
す。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/10/13/test-kitchn-openstack-chef-cookbooks-test/&#34;&gt;http://jedipunkz.github.io/blog/2013/10/13/test-kitchn-openstack-chef-cookbooks-test/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今回は実際にテストを書く方法を記していたい思います。&lt;/p&gt;
&lt;p&gt;今回使用するテストツールは下記の2つです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rspec と serverspec&lt;/li&gt;
&lt;li&gt;busser-bats&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考資料&#34;&gt;参考資料&lt;/h2&gt;
&lt;p&gt;Creationline lab さんの資料を参考にさせて頂きました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.creationline.com/lab/2933&#34;&gt;http://www.creationline.com/lab/2933&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;用意するモノ達&#34;&gt;用意するモノ達&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack にアクセスするためのユーザ・パスワード&lt;/li&gt;
&lt;li&gt;Keystone の AUTH_URL&lt;/li&gt;
&lt;li&gt;テストに用いる OS イメージの Image ID&lt;/li&gt;
&lt;li&gt;テナント ID&lt;/li&gt;
&lt;li&gt;nova 管理のキーペアの作成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらは OpenStack を普段から利用されている方なら馴染みのモノかと思います。&lt;/p&gt;
&lt;h2 id=&#34;kitchenyml-ファイルの作成&#34;&gt;.kitchen.yml ファイルの作成&lt;/h2&gt;
&lt;p&gt;下記の通り .kitchen.yml ファイルを test-kitchen のルートディレクトリで作成しま
す。今後の操作は全てこのディレクトリで作業行います。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&amp;lt;&amp;gt;&amp;rdquo; で括った箇所が環境に合わせた設定になります。&lt;/p&gt;
&lt;p&gt;また、ここでは前回同様に &amp;rsquo;ntp&amp;rsquo; の Cookbook をテストする前提で記します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;+++&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;driver_plugin&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;openstack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;suites&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;run_list&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#ae81ff&#34;&gt;recipe[ntp::default]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;attributes&lt;/span&gt;: {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;platforms&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ubuntu-12.04&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;driver_config&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;openstack_username&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_api_key&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;openstack_password&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_auth_url&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http://&amp;lt;openstack_ip_addr&amp;gt;:5000/v2.0/tokens&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;image_ref&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;image_id&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;flavor_ref&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;key_name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;key_name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_tenant&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;tenant_name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;ssh_username&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;private_key_path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;path_to_secretkey&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;centos-64&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;driver_config&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;openstack_username&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_api_key&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;openstack_password&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_auth_url&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http://&amp;lt;openstack_ip_addr&amp;gt;:5000/v2.0/tokens&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;image_ref&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;image_id&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;flavor_ref&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;key_name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;key_name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;openstack_tenant&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;tenant_name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;username&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;ssh_username&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;private_key_path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;path_to_secretkey&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;busser-bats テスト
+++&lt;/p&gt;</description>
    </item>
    <item>
      <title>test-kitchen と OpenStack で Chef Cookbooks テスト(前篇)</title>
      <link>https://jedipunkz.github.io/post/2013/10/13/test-kitchn-openstack-chef-cookbooks-test/</link>
      <pubDate>Sun, 13 Oct 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/10/13/test-kitchn-openstack-chef-cookbooks-test/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;test-kitchen + Vagrant を利用して複数環境で Chef Cookbooks のテストを行う方法は
結構皆さん利用されていると思うのですが Vagrant だと手元のマシンに仮想マシンが
バシバシ立ち上げるので僕はあまり好きではないです。そこで、OpenStack のインスタ
ンスをその代替で使えればいいなぁと結構前から思っていたのですが、今回うまくいっ
たのでその方法を記します。&lt;/p&gt;
&lt;h2 id=&#34;用意するモノ&#34;&gt;用意するモノ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack 環境一式&lt;/li&gt;
&lt;li&gt;Chef がインストールされた OS イメージとその ID&lt;/li&gt;
&lt;li&gt;test-kitchen を実行するワークステーション (お手持ちの Macbook 等)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OS イメージの作成ですが Veewee などで自動構築できますし、インスタンス上で Chef
のインストールを行った後にスナップショットを作成してそれを利用しても構いません。&lt;/p&gt;
&lt;h2 id=&#34;test-kitchen-のインストール&#34;&gt;test-kitchen のインストール&lt;/h2&gt;
&lt;p&gt;test-kitchen をインストールします。versoin 1.0.0 はまだリリースされていないの
で github から master ブランチを取得してビルドします。直近で OpenStack に関連
する不具合の修正等が入っているのでこの方法を取ります。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% git clone https://github.com/opscode/test-kitchen.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd test-kitchen
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% bundle install
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% rake build &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;--- gem をビルド&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% gen install ./pkg/test-kitchen-1.0.0.dev.gem
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;現時点 (2013/10/13) で berkshelf の利用しているソフトウェアと衝突を起こす問題
があるので bundle で解決します。下記のように Gemfile に gem
&amp;lsquo;kitchen-openstack&amp;rsquo; と記述します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GlusterFS の各クラスタタイプ構築</title>
      <link>https://jedipunkz.github.io/post/2013/10/12/glusterfs-install/</link>
      <pubDate>Sat, 12 Oct 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/10/12/glusterfs-install/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;GlusterFS をちょっと前に調べてました。何故かと言うと OpenStack Havana がもうす
ぐリリースされるのですが、Havana から GlusterFS がサポートされる予定だからです。&lt;/p&gt;
&lt;p&gt;この辺りに色々情報が載っています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.gluster.org/category/openstack/&#34;&gt;http://www.gluster.org/category/openstack/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;その前に GlusterFS を構築出来ないといけないので、今回はその方法を書いていきま
す。各クラスタタイプ毎に特徴や構築方法が異なるのでその辺りを重点的に。&lt;/p&gt;
&lt;h2 id=&#34;環境&#34;&gt;環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu Server 12.04.3 LTS&lt;/li&gt;
&lt;li&gt;PPA レポジトリ利用&lt;/li&gt;
&lt;li&gt;/dev/sdb を OS 領域とは別の disk としてサーバに追加する&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;用いる-ppa-レポジトリ&#34;&gt;用いる PPA レポジトリ&lt;/h2&gt;
&lt;p&gt;Ubuntu 12.04.3 LTS の GlusterFS バージョンは 3.2 です。3.4 系が今回使いたかっ
たので下記の PPA レポジトリを利用させてもらいます。ちゃんと構築するなら自分で
パッケージを作成することをオススメします。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://launchpad.net/~semiosis/&amp;#43;archive/ubuntu-glusterfs-3.4&#34;&gt;https://launchpad.net/~semiosis/+archive/ubuntu-glusterfs-3.4&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;準備&#34;&gt;準備&lt;/h1&gt;
&lt;p&gt;ここからの手順は全てのサーバで操作します。&lt;/p&gt;
&lt;h2 id=&#34;レポジトリの利用方法&#34;&gt;レポジトリの利用方法&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo aptitude install python-software-properties
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo add-apt-repository ppa:semiosis/ubuntu-glusterfs-3.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;glusterfs34-のインストール&#34;&gt;GlusterFS3.4 のインストール&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install glusterfs-server gluserfs-client
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;xfsprogs-のインストール&#34;&gt;xfsprogs のインストール&lt;/h2&gt;
&lt;p&gt;glusterfs は xfs を扱うため xfsprogs をインストールする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Methos アーキテクチャ #2 (Docker on Mesos)</title>
      <link>https://jedipunkz.github.io/post/2013/10/01/methos-architecture-number-2-docker-on-mesos/</link>
      <pubDate>Tue, 01 Oct 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/10/01/methos-architecture-number-2-docker-on-mesos/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Mesos アーキテクチャについて2つめの記事です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/09/28/mesos-architecture-number-1/&#34;&gt;http://jedipunkz.github.io/blog/2013/09/28/mesos-architecture-number-1/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上記の前回の記事で Mesos 自体のアーキテクチャについて触れましたが、今回は
Mesos + Marathon + Docker の構成について理解したことを書いていこうと思います。&lt;/p&gt;
&lt;p&gt;mesos クラスタは 幾つかの mesos masters と沢山の mesos slaves から成っており、
mesos slaves の上では docker を操作する executor が稼働している。marathon は
mesos master の上で稼働する mesos framework である。init や upstart の様な存在
であることが言え、REST API を持ち container の動作を制御する。marathon には
ruby の client 等も存在する。下記がそれ。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mesosphere/marathon_client&#34;&gt;https://github.com/mesosphere/marathon_client&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-----------------+
| docker registry | index.docker.io (もしくは local registry)
+-----------------+
|
+----------------+
|                |
+--------------+ +--------------+
| mesos master | | mesos master |
+--------------+ +--------------+
|                |
|----------------+-----------------------------------|

+--------------+ +--------------+     +--------------+
| mesos slave  | | mesos slave  | ... | mesos slave  | 
+--------------+ +--------------+     +--------------+
|                |                    |
+--------------+ +--------------+     +--------------+
| mesos slave  | | mesos slave  | ... | mesos slave  | 
+--------------+ +--------------+     +--------------+
.                .                    .
.                .                    .
.                .                    .
+--------------+ +--------------+     +--------------+
| mesos slave  | | mesos slave  | ... | mesos slave  |
+--------------+ +--------------+     +--------------+
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;オファから-docker-が稼働するまでの流れ&#34;&gt;オファから docker が稼働するまでの流れ&lt;/h2&gt;
&lt;p&gt;上記の構成の図を見ながら理解していきましょう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DevOps Day Tokyo 2013 参加レポート</title>
      <link>https://jedipunkz.github.io/post/2013/09/29/devops-day-tokyo-2013-report/</link>
      <pubDate>Sun, 29 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/29/devops-day-tokyo-2013-report/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;DevOps Day Tokyo 2013 に参加してきました。たくさんの刺激を受けたのでレポート書
いておきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;開催日 : 2013年09月28日
場所   : 東京六本木ミッドタウン Yahoo! Japan さま
URL    : http://www.devopsdays.org/events/2013-tokyo/
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;making-operation-visible&#34;&gt;Making Operation Visible&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;Nick Galbreath (@ngalbreath) さん
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DevOps の拠点 Etsy に努めた経緯のある DevOps リーダ Galbreath さん。DevOps の
概略から何が必要でありどう行動に起こせばよいか説明してくださいました。&lt;/p&gt;
&lt;iframe src=&#34;http://www.slideshare.net/slideshow/embed_code/26632342&#34;
width=&#34;427&#34; height=&#34;356&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34;
scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC;border-width:1px 1px
0;margin-bottom:5px&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div
style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a
href=&#34;https://www.slideshare.net/nickgsuperstar/making-operations-visible-dev-opsdays-tokyo-2013key&#34;
title=&#34;Making operations visible - devopsdays tokyo 2013&#34;
target=&#34;_blank&#34;&gt;Making operations visible - devopsdays tokyo 2013&lt;/a&gt;
&lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;http://www.slideshare.net/nickgsuperstar&#34;
target=&#34;_blank&#34;&gt;Nick Galbreath&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;
&lt;p&gt;こちら、Galbreath さんの当日の資料。&lt;/p&gt;
&lt;h2 id=&#34;devops-が実行出来ない理由&#34;&gt;DevOps が実行出来ない理由&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tool が足りない&lt;/li&gt;
&lt;li&gt;社風の影響&lt;/li&gt;
&lt;li&gt;見えないモノが価値がないと事業から考えられている&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;出来る事は、価値があるモノの社内への説明と、Tool を使った可視化。データの可視
化が重要。Ops の人は結構「データをどこそこの部署に見せても理解してもらえない」
だとか「データを閲覧させると万が一の時にシステムが破損する」等と考えがち。が、
ビジネス寄りの人にとって重要なグラフが含まれていたり、アカウント担当の人に役立
つものも含まれている。ましてシステムが破損することなど決して無い。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mesos アーキテクチャ #1</title>
      <link>https://jedipunkz.github.io/post/2013/09/28/mesos-architecture-number-1/</link>
      <pubDate>Sat, 28 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/28/mesos-architecture-number-1/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今回はクラスタマネージャである Mesos について書こうと思います。&lt;/p&gt;
&lt;p&gt;Mesos は Apache Software Foundation によって管理されるソフトウェアで分散アプリ
ケーションをクラスタ化することが出来るマネージャです。Twitter が採用しているこ
とで有名だそうで、開発にも積極的に参加しているそうです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://mesos.apache.org/&#34;&gt;http://mesos.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;@riywo さんが既に Mesos + Marathon + Zookeper + Docker な構成を組む手順をブロ
グで紹介されていますので是非試してみると面白いと思います。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://tech.riywo.com/blog/2013/09/27/mesos-introduction-1/&#34;&gt;http://tech.riywo.com/blog/2013/09/27/mesos-introduction-1/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;私は理解した Mesos のアーキテクチャについて少し書いていきたいと思います。&lt;/p&gt;
&lt;h2 id=&#34;全体の構造&#34;&gt;全体の構造&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+-----------+
| zookeeper |
|  quorum   |
+-----------+
|
+----------------+----------------+
|                |                |
+--------------+ +--------------+ +--------------+
| mesos-master | | mesos-master | | mesos-master |
|    active    | |  hot standby | |  hot standby |
+--------------+ +--------------+ +--------------+ ...
|
+----------------+----------------+
|                |                |
+--------------+ +--------------+ +--------------+
|  mesos-slave | |  mesos-slave | |  mesos-slave |
|   executor   | |   executor   | |   executor   |
| +----++----+ | | +----++----+ | | +----++----+ |
| |task||task| | | |task||task| | | |task||task| |
| +----++----+ | | +----++----+ | | +----++----+ |
+--------------+ +--------------+ +--------------+ ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;基本的に few masters + many slaves の構成です。task は slaves の上で走ります。
master はオファーによりアプリケーション(フレームワーク)に対して CPU, メモリの
リソースをシェア出来ます。リソースは slave ID, resource1: amount1,
resource2, amount2, &amp;hellip; といった配列を含みます。master はポリシに従いそれぞれ
のフレームワークに対してリソースをどれだけ提供するか決定します。プラグイン形式
で様々なポリシを取り込む仕組みになっています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef で kibana &#43; elasticsearch &#43; fluentd デプロイしてみた</title>
      <link>https://jedipunkz.github.io/post/2013/09/13/chef-kibana-elasticsearch-fluentd/</link>
      <pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/13/chef-kibana-elasticsearch-fluentd/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;前回 kibana + elasticsearch + fluentd を構築する方法を載せたのだけど手動で構築
したので格好悪いなぁと思っていました。いうことで！ Chef でデプロイする方法を調
べてみました。&lt;/p&gt;
&lt;p&gt;意外と簡単に出来たし、スッキリした形でデプロイ出来たのでオススメです。&lt;/p&gt;
&lt;h2 id=&#34;前提の環境は&#34;&gt;前提の環境は&amp;hellip;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 12.04 LTS precise&lt;/li&gt;
&lt;li&gt;Chef サーバ構成&lt;/li&gt;
&lt;li&gt;入力するログは nginx (例)&lt;/li&gt;
&lt;li&gt;オールインワン構成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cookbook が他の OS に対応しているか確認していないので Ubuntu を前提にしていま
す。Chef サーバのデプロイや knife の設定は済んでいるものとして説明していきます。
例で nginx のログを入力します。なので nginx も Chef でデプロイします。ここは他
のものに置き換えてもらっても大丈夫です。手順を省略化するためオールインワン構成
で説明します。nginx, fluentd は複数のノードに配置することも手順を読み替えれば
もちろん可能です。&lt;/p&gt;
&lt;h2 id=&#34;cookbook-の準備&#34;&gt;Cookbook の準備&lt;/h2&gt;
&lt;p&gt;お決まり。Cookbooks の取得に Berkshelf を用いる。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd chef-repo
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% gem install berkshelf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;EDITOR&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; Berksfile
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cookbook &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elasticsearch&amp;#39;&lt;/span&gt;, git: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://github.com/elasticsearch/cookbook-elasticsearch.git&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cookbook &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;td-agent&amp;#39;&lt;/span&gt;, git: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://github.com/treasure-data/chef-td-agent.git&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cookbook &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kibana&amp;#39;&lt;/span&gt;, git: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://github.com/realityforge/chef-kibana.git&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cookbook &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nginx&amp;#39;&lt;/span&gt;, git: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://github.com/opscode-cookbooks/nginx.git&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Cookbooks を取得します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>第14回 OpenStack 勉強会参加ログ</title>
      <link>https://jedipunkz.github.io/post/2013/09/09/14th-openstack-study-hackathon/</link>
      <pubDate>Mon, 09 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/09/14th-openstack-study-hackathon/</guid>
      <description>&lt;p&gt;こんにちは。@jedipunkz です。&lt;/p&gt;
&lt;p&gt;OpenStack 第14回勉強会 ハッカソンに参加してきました。その時の自分の作業ログを
記しておきます。自分の作業内容は &amp;lsquo;OpenStack + Docker 構築&amp;rsquo; です。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;場所 : CreationLine さま
日時 : 2013年9月8日(土)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当日の atnd。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://atnd.org/events/42891&#34;&gt;http://atnd.org/events/42891&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当日発表のあった内容&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ansible で OpenStack を実際に皆の前でデプロイ！&lt;/li&gt;
&lt;li&gt;Yoshiyama さん開発 LogCas お披露目&lt;/li&gt;
&lt;li&gt;Havana の機能改善・機能追加内容確認&lt;/li&gt;
&lt;li&gt;その他 Horizon の機能についてだったり openstack.jp の運用についてなど&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自分が話を聞きながら黙々とやったことは&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack + Docker 構築&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;結果&amp;hellip; NG 動かず。時間切れ。公式の wiki の手順がだいぶ変なので手順を修正しながら進めました。&lt;/p&gt;
&lt;p&gt;公式の wiki はこちらにあります。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.openstack.org/wiki/Docker&#34;&gt;https://wiki.openstack.org/wiki/Docker&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;その修正しながらメモった手順を下記に貼り付けておきます。&lt;/p&gt;
&lt;h2 id=&#34;作業環境&#34;&gt;作業環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ホスト : Ubuntu 12.04.3 Precise&lt;/li&gt;
&lt;li&gt;OpenStack バージョン : devstack (2013/09/08 master ブランチ)&lt;/li&gt;
&lt;li&gt;構成 : オールインワン (with heat, ceilometer, neutron)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;普通に動かすとエラーが出力される&#34;&gt;普通に動かすとエラーが出力される&lt;/h2&gt;
&lt;p&gt;これは devstack (2013/09/08 時点) での不具合なので直ちに修正されるかも。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kibana3 &#43; elasticsearch &#43; fluentd を試した</title>
      <link>https://jedipunkz.github.io/post/2013/09/08/kibana3-plus-elasticsearch-plus-fluentd/</link>
      <pubDate>Sun, 08 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/08/kibana3-plus-elasticsearch-plus-fluentd/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;{% img /pix/kibana3.png %}&lt;/p&gt;
&lt;p&gt;前回の記事で Kibana + elasticsearch + fluentd を試しましたが、ツイッターで
@nora96o さんに &amp;ldquo;Kibana3 使うと、幸せになれますよ！&amp;rdquo; と教えてもらいました。早
速試してみましたので、メモしておきます。&lt;/p&gt;
&lt;p&gt;前回の記事。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2013/09/07/kibana-plus-elasticsearch-plus-fluentd/&#34;&gt;http://jedipunkz.github.io/blog/2013/09/07/kibana-plus-elasticsearch-plus-fluentd/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前半の手順は前回と同様ですが、念のため書いておきます。&lt;/p&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS : Ubuntu 12.04 Precise (同じ方法で 13.04 Raring でも出来ました)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;必要なパッケージのインストール&#34;&gt;必要なパッケージのインストール&lt;/h2&gt;
&lt;p&gt;下記のパッケージを事前にインストールします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install git-core build-essential ruby1.9.3 openjdk-7-jdk
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;手順を省くために Ruby はパッケージで入れました。また Java は他の物を利用しても
構いません。Ruby は fluentd が、Java は elasticsearch が必要とします。&lt;/p&gt;
&lt;h2 id=&#34;elasticsearch-のインストール&#34;&gt;elasticsearch のインストール&lt;/h2&gt;
&lt;p&gt;下記のサイトより elasticsearch をダウンロードします。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.elasticsearch.org/download/&#34;&gt;http://www.elasticsearch.org/download/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;現時点 (2013/09/08) で最新のバージョンは 0.90.3 でした。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-0.90.3.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo dpkg -i elasticsearch-0.90.3.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo service elasticsearch start
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;fluentd-のインストール&#34;&gt;fluentd のインストール&lt;/h2&gt;
&lt;p&gt;fluentd を下記の通りインストールします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kibana &#43; ElasticSearch &#43; fluentd を試してみた</title>
      <link>https://jedipunkz.github.io/post/2013/09/07/kibana-plus-elasticsearch-plus-fluentd/</link>
      <pubDate>Sat, 07 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/07/kibana-plus-elasticsearch-plus-fluentd/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;自動化の流れを検討する中でログ解析も忘れてはいけないということで ElasticSearch
を使いたいなぁとぼんやり考えていて Logstash とか Kibana とかいうキーワードも目
に止まるようになってきました。&lt;/p&gt;
&lt;p&gt;ElasticSaerch は API で情報を検索出来たりするので自動化にもってこい。バックエ
ンドに Logstash を使って&amp;hellip; と思ってたのですが最近よく聞くようになった fluentd
をそろそろ真面目に使いたい！ということで、今回は Kibana + ElasticSearch +
fluentd の組み合わせでログ解析システムを組む方法をメモしておきます。&lt;/p&gt;
&lt;h2 id=&#34;参考にさせて頂いた-url&#34;&gt;参考にさせて頂いた URL&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://memocra.blogspot.jp/2013/04/kibanakibanaelasticsearchfluentd.html&#34;&gt;http://memocra.blogspot.jp/2013/04/kibanakibanaelasticsearchfluentd.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS : Ubuntu 12.04 Precise (同じ方法で 13.04 Raring でも出来ました)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;必要なパッケージインストール&#34;&gt;必要なパッケージインストール&lt;/h2&gt;
&lt;p&gt;下記のパッケージを事前にインストールします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install git-core build-essential ruby1.9.3 openjdk-7-jdk
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;手順を省くために Ruby はパッケージで入れました。また Java は他の物を利用しても
構いません。Ruby は Kibana, fluentd が、Java は ElasticSearch が必要とします。&lt;/p&gt;
&lt;h2 id=&#34;elasticsearch-のインストール&#34;&gt;ElasticSearch のインストール&lt;/h2&gt;
&lt;p&gt;下記のサイトより ElasticSearch をダウンロードします。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.elasticsearch.org/download/&#34;&gt;http://www.elasticsearch.org/download/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;現時点 (2013/09/07) で最新のバージョンは 0.90.3 でした。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hurricane Electric &#43; Vyatta で宅内 IPv6 化</title>
      <link>https://jedipunkz.github.io/post/2013/09/01/hurricane-electric-vyatta-ipv6/</link>
      <pubDate>Sun, 01 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/09/01/hurricane-electric-vyatta-ipv6/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;自宅の IPv6 化、したいなぁとぼんやり考えていたのですが、Hurricane Electric
Internet Services を見つけました。IPv4 の固定グローバル IP を持っていれば誰で
も IPv6 のトンネルサービスを無料で受けられるサービスです。&lt;/p&gt;
&lt;p&gt;1つのユーザで5アカウントまで取得でき (5 エンドポイント)、1アカウントで /64 の
アドレスがもらえます。また申請さえすれば (クリックするだけ) /48 も1アカウント
毎にもらえます。つまり /48 x 5 + /64 x 5 &amp;hellip; でか！&lt;/p&gt;
&lt;p&gt;私の宅内は Vyatta で PPPOE してるのですが、各種 OS (Debian, NetBSD&amp;hellip;) や機器
(Cisco, JunOS..)のコンフィギュレーションを自動生成してくれるので、接続するだけ
であればそれをターミナルに貼り付けるだけ！です。&lt;/p&gt;
&lt;h2 id=&#34;サービス-url&#34;&gt;サービス URL&lt;/h2&gt;
&lt;p&gt;Hurricane Electric は下記の URL です。アカウントもここで作成出来ます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://tunnelbroker.net&#34;&gt;http://tunnelbroker.net&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ipv6-接続性を確保する方法&#34;&gt;IPv6 接続性を確保する方法&lt;/h2&gt;
&lt;p&gt;Vyatta が IPv6 のアドレスを持ち接続性を確保するだけであれば、上に記したように
コピペで出来ます。上記の URL でアカウントを作成しログインします。左メニューの
&amp;ldquo;Create Regular Tunnel&amp;rdquo; を押して、自分の情報 (IPv4 のエンドポイントアドレス等)
を入力します。その後、取得した IPv6 のレンジのリンクをクリックし上記メニュー
&amp;ldquo;Example Configuration&amp;rdquo; を選択します。プルダウンメニューが現れるので、自宅の
OS や機器に合った名前を選択します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vyatta で L2TP over IPsec による VPN 構築</title>
      <link>https://jedipunkz.github.io/post/2013/08/24/vyatta-l2tp-ipsec-vpn/</link>
      <pubDate>Sat, 24 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/24/vyatta-l2tp-ipsec-vpn/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;以前、こんな記事をブログに記しました。2012/06 の記事です。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.io/blog/2012/06/13/vyatta-vpn/&#34;&gt;http://jedipunkz.github.io/blog/2012/06/13/vyatta-vpn/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;その後、PPTP で保護されたネットワークの VPN パスワードを奪取出来るツールが公開
されました。2012/07 のことです。よって今では VPN に PPTP を用いることが推奨さ
れていません。&lt;/p&gt;
&lt;p&gt;ということで L2TP over IPsec による VPN 構築を Vyatta で行う方法を記します。&lt;/p&gt;
&lt;h2 id=&#34;fig1--home-lan-と-vyatta-のアドレス&#34;&gt;fig.1 : home lan と vyatta のアドレス&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                +--------+                      +-----+
    home lan ---| vyatta | --- the internet --- | CPE |
                +--------+                      +-----+
    X.X.X.X/X(NAT)     pppoe0
                       Y.Y.Y.Y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;この様に X.X.X.X/X と Y.Y.Y.Y/Y が関係しているとします。CPE は VPN により
X.X.X.X/X に接続することが出来ます。&lt;/p&gt;
&lt;h2 id=&#34;手順--ipsec&#34;&gt;手順 : IPsec&lt;/h2&gt;
&lt;p&gt;下記の操作で IPsec を待ち受けるインターフェースの設定します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% configure
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# edit vpn ipsec&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# set ipsec-interface interface pppoe0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;インターフェース名は環境に合わせて設定してください。私の環境では pppoe0 です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack nova-network IPv6 対応</title>
      <link>https://jedipunkz.github.io/post/2013/08/18/openstack-nova-network-ipv6/</link>
      <pubDate>Sun, 18 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/18/openstack-nova-network-ipv6/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です&lt;/p&gt;
&lt;p&gt;今更なのかもしれませんが、OpenStack の nova-network を IPv6 対応する方法を調べ
てみました。何故 nova-network なのか? 自宅の構成が nova-network だからです..。
以前は Quantum (現 Neutron) 構成で使っていましたが、ノードをコントローラとコン
ピュートに別けた時に NIC が足らなくなり&amp;hellip;。&lt;/p&gt;
&lt;p&gt;さて本題です。下記のサイトを参考にしました。ほぼそのままの手順ですが、自分のた
めにもメモです。&lt;/p&gt;
&lt;h2 id=&#34;参考-url&#34;&gt;参考 URL&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org/grizzly/openstack-compute/admin/content/configuring-compute-to-use-ipv6-addresses.html&#34;&gt;http://docs.openstack.org/grizzly/openstack-compute/admin/content/configuring-compute-to-use-ipv6-addresses.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;前提&#34;&gt;前提&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack の構成は予め構築されている&lt;/li&gt;
&lt;li&gt;nova-network を用いている&lt;/li&gt;
&lt;li&gt;構成はオールインワンでも複数台構成でも可能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;
&lt;p&gt;nova がインストールされているすべてのノードで python-netaddr をインストールし
ます。私の場合は rcbops の chef cookbooks で構築したのですが、既にインストール
されていました。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install python-netaddr
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;nova-network が稼働しているノードで radvd をインストールします。これは
IPv6 を Advertise しているルータ等が予め備わっている環境であっても、インストー
ルする必要があります。また /etc/radvd.conf が初め無いので radvd 単体では稼働し
ませんが、問題ありません。OpenStack の場合 /var/lib/nova 配下のコンフィギュレー
ションファイルを読み込んでくれます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install radvd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;/etc/sysctl.conf に下記の記述を追記します。RA の受信とフォワーディングを許可し
ています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>rcbops Cookbooks で Neutron 構成 OpenStack</title>
      <link>https://jedipunkz.github.io/post/2013/08/16/rcbops-cookbooks-neutron-openstack/</link>
      <pubDate>Fri, 16 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/16/rcbops-cookbooks-neutron-openstack/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;rcbops Cookbooks で Neutron 構成の OpenStack をデプロイする方法を書きたいと思
います。先日紹介した openstack-chef-repo にも Neutron のレシピが含まれているの
ですが、まだまだ未完成で手作業をおりまぜながらのデプロイになっていまうので、今
現在のところ Neutron 構成を組みたいのであればこの rcbops の Cookbooks を用いる
しかないと思います。&lt;/p&gt;
&lt;p&gt;今回は VLAN モードの構築を紹介します。GRE モードも少し手順を修正すれば構成可能
です。最後のまとめに GRE モードの構築について少し触れています。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                                                                                 public network
+----------------+----------------+----------------+----------------+----------------
|                |                |                                  
+--------------+ +--------------+ +--------------+ +--------------+ +--------------+
| controller01 | |  network01   | |  network02   | |  compute01   | |  compute02   |
+--------------+ +-------+------+ +-------+------+ +-------+------+ +-------+------+
|                |       |        |       |        |       |        |       |    management network
+----------------+-------o--------+-------o--------+-------o--------+-------o--------
                         |                |                |                |    vm network
                         +----------------+----------------+----------------+--------
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;特徴は&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emacs &#43; Mew で Gmail を読み書きする</title>
      <link>https://jedipunkz.github.io/post/2013/08/12/emacs-mew-gmail/</link>
      <pubDate>Mon, 12 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/12/emacs-mew-gmail/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今日も軽めの話題を。&lt;/p&gt;
&lt;p&gt;Gmail を Emacs + Mew で読み書きする方法を何故かいつも忘れてしまうので自分のた
めにもメモしておきます。Gmail はブラウザで読み書き出来るのに！と思われるかもし
れませんが、Emacs で文章が書けるのは重要なことです。:D&lt;/p&gt;
&lt;h2 id=&#34;対象-os&#34;&gt;対象 OS&lt;/h2&gt;
&lt;p&gt;比較的新しい&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debian Gnu/Linux&lt;/li&gt;
&lt;li&gt;Ubuntu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;を使います。&lt;/p&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;
&lt;p&gt;Emacs, Mew, stunnel4 をインストールします。Emacs は好きな物を入れてください。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install emacs24-nox stunnel4 mew mew-bin ca-certificates
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;openssl コマンドで mail.pem を生成します。生成したものを /etc/stunnel 配下に設
置します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% openssl req -new -out mail.pem -keyout mail.pem -nodes -x509 -days &lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo cp mail.pem /etc/stunnel/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;stunnel はインストール直後、起動してくれないので ENABLE=1 に修正します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;EDITOR&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; /etc/default/stunnel4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ENABLE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 0 -&amp;gt; 1 へ変更&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;stunenl.conf のサンプルを /etc/stunnel 配下に設置します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Debian Unstable で stumpwm</title>
      <link>https://jedipunkz.github.io/post/2013/08/09/debian-unstable-stumpwm/</link>
      <pubDate>Fri, 09 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/09/debian-unstable-stumpwm/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Linux のウィンドウマネージャは使い続けて長いのですが、既に1周半しました。twm -&amp;gt; gnome -&amp;gt;
enlightenment -&amp;gt; OpenBox -&amp;gt;  .. 忘れた .. -&amp;gt; twm -&amp;gt; vtwm -&amp;gt; awesome -&amp;gt; kde -&amp;gt;
gnome -&amp;gt; enligtenment &amp;hellip;&lt;/p&gt;
&lt;p&gt;巷では Linux のデスクトップ環境は死んだとか言われているらしいですが、stumpwm
というウィンドウマネージャは結構いいなと思いました。タイル型のウィンドウマネー
ジャで Emacs 好きの人が開発したらしいです。設定は lisp で書けます。&lt;/p&gt;
&lt;p&gt;見た目は派手では無いのですが、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;グルーピング機能&lt;/li&gt;
&lt;li&gt;すべての操作がキーボードで出来る&lt;/li&gt;
&lt;li&gt;タイル型であるので煩わしいマウスでのウィンドウ操作が不要&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という点に惹かれました。&lt;/p&gt;
&lt;p&gt;Linux を使う時、私の場合 Debian Gnu/Linux Unstalble をいつも使うのですが、
Unstable だと apt-get install stumpwm したバイナリがコケる&amp;hellip;ということでビル
ドしてあげました。普段慣れないビルド方法だったので、その時の手順を自分のために
もメモしておきます。&lt;/p&gt;
&lt;h2 id=&#34;前提環境&#34;&gt;前提環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Debian Gnu/Linux unstable 利用&lt;/li&gt;
&lt;li&gt;X の環境は揃っている&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ビルド手順&#34;&gt;ビルド手順&lt;/h2&gt;
&lt;h4 id=&#34;clisp-をインストール&#34;&gt;clisp をインストール&lt;/h4&gt;
&lt;p&gt;clisp をインストールします。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% sudo apt-get install clisp-dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;lisp.run というファイルを stumpwm が見つけられないので symlink 張ってあげます。
ちょっと泥臭い。&lt;/p&gt;</description>
    </item>
    <item>
      <title>openstack-chef-repo で OpenStack 複数台構成をデプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/08/06/opscode-cookbooks-openstack-deploy/</link>
      <pubDate>Tue, 06 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/08/06/opscode-cookbooks-openstack-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;前回、github.com/rcbops の Cookbooks を利用した OpenStack デプロイ方法を紹介し
ました。これは RackSpace 社の Private Cloud Service で使われている Cookbooks
で Apache ライセンスの元、誰でも利用できるようになっているものです。HA 構成を
組めたり Swift の操作 (Rings 情報管理など) も Chef で出来る優れた Cookbooks な
わけですが、運用するにあたり幾つか考えなくてはならないこともありそうです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;chef-client の実行順番と実行回数が密接に関わっていること&lt;/li&gt;
&lt;li&gt;HA 構成の手動切替等、運用上必要な操作について考慮する必要性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;※ 後者については OpenStack ユーザ会の方々に意見もらいました。&lt;/p&gt;
&lt;p&gt;特に前項は Chef を利用する一番の意義である &amp;ldquo;冪等性&amp;rdquo; をある程度 (全くという意味
ではありませんが) 犠牲にしていると言えます。また chef-client の実行回数、タイ
ミング等 Cookbooks を完全に理解していないと運用は難しいでしょう。自ら管理して
いる Cookbooks なら問題ないですが、rcbops が管理しているので常に更新状況を追っ
ていく必要もありそうです。&lt;/p&gt;
&lt;p&gt;一方、Opscode, RackSpace, AT&amp;amp;T 等のエンジニアが管理している Cookbooks がありま
す。これは以前、日本の OpenStack 勉強会で私が話した &amp;lsquo;openstack-chef-repo&amp;rsquo; を利
用したモノです。github.com/stackforge の元に管理されています。
openstack-chef-repo は Berksfile, Roles, Environments のみの構成で各 Cookbooks
は Berksfile を元に取得する形になります。取得先は同じく github.com/stackforge
上で管理されています。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cobbler で OS 自動インストール</title>
      <link>https://jedipunkz.github.io/post/2013/07/28/cobbler-os-automation-install/</link>
      <pubDate>Sun, 28 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/07/28/cobbler-os-automation-install/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;最近、自動化は正義だと最近思うのですが、その手助けをしてくれるツール Cobbler
を試してみました。Cobbler と複数 OS, ディストリビューションを CLI, GUI で管理出
来るツールです。PXE, TFTP, DHCPを組分せれば OS の自動構築が出来るのは古くから
ありますが、TFTP サーバに配置するカーネルイメージやマックアドレスの管理を一元
して管理してくれるのがこの Cobbler です。&lt;/p&gt;
&lt;p&gt;今回は Cobbler の構築方法をお伝えします。本当は Chef Cookbooks で構築したかっ
たのですが Opscode Community にある Cookbooks はイマイチだったので、今回は手動
で。&lt;/p&gt;
&lt;h2 id=&#34;前提環境&#34;&gt;前提環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS は CentOSを。Ubuntu を利用すると DHCP のコンフィギュレーションを自動で出
来ません&lt;/li&gt;
&lt;li&gt;利用するネットワークの DHCP はオフにします&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;構築手順&#34;&gt;構築手順&lt;/h2&gt;
&lt;p&gt;SELINUX を無効にします。石◯さん、ごめんなさい。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ${EDITOR} /etc/sysconfig/selinux&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SELINUX&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;disabled
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# setenforce 0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;EPEL のレポジトリを追加します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# rpm -Uvh http://ftp.iij.ad.jp/pub/linux/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cobbler をインストールします。またその他必要なパッケージもここでインストールし
ます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# yum install cobbler debmirror pykickstart&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;自分の設定したいパスワードを生成して /etc/cobbler/settings 内の
default_password_crypted: に設定します。パスワードの生成は下記のように openssl
コマンドを利用します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Swift HA 構成を Chef でデプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/07/26/swift-ha-chef-deploy/</link>
      <pubDate>Fri, 26 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/07/26/swift-ha-chef-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;最近 Chef で OpenStack をデプロイすることばかりに興味持っちゃって、他のことも
やらんとなぁと思っているのですが、せっかくなので Swift HA 構成を Chef でデプロ
イする方法を書きます。&lt;/p&gt;
&lt;p&gt;Swift って分散ストレージなのに HA ってなんよ！と思われるかもしれませんが、ご存
知の様に Swift はストレージノード (accout, object, container) とプロキシノード
に別れます。今回紹介する方法だとプロキシノードを Keepalived と Haproxy で HA、
また MySQL も KeepAlived で HA の構成に出来ました。いつものように RackSpace 管
理の Cookbooks を使っています。&lt;/p&gt;
&lt;h2 id=&#34;参考資料&#34;&gt;参考資料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.rackspace.com/knowledge_center/article/openstack-object-storage-configuration&#34;&gt;http://www.rackspace.com/knowledge_center/article/openstack-object-storage-configuration&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;構成は簡単に記すと下記のようになります。特徴としては&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;swift-proxy01, swift-proxy02 で HA。VRRP + LB な構成。&lt;/li&gt;
&lt;li&gt;swift-proxy01 で git サーバ稼働。Rings 情報を管理。&lt;/li&gt;
&lt;li&gt;swift-storageNN がストレージノード&lt;/li&gt;
&lt;li&gt;OS は Ubuntu server 12.04&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;です。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;|--------- VRRP + Load Balancer ------|

+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+
|  swift-proxy01  | |  swift-proxy02  | | swift-storage01 | | swift-storage02 | | swift-storage03 |
+-----------------+ +-----------------+ +-----------------+ +-----------------+ +-----------------+
|                   |                   |                   |                   |
+-------------------+-------------------+-------------------+-------------------+------------------
|                   |
+-----------------+ +-----------------+
| chef workstation| |   chef server   |
+-----------------+ +-----------------+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;絵は書く意味なかったか&amp;hellip;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack HA 構成を Chef でデプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/07/17/openstach-ha-chef-deploy/</link>
      <pubDate>Wed, 17 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/07/17/openstach-ha-chef-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;OpenStack を運用する中でコントローラは重要です。コントローラノードが落ちると、
仮想マシンの操作等が利用出来ません。コントローラの冗長構成を取るポイントは公式
wiki サイトに記述あるのですが PaceMaker を使った構成でしんどいです。何より運用
する人が混乱する仕組みは避けたいです。&lt;/p&gt;
&lt;p&gt;RackSpace 社の管理している Chef Cookbooks の Roles に &amp;lsquo;ha-controller1&amp;rsquo;,
&amp;lsquo;ha-controller2&amp;rsquo; というモノがあります。今回はこれを使った HA 構成の構築方法に
ついて書いていこうかと思います。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;最小構成を作りたいと思います。HA のためのコントローラノード2台, コンピュートノー
ド1台, Chef ワークショテーション1台, Chef サーバノード1台。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+----------------+----------------+----------------+----------------+--------------- public network
|                |                | eth0           |                |                10.0.0.0/24
+--------------+ +--------------+ +--------------+ +--------------+ +--------------+
| controller01 | | controller01 | |  compute01   | | chef server  | | workstation  |
+--------------+ +--------------+ +--------------+ +--------------+ +--------------+
                                  | eth1
                                  +------------------------------------------------- fixed range network
                                                                                     172.16.0.0/24
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;特徴&#34;&gt;特徴&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;controller01&amp;rsquo;, &amp;lsquo;controller02&amp;rsquo; で HA 化コントローラ&lt;/li&gt;
&lt;li&gt;&amp;lsquo;compute01&amp;rsquo; はコンピュートノード&lt;/li&gt;
&lt;li&gt;&amp;lsquo;chef server&amp;rsquo; は Chef サーバ、Chef11 推奨&lt;/li&gt;
&lt;li&gt;ほとんどの作業を行う &amp;lsquo;workstaion&amp;rsquo; は Chef ワークステーション&lt;/li&gt;
&lt;li&gt;nova-network 構成&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chef-サーバの構築&#34;&gt;Chef サーバの構築&lt;/h2&gt;
&lt;p&gt;Chef サーバの構築方法は本題から外れるので割愛します。今は Omnibus インストーラで一発です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef で OpenStack デプロイ</title>
      <link>https://jedipunkz.github.io/post/2013/07/08/chef-openstack-deploy/</link>
      <pubDate>Mon, 08 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/07/08/chef-openstack-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;前回の記事で OpenCenter を使った OpenStack デプロイを行いましたが、デプロイの
仕組みの実体は Opscode Chef です。慣れている人であれば Chef を単独で使った方が
よさそうです。僕もこの方法を今後取ろうと思っています。&lt;/p&gt;
&lt;p&gt;幾つかの構成を試している最中ですが、今回 nova-network を使ったオールインワン構
成を作ってみたいと思います。NIC の数は1つです。ノート PC や VPS サービス上にも
構築できると思いますので試してみてください。&lt;/p&gt;
&lt;p&gt;今回は Chef サーバの構築や Knife の環境構築に関しては割愛します。&lt;/p&gt;
&lt;p&gt;また全ての操作は workstation ノードで行います。皆さんお手持ちの Macbook 等です。
デプロイする先は OpenStack をデプロイするサーバです。&lt;/p&gt;
&lt;h2 id=&#34;手順&#34;&gt;手順&lt;/h2&gt;
&lt;h4 id=&#34;chef-cookbook-を取得&#34;&gt;Chef Cookbook を取得&lt;/h4&gt;
&lt;p&gt;RackSpace 社のエンジニアがメンテナンスしている Chef Cookbook を使います。各
Cookbook が git submodule 化されているので &amp;ndash;recursive オプションを付けます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% git clone https://github.com/rcbops/chef-cookbooks.git ~/openstack-chef-repo
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;% cd openstack-chef-repo
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;v400-ブランチをチェックアウト&#34;&gt;&amp;lsquo;v4.0.0&amp;rsquo; ブランチをチェックアウト&lt;/h4&gt;
&lt;p&gt;master ブランチは今現在 (2013/07/08) folsom ベースの構成になっているので
&amp;lsquo;grizzly&amp;rsquo; のためのブランチ &amp;lsquo;v4.0.0&amp;rsquo; をローカルにチェックアウトします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>内部で Chef を使っている OpenCenter で OpenStack 構築</title>
      <link>https://jedipunkz.github.io/post/2013/07/02/chef-opencenter-openstack/</link>
      <pubDate>Tue, 02 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/07/02/chef-opencenter-openstack/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;第13回 OpenStack 勉強会に参加してきました。内容の濃い収穫のある勉強会でした。
参加してよかった。特にえぐちさんの OpenCenter に関するプレゼン (下記のスライド
参照のこと) には驚きました。ちょうど当日 RackSpace のエンジニアが管理している
github 上の Chef Cookbooks を使って OpenStack 構築できたぁ！と感動していたのに、
その晩のうちに Chef を使って GUI で！ OpenStack が自動構築出来るだなんて&amp;hellip;。&lt;/p&gt;
&lt;p&gt;えぐちさんのスライド資料はこちら。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/guchi_hiro/open-centeropenstack&#34;&gt;http://www.slideshare.net/guchi_hiro/open-centeropenstack&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;早速、私も手元で OpenCenter 使ってみました。えぐちさん、情報ありがとうございましたー。&lt;/p&gt;
&lt;p&gt;実は私 としては Chef 単体で OpenStack を構築したいのですが、OpenCenter がどう
Cookbook や Roles, Environment を割り当てているのか知りたかったので、
OpenCenter を使って構築してみました。今回はその準備。今日は OpenCenter で皆さ
んも OpenStack を構築できるようキャプチャ付きで方法を紹介しますが、次の機会に
Chef 単体での OpenStack の構築方法を紹介出来ればいいなぁと思っています。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+---------------+---------------+---------------+---------------+-------------- public network
|eth0           |eth0           |eth1           |eth1           | eth1
|10.200.10.11   |10.200.10.12   |10.200.10.13   |10.200.10.14   |10.200.10.15
+-------------+ +-------------+ +-------------+ +-------------+ +-------------+
| opencenter  | |   oc-chef   | |oc-controller| | oc-compute01| | oc-compute02|
+-------------+ +-------------+ +-------------+ +-------------+ +-------------+
                                                |10.200.9.14    |10.200.9.15
                                                | eth0          |eth0
                                                +---------------+-------------- vm network
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;5台使ってみた&lt;/li&gt;
&lt;li&gt;全てのノードでインターネットへの経路を public network に向ける&lt;/li&gt;
&lt;li&gt;VM が接続する br100 ブリッジは eth0 にバインドした&lt;/li&gt;
&lt;li&gt;VM からインターネットへのアクセスは oc-computeNN が NAT する&lt;/li&gt;
&lt;li&gt;oc-chef は Chef Server !&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opencenter-の構築&#34;&gt;OpenCenter の構築&lt;/h2&gt;
&lt;p&gt;構築は&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sensu 監視システムを Chef で制御</title>
      <link>https://jedipunkz.github.io/post/2013/06/20/sensu-chef-controll/</link>
      <pubDate>Thu, 20 Jun 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/06/20/sensu-chef-controll/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;自動化の基盤を導入するために色々調べているのですが、監視も自動化しなくちゃ！と
いうことで Sensu を調べてたのですが Chef との相性バッチリな感じで、自分的にイ
ケてるなと思いました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公式サイト &lt;a href=&#34;http://www.sonian.com/cloud-monitoring-sensu/&#34;&gt;http://www.sonian.com/cloud-monitoring-sensu/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ドキュメント &lt;a href=&#34;http://docs.sensuapp.org/0.9/index.html&#34;&gt;http://docs.sensuapp.org/0.9/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;開発元が予め Chef の Cookbook (正確にはラッパー Cookbook 開発のための
Cookbook で Include して使う) を用意してくれていたり、インストールを容易にする
ための Omnibus 形式のパッケージの提供だったり。Omnibus なのでインストールと共
に Sensu が推奨する Ruby 一式も一緒にインストールされます。Chef と同じですね。&lt;/p&gt;
&lt;p&gt;今回紹介したいのは、Chef で Sensu を構築・制御する方法です。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+--------------+ +--------------+
| chef-server  | | workstation  |
+--------------+ +--------------+
       |                |
       +----------------+ 
       |
+--------------+
| sensu-server |
+--------------+
       |
       +----------------+----------------+----------------+
       |                |                |                |
+--------------+ +--------------+ +--------------+ +--------------+
| sensu-client | | sensu-client | | sensu-client | | sensu-client | ..&amp;gt;
+--------------+ +--------------+ +--------------+ +--------------+
| service node | | service node | | service node | | service node |
+--------------+ +--------------+ +--------------+ +--------------+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;この構成の処理の流れとしては&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef を Ruby コード内で利用する</title>
      <link>https://jedipunkz.github.io/post/2013/06/12/chef-ruby-code/</link>
      <pubDate>Wed, 12 Jun 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/06/12/chef-ruby-code/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;require &amp;lsquo;chef&amp;rsquo; して Ruby コードの中で chef を利用したいと思って色々調べていた
のですが、そもそもリファレンスが無くサンプルコードもごくわずかしかネット上に見
つけられない状態でした。結局ソースコードを読んで理解していく世界なわけですが、
サンプルコードが幾つかあると他の人に役立つかなぁと思い、ブログに載せていこうか
なぁと。&lt;/p&gt;
&lt;p&gt;まず Chef サーバへアクセスするためには下記の情報が必要です。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ユーザ名&lt;/li&gt;
&lt;li&gt;ユーザ用のクライアント鍵&lt;/li&gt;
&lt;li&gt;Chef サーバの URL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらは Chef::Config で記していきます。&lt;/p&gt;
&lt;p&gt;では早速サンプルコードです。まずは data bags 内データの一覧を取得するコードで
す。data bags 内のデータを全で取得し配列で表示します。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env ruby&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chef/rest&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chef/search/query&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:node_name&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user01&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:client_key&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/user01/user01.pem&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:chef_server_url&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://10.200.9.22&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DataBag&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;each &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;bag_name, url&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DataBag&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;load(bag_name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;each &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;item_name, url&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DataBagItem&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(bag_name, item_name)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_hash
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    puts item
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;次は data bags にデータを入力するコードです。json_data という JSON 形式のデー
タを test_data という data bag に放り込んでいます。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env ruby&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chef/rest&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chef/search/query&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:node_name&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user01&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:client_key&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/user01/user01.pem&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:chef_server_url&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://10.0.0.10&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;json_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;command&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;echo test&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;databag_item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Chef&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DataBagItem&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;new
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;databag_item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data_bag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test_data&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;databag_item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;raw_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; proc_nginx
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;databag_item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;次は nodes 一覧の取得です。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ceph クラスターネットワーク構成</title>
      <link>https://jedipunkz.github.io/post/2013/05/25/ceph-cluster-network/</link>
      <pubDate>Sat, 25 May 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/05/25/ceph-cluster-network/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Ceph を運用する上で考慮しなければいけないのがトラフィックの負荷です。特に OSD
同士のレプリケーション・ハートビートには相当トラフィックの負荷が掛かることが想
像出来ます。&lt;/p&gt;
&lt;p&gt;このため MDS, MON の通信に影響を与えないよう、OSD レプリケーション・ハートビー
トのためのネットワークを別に設けるのがベストプラクティスな構成の様です。このネッ
トワークのことをクラスターネットワークと Ceph 的に言うそうです。&lt;/p&gt;
&lt;p&gt;こんな接続になります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                +------+
                |Client|
                +------+
                |
+-------+-------+-------+-------+------ public network
|       |       |       |       |
+-----+ +-----+ +-----+ +-----+ +-----+
| MON | | MDS | | OSD | | OSD | | OSD |
+-----+ +-----+ +-----+ +-----+ +-----+
                |       |       |
----------------+-------+-------+------ cluster network
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上図の様に MON, MDS は public ネットワークを介し OSD のレプリケーション・ハー
トビートのみ cluster ネットワークを介します。Client と MDS との通信に影響を与
えない構成になります。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack &#43; Ceph 連携</title>
      <link>https://jedipunkz.github.io/post/2013/05/19/openstack-ceph/</link>
      <pubDate>Sun, 19 May 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/05/19/openstack-ceph/</guid>
      <description>&lt;p&gt;こんにちは。最近 OpenStack の導入に向けて保守性や可用性について調査している
&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;OpenStack は MySQL のダンプや OS イメージ・スナップショットのバックアップをとっ
ておけばコントローラの復旧も出来ますし、Grizzly 版の Quantum では冗長や分散が
取れるので障害時に耐えられます。また Quantum の復旧は手動もで可能です。最後の
悩みだった Cinder の接続先ストレージですが、OpenStack のスタンスとしては高価な
ストレージの機能を使ってバックアップ取るか、Ceph, SheepDog のようなオープンソー
スを使うか、でした。で、今回は Ceph を OpenStack に連携させようと思いました。&lt;/p&gt;
&lt;p&gt;この作業により Cinder の接続先ストレージが Ceph になるのと Glance の OS イメー
ジ・スナップショットの保管先が Ceph になります。&lt;/p&gt;
&lt;p&gt;下記の参考資料が完成度高く、ほぼ内容はそのままです。若干付け足していますが。&lt;/p&gt;
&lt;h2 id=&#34;参考資料&#34;&gt;参考資料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://ceph.com/docs/master/rbd/rbd-openstack/&#34;&gt;http://ceph.com/docs/master/rbd/rbd-openstack/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;前提の構成&#34;&gt;前提の構成&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;+-------------+-------------+--------------------------------------------- Public/API Network
|             |             |             
+-----------+ +-----------+ +-----------+ +-----------+ +-----------+ +-----------+
|           | |           | |vm|vm|..   | |           | |           | |           |
| controller| |  network  | +-----------+ |  ceph01   | |  ceph01   | |  ceph01   |
|           | |           | |  compute  | |           | |           | |           |
|           | |           | |           | |           | |           | |           |
+-----------+ +-----------+ +-----------+ +-----------+ +-----------+ +-----------+
|             |     |       |     |       |             |             |
+-------------+-----)-------+-----)-------+-------------+-------------+-- Management/API Network
                    |             |                       
                    +-------------+-----------------------------------+-- Data Network
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Ceph は OpenStack の Management Network 上に配置&lt;/li&gt;
&lt;li&gt;Ceph は3台構成 (何台でも可)&lt;/li&gt;
&lt;li&gt;OpenStack も3台構成 (何台でも可)&lt;/li&gt;
&lt;li&gt;連携処理するのは controller, compute ノード&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;では早速手順ですが、OpenStack と Ceph の構築手順は割愛します。私の他の記事を参
考にしていただければと思います。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef Cookbook でユーザ・グループ追加</title>
      <link>https://jedipunkz.github.io/post/2013/05/18/chef-cookbook-adding-users/</link>
      <pubDate>Sat, 18 May 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/05/18/chef-cookbook-adding-users/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。
今回は Opscode Chef でユーザ・グループを作成する方法をまとめます。&lt;/p&gt;
&lt;p&gt;&amp;lsquo;users&amp;rsquo; Cookbook を使います。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% cd ${YOUR_CHEF_REPO}
% ${EDITOR} Berksfile
cookbook &#39;users&#39;
% berks install --path ./cookbooks
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;data_bag を使ってユーザ・グループの管理をしたいので管理ディレクトリを作成しま
す。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% mkdir -p data_bags/users
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;data_bags/users/jedipunkz.json ファイルを作成します。必要に応じて内容を書き換えてください。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;id&amp;quot;: &amp;quot;jedipunkz&amp;quot;,
  &amp;quot;ssh_keys&amp;quot;: &amp;quot;ssh-rsa AAAABx92tstses jedipunkz@somewhere&amp;quot;,
  &amp;quot;groups&amp;quot;: [ &amp;quot;sysadmin&amp;quot;, &amp;quot;sudo&amp;quot; ],
  &amp;quot;uid&amp;quot;: 2001,
  &amp;quot;shell&amp;quot;: &amp;quot;\/usr\/bin\/zsh&amp;quot;,
  &amp;quot;comment&amp;quot;: &amp;quot;jedipunkz sysadmin&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;$1$s%H8BMHlB$7s3h30y9IB1SklftZXYhvssJ&amp;quot;

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;json ファイルの説明です。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;id : ユーザ名&lt;/li&gt;
&lt;li&gt;ssh_keys : SSH 公開鍵&lt;/li&gt;
&lt;li&gt;groups : 所属させるグループ&lt;/li&gt;
&lt;li&gt;uid : unix id&lt;/li&gt;
&lt;li&gt;sheell : ログインシェル&lt;/li&gt;
&lt;li&gt;comment : コメント&lt;/li&gt;
&lt;li&gt;passwd : ハッシュ化したパスワード&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特にハッシュ化したパスワードは下記のコマンドで生成出来ます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ceph-Deploy で Ceph 分散ストレージ構築</title>
      <link>https://jedipunkz.github.io/post/2013/05/11/ceph-deploy/</link>
      <pubDate>Sat, 11 May 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/05/11/ceph-deploy/</guid>
      <description>&lt;p&gt;今回は ceph-deploy というツールを使って Ceph ストレージを簡単に構築することが
出来るので紹介します。Ceph は分散ストレージでオブジェクトストレージとしてもブ
ロックストレージとしても動作します。今回の構築ではブロックストレージとしてのみ
の動作です。&lt;/p&gt;
&lt;p&gt;Ceph が公開しているのが ceph-deploy なわけですが、マニュアル操作に代わる構築方
法として公開しているようです。その他にも Chef Cookbook も公開されているようで
す。&lt;/p&gt;
&lt;p&gt;それでは早速。&lt;/p&gt;
&lt;h2 id=&#34;今回の構成&#34;&gt;今回の構成&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;+--------+ +--------+ +--------+
| ceph01 | | ceph02 | | ceph03 |
|  osd   | |  osd   | |  osd   |
|  mon   | |  mon   | |  mon   |
|  mds   | |  mds   | |  mds   |
+--------+ +--------+ +--------+
| 10.0.0.1 | 10.0.0.2 | 10.0.0.3
|          |          |          
+----------+----------+
|
| 10.0.0.10
+-------------+
| workstation |
+-------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;特徴は&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quantum Network ノードの分散・冗長</title>
      <link>https://jedipunkz.github.io/post/2013/04/26/quantum-network-distributing/</link>
      <pubDate>Fri, 26 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/26/quantum-network-distributing/</guid>
      <description>&lt;p&gt;こんにちは。Grizzly がリリースされてから暫く経ちました。今回は Folsom リリース
まであった Quantum ノードのボトルネックと単一障害点を解決する新しい機能につい
て評価した結果をお伝えします。&lt;/p&gt;
&lt;p&gt;Folsom までは&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quantum L3-agent が落ちると、その OpenStack 一式の上にある仮想マシン全ての通
信が途絶える&lt;/li&gt;
&lt;li&gt;Quantum L3-agent に仮想マシンの全てのトラフィックが集まりボトルネックとなる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という問題がありました。Folsom リリース時代にもし僕が職場で OpenStack を導入す
るのであればこれらを理由に nova-network を選択していたかもしれません。
nova-network は compute ノードが落ちればその上の仮想マシンも同時に落ちるが、他
の compute ノード上の仮想マシンの通信には影響を与えないからです。もちろん仮想
ルータ・仮想ネットワークの生成等を API でユーザに提供したいなどの要望があれば
Quantum を選択するしかありませんが。これに対して Grizzly リリースの Quantum は
改善に向けて大きな機能を提供してくれています。L3-agent, DHCP-agent の分散・冗
長機能です。&lt;/p&gt;
&lt;p&gt;下記の構成が想定出来ます。ここでは Network ノードを2台用意しました。それ以上の
台数に増やすことも出来ます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+-------------+-------------+-------------------------- Public/API Network
|             |             |
+-----------+ +-----------+ +-----------+ +-----------+
|           | |           | |           | |vm|vm|..   |
| controller| |  network  | |  network  | +-----------+
|           | |           | |           | |  compute  |
+-----------+ +-----------+ +-----------+ +-----------+
|             |     |       |     |       |     |
+-------------+-----)-------+-----)-------+-----)------ Management/API Network
                    |             |             |
                    +-------------+-------------+------ Data Network
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;L3-agent の分散は仮想ルータ単位で行います。それに対し DHCP-agent は仮想
ネットワーク単位で行います。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef for OpenStack</title>
      <link>https://jedipunkz.github.io/post/2013/04/21/chef-for-openstack-grizzly-roadmap/</link>
      <pubDate>Sun, 21 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/21/chef-for-openstack-grizzly-roadmap/</guid>
      <description>&lt;p&gt;以前にも話題にしたことがある Chef For OpenStack ですが今週新しい情報が入って来
ました。#ChefConf 2013 というイベントがあったのですがここで Opscode の Matt
Ray さんらが集まり OpenStack を Chef で構築する &amp;lsquo;Chef for OpenStack&amp;rsquo; について
語られた模様です。その時の資料が SlideShare に上がっていたので見てみました。&lt;/p&gt;
&lt;iframe src=&#34;http://www.slideshare.net/slideshow/embed_code/19197748&#34;
width=&#34;427&#34; height=&#34;356&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34;
scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC;border-width:1px 1px
0;margin-bottom:5px&#34; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt;
&lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a
href=&#34;http://www.slideshare.net/mattray/chef-for-openstack-grizzly-roadmap&#34;
title=&#34;Chef for OpenStack: Grizzly Roadmap&#34; target=&#34;_blank&#34;&gt;Chef for
OpenStack: Grizzly Roadmap&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a
href=&#34;http://www.slideshare.net/mattray&#34; target=&#34;_blank&#34;&gt;Matt Ray&lt;/a&gt;&lt;/strong&gt;
&lt;/div&gt;
&lt;p&gt;気にあった点を幾つか挙げていきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/osops&#34;&gt;https://github.com/osops&lt;/a&gt; で管理される&lt;/li&gt;
&lt;li&gt;各コンポーネントの cookbook の名前には &amp;lsquo;-cookbook&amp;rsquo; を最後に付ける&lt;/li&gt;
&lt;li&gt;quantum, cinder, ceilometer, heat 等、比較的新しいコンポーネントも加わる&lt;/li&gt;
&lt;li&gt;gerrit でコードレビューされ CI も提供される&lt;/li&gt;
&lt;li&gt;Chef11 が用いられる&lt;/li&gt;
&lt;li&gt;Ruby 1.9.x に対応した chef-client が用いられる&lt;/li&gt;
&lt;li&gt;Foodcritic で可能な限りテストされる&lt;/li&gt;
&lt;li&gt;chef-solo はサポートされない&lt;/li&gt;
&lt;li&gt;5月に &amp;lsquo;2013.1.0&amp;rsquo; がリリースされる (openstack 2013.1 対応と思われる)&lt;/li&gt;
&lt;li&gt;chef-repo の形で提供される&lt;/li&gt;
&lt;li&gt;Ubuntu 12.04 が前提&lt;/li&gt;
&lt;li&gt;HyperVisor は KVM, LXC がサポートされる&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上です。恐らく chef-repo で提供されるということは spiceweasel を使った構成構
築が出来るような形になるでしょう。楽しみです。またコントリビュートする方法も掲
載されているので興味が有る方は協力してみるのも楽しいかもしれません。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Grizzy で非 Virtio OS 稼働</title>
      <link>https://jedipunkz.github.io/post/2013/04/21/openstack-non-virtio/</link>
      <pubDate>Sun, 21 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/21/openstack-non-virtio/</guid>
      <description>&lt;p&gt;こんにちは jedipunkz です。&lt;/p&gt;
&lt;p&gt;Virtio に対応していない OS を OpenStack で稼働させることが今まで出来なかったの
ですが Grizzly から非 Virtio な OS イメージが扱えるようになった。今まで NetBSD
やら古い FreeBSD やら virtio ドライバを OS イメージに入れることに苦労していたの
だけど、これで問題無くなった。&lt;/p&gt;
&lt;p&gt;最初、この機能のこと調べるのに「どうせ libvirt が生成する xml を書き換えるのだ
から nova 周りの設定なんだろうー」と思っていたら全く方法が見つからず&amp;hellip;。結局
OS イメージを格納している Glance の設定にありました。&lt;/p&gt;
&lt;p&gt;ここでは FreeBSD7.4 Release を例に挙げて説明していきます。&lt;/p&gt;
&lt;h2 id=&#34;前提とする環境&#34;&gt;前提とする環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack Grizzly が稼働していること&lt;/li&gt;
&lt;li&gt;ホスト OS に Ubuntu 12.04.2 LTS が稼働していること&lt;/li&gt;
&lt;li&gt;ゲスト OS に FreeBSD 7.4 Release を用いる&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;とします。OS のバージョンはホスト・ゲスト共に、上記以外でも構いません。Grizzly
さえ動いていれば OK です。&lt;/p&gt;
&lt;h2 id=&#34;os-イメージ作成&#34;&gt;OS イメージ作成&lt;/h2&gt;
&lt;p&gt;KVM で OS イメージを作成します。もちろん virtio なインターフェースは指定せず&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Grizzly 構築スクリプト</title>
      <link>https://jedipunkz.github.io/post/2013/04/20/openstack-grizzly-installation-script/</link>
      <pubDate>Sat, 20 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/20/openstack-grizzly-installation-script/</guid>
      <description>&lt;p&gt;OpenStack Grizzly がリリースされて2週間ほど経過しました。皆さん動かしてみまし
たか？今回、毎度の構築 Bash スクリプトを開発したので公開します。&lt;/p&gt;
&lt;p&gt;下記のサイトで公開しています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/openstack_grizzly_install&#34;&gt;https://github.com/jedipunkz/openstack_grizzly_install&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;このスクリプト、複数台構成とオールインワン構成の両方が構成出来るようなっていま
すが、今回は簡単なオールインワン構成の組み方をを簡単に説明したいと思います。&lt;/p&gt;
&lt;h2 id=&#34;前提の環境&#34;&gt;前提の環境&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 12.04 LTS が稼働している&lt;/li&gt;
&lt;li&gt;Cinder のためのディスクを OS 領域と別に用意 (/dev/sdb1 など)&lt;/li&gt;
&lt;li&gt;オールインワン構成の場合は 2 NICs 準備&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ubuntu 13.04 の daily build も完成度上がっている時期ですが OVS 側の対応が
OpenStack 構成に問題を生じさせるため 12.04 LTS + Ubuntu Cloud Archive の組み合
わせで構築するのが主流になっているようです。また、Cinder 用のディスクは OS 領
域を保持しているディスクとは別 (もしくはパーティションを切ってディスクデバイス
を別けても可) が必要です。オールインワン構成の場合は NIC を2つ用意する必要があ
ります。通常 OpenStack を複数台構成する場合は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;コントローラノード x 1 台&lt;/li&gt;
&lt;li&gt;ネットワークノード x 1 台&lt;/li&gt;
&lt;li&gt;コンピュートノード x n 台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;で組み、VM はコンピュートノードからネットワークノードを介してインターネットに
接続します。よってそのため更に NIC が必要になるのですが、オールインワン構成の
場合は&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chef 11 サーバのローカルネットワーク上構築</title>
      <link>https://jedipunkz.github.io/post/2013/04/06/chef-11-private-network/</link>
      <pubDate>Sat, 06 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/06/chef-11-private-network/</guid>
      <description>&lt;p&gt;chef-solo を使うの？Chef サーバを使うの？という議論は結構前からあるし、答えは
「それぞれの環境次第」だと思うのだが、僕は個人的に Chef サーバを使ってます。ホ
ステッド Chef を使いたいけどお金ないし。会社で導入する時はホステッド Chef を契
約してもらうことを企んでます。(・∀・) 何故なら cookbooks を開発することがエン
ジニアの仕事の本質であって Chef サーバを運用管理することは本質ではないから。そ
れこそクラウド使えという話だと思う。&lt;/p&gt;
&lt;p&gt;でも！Chef に慣れるには無料で使いたいし、継続的に Cookbooks をターゲットノード
で実行したい。ということで Chef サーバを構築して使っています。&lt;/p&gt;
&lt;p&gt;Chef 10 の時代は Chef サーバの構築方法は下記の通り3つありました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;手作業！&lt;/li&gt;
&lt;li&gt;Bootstrap 構築&lt;/li&gt;
&lt;li&gt;Opscode レポジトリの Debian, Ubuntu, CentOS パッケージ構築&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;それが Chef 11 では&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu, RHEL のパッケージ (パッケージインストールですべて環境が揃う)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://www.opscode.com/chef/install/&#34;&gt;http://www.opscode.com/chef/install/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この方法1つだけ。でも簡単になりました。&lt;/p&gt;
&lt;p&gt;&amp;lsquo;Chef Server&amp;rsquo; タブを選択するとダウンロード出来る。じっくりは deb ファイルの中
身を見たことがないけど、チラ見した時に chef を deb の中で実行しているように見
えた。徹底してるｗ&lt;/p&gt;
&lt;p&gt;Chef 10 時代のパッケージと違って行う操作は下記の2つのコマンドだけ。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo dpkg -i chef-server_11.0.6-1.ubuntu.12.04_amd64.deb # ダウンロードしたもの
% sudo chef-server-ctl reconfigure
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;簡単。でも&amp;hellip; この状態だと https://&amp;lt;サーバの FQDN&amp;gt; でサーバが Listen している。
IP アドレスでアクセスしてもリダイレクトされる。つまり、ローカルネットワーク上
に構築することが出来ない。安易に hosts で解決も出来ない。何故ならターゲットノー
ドは通常まっさらな状態なので bootstrap するたびに hosts を書くなんてアホらしい
しやってはいけない。&lt;/p&gt;</description>
    </item>
    <item>
      <title>クラウドマネジメント勉強会レポ</title>
      <link>https://jedipunkz.github.io/post/2013/04/06/cloudmanagement/</link>
      <pubDate>Sat, 06 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/04/06/cloudmanagement/</guid>
      <description>&lt;p&gt;クラウドマネジメント勉強会に参加してきた。今が旬なのか定員140名が埋まっていま
した。クラウドフェデレーションサービス各種の話が聞ける貴重な勉強会の場でした。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;場所 : スクエアエニックスさん
日程 : 2013年4月5日 19:00 -
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;少し長くなるので、早速。&lt;/p&gt;
&lt;h2 id=&#34;クラウド運用管理研究会&#34;&gt;クラウド運用管理研究会&lt;/h2&gt;
&lt;p&gt;クラウド利用推進機構が運営するクラウド運用管理研究会は下記の3つに分別されるそ
うです。今回は一項目の &amp;lsquo;クラウドマネジメントツール研究会&amp;rsquo; にあたるそう。別の研
究会も既に勉強会を実施しているそうです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;クラウドマネジメントツール研究会&lt;/li&gt;
&lt;li&gt;デザインパターン研究会&lt;/li&gt;
&lt;li&gt;運用管理・監視研究会&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;aws-opsworks&#34;&gt;AWS OpsWorks&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;アマゾンデータサービスジャパン AWS 片山さん, 船崎さん
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OpsWorks は最近話題になった AWS 利用者に無料で提供されるクラウドフェデレーショ
ンサービス。Web UI で操作し簡単デプロイを実現するサービスです。&lt;/p&gt;
&lt;h2 id=&#34;opsworks-が自動化するモノ&#34;&gt;OpsWorks が自動化するモノ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;サーバ設定&lt;/li&gt;
&lt;li&gt;ミドルウェア構築&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;特徴&#34;&gt;特徴&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Chef フレームワークを利用 (chef-solo を内部的に利用)&lt;/li&gt;
&lt;li&gt;任意の cookbooks を利用可能&lt;/li&gt;
&lt;li&gt;LB, AP, DB などをレイヤ化, 任意のレイヤも作成可能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opsworks-の流れ&#34;&gt;OpsWorks の流れ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stack 作成&lt;/li&gt;
&lt;li&gt;レイヤ作成 (LB, AP, DB, 任意)&lt;/li&gt;
&lt;li&gt;レシピの作成&lt;/li&gt;
&lt;li&gt;レイヤにインスタンス作成&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;下記をレイヤ化で区別する&#34;&gt;下記をレイヤ化で区別する&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Package インストール&lt;/li&gt;
&lt;li&gt;OS 設定&lt;/li&gt;
&lt;li&gt;アプリデプロイ&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;
&lt;p&gt;AWS OpsWorks の登場で他のクラウドフェデレーションサービスがどうなるの？とさえ
思った。AWS はインターネット・ホスティング業界のあらゆるサービスを押さえようと
している感がある。もう隙間がない！ｗ OpsWorks に関してまだ問題は残っているそう
だ。VPC, micro 現在未対応など。が解決に向けて作業しているそう。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NetBSD on OpenStack</title>
      <link>https://jedipunkz.github.io/post/2013/03/28/netbsd-on-openstack/</link>
      <pubDate>Thu, 28 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/03/28/netbsd-on-openstack/</guid>
      <description>&lt;p&gt;もう数日で OpenStack の次期バージョン版 Grizzly がリリースされるタイミングだが
現行バージョン Folsom の OpenStack の上に NetBSD を載せてみた。完全にお遊び
だけど&amp;hellip;。&lt;/p&gt;
&lt;p&gt;結局、ほとんど何も特別な対応取ることなく NetBSD が動いた。もちろんハイパーバイ
ザは KVM です。だけど少し条件がある。&lt;/p&gt;
&lt;p&gt;qemu の不具合があり Ubuntu 12.04 LTS + Ubuntu Cloud Archives の組み合わせでは
NetBSD が動作しなかった。下記のようなカーネルパニックが発生。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;panic: pci_make_tag: bad request
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;この不具合に相当するんじゃないかと思ってる。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bugs.launchpad.net/qemu/&amp;#43;bug/897771&#34;&gt;https://bugs.launchpad.net/qemu/+bug/897771&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;よって下記の組み合わせで動作を確認した。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 12.10 + OpenStack (Native Packages)&lt;/li&gt;
&lt;li&gt;qemu, kvm : 1.2.0+noroms-0ubuntu2.12.10.3&lt;/li&gt;
&lt;li&gt;NetBSD 6.1 RC2 amd64&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前提条件&#34;&gt;前提条件&lt;/h2&gt;
&lt;p&gt;OpenStack Folsom が動作していること。&lt;/p&gt;
&lt;h2 id=&#34;netbsd-os-イメージ作成&#34;&gt;NetBSD OS イメージ作成&lt;/h2&gt;
&lt;p&gt;nova-compute が動作しているホストの qemu-kvm を利用する。OpenStack 上に何でも
良いので OS を動作させこの kvm プロセスのパラメータを参考に kvm コマンドを実行
し NetBSD をインストールさせた。一番確実な方法。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Berkshelf で Chef Cookbook の管理</title>
      <link>https://jedipunkz.github.io/post/2013/03/17/berkshelf-chef-cookbook-manage/</link>
      <pubDate>Sun, 17 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/03/17/berkshelf-chef-cookbook-manage/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;今日は Chef Cookbook の管理をしてくれる Berkshelf について。&lt;/p&gt;
&lt;p&gt;Berkshelf は Librarian-Chef と同じく Cookbook の管理をしてくれるツールです。依
存関係のクリアもしてくれます。Opscode の中の人 @someara さんにこんなこと言われ
て、&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p&gt;@&lt;a
href=&#34;https://twitter.com/jedipunkz&#34;&gt;jedipunkz&lt;/a&gt; berkshelf &amp;gt;
librarian-chef&lt;/p&gt;&amp;mdash; somearaさん (@someara) &lt;a
href=&#34;https://twitter.com/someara/status/298664663976120321&#34;&gt;2013年2月5日
&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Librarian-chef じゃなくて Berkshelf 使えってことだろうなぁと思ったので僕は
Bekshelf を使うようにしてます。先日ブログ記事にした openstack-chef-repo も以前
は Librarian-chef を使っていたのですが最近 Berkshelf に置き換わりました。
openstack-chef-repo は Opscode の中の人の @mattray さん達が管理しています。&lt;/p&gt;
&lt;p&gt;では早速。&lt;/p&gt;
&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;
&lt;p&gt;インストールは簡単。gem install するだけです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% gem install berkshelf
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;
&lt;p&gt;chef-repo 配下で Berksfile を下記のように書きます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;site :opscode

cookbook &#39;chef-client&#39;
cookbook &#39;nginx&#39;, &#39;= 0.101.2&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;berks コマンドを実行して Cookbooks をダウンロードします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>chef-client の継続的デリバリ</title>
      <link>https://jedipunkz.github.io/post/2013/03/15/chef-contenuously-deploy/</link>
      <pubDate>Fri, 15 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/03/15/chef-contenuously-deploy/</guid>
      <description>&lt;p&gt;こんにちは。&lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;久々に Chef の話題。&lt;/p&gt;
&lt;p&gt;有名な方々が最近 Chef について記事書いたりで Chef が再び盛り上がってきましたね。
僕のブログにも chef-solo で検索してアクセスしてくる方が増えているようです。&lt;/p&gt;
&lt;p&gt;ちょうど今、仕事で試験的なサービスを立ち上げてそこで Chef を使っているのですが Server,
Workstation, Target Node(s) の構成で使っていて、僕らは最初から chef-solo と
capistrano でってことは考えていませんでした。もちろん chef-solo + capistrano
の環境も調査しましたが、今の Server 構成が便利なのでもう戻れない。&lt;/p&gt;
&lt;p&gt;今日は Chef サーバ構成の良さについての記事ではないですが、それについては次回、
時間見つけて書こうかと思ってます。&lt;/p&gt;
&lt;p&gt;今日は &amp;lsquo;chef-client をどうアップデートするか&amp;rsquo; について。せっかく Chef
でサーバ構成を継続的にデプロイ出来ても Chef 自身をアップデート出来ないと悲しい
ですよね。chef-client が稼働しているインスタンスなんて起動して利用してすぐに破
棄だって時代ですが、なかなかそうもいなかい気がしています。&lt;/p&gt;
&lt;p&gt;「ほら、だから chef-solo 使えばいいんだよ！」って思ってるあなた！違うんですよー。
そのデメリットを上回るメリットが Chef サーバ構成にあるんです。次回書きますｗ&lt;/p&gt;
&lt;p&gt;Chef10 から Chef11 と試験してみるにはちょうど良い時期でした。今回の構成は&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;旧環境&#34;&gt;旧環境&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;+------------------+
|   chef server    |
|  version 10.18   |
+------------------+
^
|
+--------------------+
|                    |
|                    |
+------------------+ +------------------+
| chef workstation | |   target node    |
|  version 10.24   | |  version 10.24   |
+------------------+ +------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;chef server は apt.opscode.com レポジトリを利用した Chef 10.18 なもの&lt;/li&gt;
&lt;li&gt;chef workstaion は version 10.24 (2013年3月15日現在 10.x 系最新)&lt;/li&gt;
&lt;li&gt;target node は chef workstaion から knife bootstrap を行い構成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;knife bootstrap の際に下記のオプションを指定します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>pry のススメ</title>
      <link>https://jedipunkz.github.io/post/2013/03/06/pry/</link>
      <pubDate>Wed, 06 Mar 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/03/06/pry/</guid>
      <description>&lt;p&gt;OpenStack をコードで管理するためのフレームワークは幾つか存在するのだけど Ruby
で記述出来る Fog が良い！と隣に座ってるアプリエンジニアが言うので僕も最近少し
触ってます。&lt;/p&gt;
&lt;p&gt;Fog を使った OpenStack を管理するコードを書くことも大事なのだけど、Fog のコン
トリビュートってことで幾つかの機能を付け足して (Quantum Router 周り) ってこと
をやってました。まだ取り込まれてないけど。&lt;/p&gt;
&lt;p&gt;その開発の中で pry の存在を教えてもらいその便利さに驚いたので少し説明します。
バリバリ開発系の人は既に知っているだろうけど、インフラ系エンジニアの僕にとって
は感激モノでした。&lt;/p&gt;
&lt;p&gt;pry は irb 代替な Ruby のインタラクティブシェルです。下記の URL から持ってこれ
ます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pry/pry&#34;&gt;https://github.com/pry/pry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;シンタックスハイライトされたり json のレスポンスが綺麗に成形されたり irb 的に
使うだけでも便利なのだけど &amp;lsquo;?&amp;rsquo; や &amp;lsquo;$&amp;rsquo; でコードのシンタックスを確認したりコード
内容を確認したり出来るのがアツい！&lt;/p&gt;
&lt;p&gt;ちょうど今回追加した Fog の機能を使って説明していみます。&lt;/p&gt;
&lt;p&gt;Fog のコードを require して OpenStack に接続するための情報を設定し OpenStack
Quantum に接続します。これで準備完了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;38&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/home/jedipunkz/fog/lib/fog.rb&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; @connection_hash &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;   &lt;span style=&#34;color:#e6db74&#34;&gt;:openstack_username&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demo&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;   &lt;span style=&#34;color:#e6db74&#34;&gt;:openstack_api_key&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demo&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;   &lt;span style=&#34;color:#e6db74&#34;&gt;:openstack_tenant&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;service&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;   &lt;span style=&#34;color:#e6db74&#34;&gt;:openstack_auth_url&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://172.16.1.11:5000/v2.0/tokens&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;   &lt;span style=&#34;color:#e6db74&#34;&gt;:provider&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;OpenStack&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; pry(main)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; @quantum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Fog&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Network&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;new(@connection_hash)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;試しに Router 一覧を取得します。list_routers メソッドです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>第11回OpenStack勉強会で話してきた</title>
      <link>https://jedipunkz.github.io/post/2013/02/10/di-11hui-openstack-study11-openstack-chef-repo/</link>
      <pubDate>Sun, 10 Feb 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/02/10/di-11hui-openstack-study11-openstack-chef-repo/</guid>
      <description>&lt;p&gt;2013年2月9日に行われた OpenStack 勉強会第11回で話してきました。&lt;/p&gt;
&lt;p&gt;openstack-chef-repo と言う、Opscode Chef で OpenStack を構築する内容を話して
きました。その時に説明出来なかった詳細についてブログに書いておきます。&lt;/p&gt;
&lt;iframe src=&#34;http://www.slideshare.net/slideshow/embed_code/16434817&#34;
width=&#34;427&#34; height=&#34;356&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34;
scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC;border-width:1px 1px
0;margin-bottom:5px&#34; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt;
&lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a
href=&#34;http://www.slideshare.net/tomokazubobhirai/openstack-chefrepo&#34;
title=&#34;Openstack chef-repo&#34; target=&#34;_blank&#34;&gt;Openstack chef-repo&lt;/a&gt; &lt;/strong&gt;
from &lt;strong&gt;&lt;a href=&#34;http://www.slideshare.net/tomokazubobhirai&#34;
target=&#34;_blank&#34;&gt;Tomokazu Hirai&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;
&lt;p&gt;説明で使ったスライドです。&lt;/p&gt;
&lt;h2 id=&#34;まえがき&#34;&gt;まえがき&lt;/h2&gt;
&lt;p&gt;Essex ベースで構築することしか今は出来ません。Folsom に関しては &amp;lsquo;直ちに開発が
スタートする&amp;rsquo; と記されていました。今回は Opscode と RackSpace のエンジニアが共
同で開発を進めているので期待しています。今まで個人で OpenStack の各コンポーネ
ントの cookbook を開発されていた方がいらっしゃるのだけど汎用性を持たせるという
意味で非常に難しく、またどの方の開発に追従していけばよいか判断困っていました。
よって今回こそ期待。&lt;/p&gt;
&lt;h2 id=&#34;前提の構成&#34;&gt;前提の構成&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;+-------------+
| chef-server |
+-------------+ 10.0.0.10
|
+---------------+ 10.0.0.0/24
|               |
+-------------+ +-------------+
| workstation | |    node     |
+-------------+ +-------------+
10.0.0.11       10.0.0.12
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;chef-server : chef API を持つ chef-server 。cookbook, role..などのデータを持つ&lt;/li&gt;
&lt;li&gt;workstation : openstack-chef-repo を使うノード。knife が使える必要がある。&lt;/li&gt;
&lt;li&gt;node        : OpenStack を構築するターゲットノード&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;目次&#34;&gt;目次&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;chef-server の構築 (BootStrap 使う)&lt;/li&gt;
&lt;li&gt;openstack-chef-repo を使用する準備&lt;/li&gt;
&lt;li&gt;openstack-chef-repo 実行&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chef-server-の構築&#34;&gt;chef-server の構築&lt;/h2&gt;
&lt;p&gt;Opscode の wiki に記されている通りなのですが、簡単に書いておきます。今回は
bootstrap 方式で用意します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spiceweasel で knife バッチ処理</title>
      <link>https://jedipunkz.github.io/post/2013/02/01/spiceweasel-knife-bootstrap/</link>
      <pubDate>Fri, 01 Feb 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/02/01/spiceweasel-knife-bootstrap/</guid>
      <description>&lt;p&gt;Spiceweasel &lt;a href=&#34;https://github.com/mattray/spiceweasel#cookbooks&#34;&gt;https://github.com/mattray/spiceweasel#cookbooks&lt;/a&gt; を使ってみた。&lt;/p&gt;
&lt;p&gt;Spiceweasel は Chef の cookbook のダウンロード, role/cookbook の chef server
へのアップロード, ブートストラップ等をバッチ処理的に行なってくれる(もしくはコ
マンドラインを出力してくれる)ツールで、自分的にイケてるなと感じたのでブログに
書いておきます。&lt;/p&gt;
&lt;p&gt;クラウドフェデレーション的サービスというかフロントエンドサービスというか、複数
のクラウドを扱えるサービスは増えてきているけど、chef を扱えるエンジニアであれ
ば、この Spiceweasel で簡単・一括デプロイ出来るので良いのではないかと。&lt;/p&gt;
&lt;p&gt;早速だけど chef-repo にこんな yamp ファイルを用意します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cookbooks:
- apt:
- nginx:

roles:
- base:

nodes:
- 172.24.17.3:
    run_list: role[base]
    options: -i ~/.ssh/testkey01 -x root -N webset01
- 172.24.17.4:
    run_list: role[base]
    options: -i ~/.ssh/testkey01 -x root -N webset02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上から説明すると&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lsquo;apt&amp;rsquo;, &amp;rsquo;nginx&amp;rsquo; の cookbook を opscode レポジトリからダウンロード&lt;/li&gt;
&lt;li&gt;&amp;lsquo;apt&amp;rsquo;, &amp;rsquo;nginx&amp;rsquo; の cookbook を chef-server へアップロード&lt;/li&gt;
&lt;li&gt;roles/base.rb を chef-server へアップロード&lt;/li&gt;
&lt;li&gt;2つのノードに対して bootstrap 仕掛ける&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ってことをやるためのファイルです。予め chef-repo と roles は用意してあげる必要
があります。この辺りは knife の操作のための準備と全く同じ。また Spiceweasel は、
この yaml フィアル内の各パラメータや指定した role の内容の依存関係をチェックし
てくれます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Arch Linux セットアップまとめ</title>
      <link>https://jedipunkz.github.io/post/2013/01/14/arch-linux-setup/</link>
      <pubDate>Mon, 14 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/01/14/arch-linux-setup/</guid>
      <description>&lt;p&gt;(2013/08/31 修正しました)&lt;/p&gt;
&lt;p&gt;自宅のノート PC にいつも Debian Gnu/Linux unstable を入れて作業してたのだけど、
Arch Linux が試したくなって入れてみた。すごくイイ。ミニマル思考で常に最新。端
末に入れる OS としては最適かも!と思えてきた。Ubuntu はデスクトップ環境で扱う
にはチト大きすぎるし。FreeBSD のコンパイル待ち時間が最近耐えられないし&amp;hellip;。&lt;/p&gt;
&lt;p&gt;前リリースの Arch Linux には /arch/setup という簡易インストーラがあったのだけ
ど、それすら最近無くなった。環境作る方法を自分のためにもメモしておきます。&lt;/p&gt;
&lt;h4 id=&#34;os-イメージ-iso-取得とインストール用-usb-スティック作成&#34;&gt;OS イメージ iso 取得とインストール用 USB スティック作成&lt;/h4&gt;
&lt;p&gt;Linux, Windows, Mac で作り方が変わるようだけど、自分は Mac OSX を使ってインス
トール USB スティックを作成した。&lt;/p&gt;
&lt;p&gt;diskutil で USB スティック装着前後の disk デバイス番号を覚える&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% diskutil list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(ここでは /dev/rdisk4 として進める。)&lt;/p&gt;
&lt;p&gt;アンマウントする。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo diskutil unmountDisk /dev/rdisk4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ダウンロードした iso を USB スティックに書き込む。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo dd if=/path/to/downloaded/iso of=/dev/rdisk4 bs=8192
% sudo diskutil eject /dev/rdisk4
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;usb-スティック装着しインストール開始&#34;&gt;USB スティック装着しインストール開始&lt;/h4&gt;
&lt;p&gt;起動するとメニューが表示されるので x86_64 を選んで起動。プロンプトが表示される。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Folsom on Thinkpad</title>
      <link>https://jedipunkz.github.io/post/2013/01/12/openstack-on-thinkpad/</link>
      <pubDate>Sat, 12 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/01/12/openstack-on-thinkpad/</guid>
      <description>&lt;p&gt;以前紹介した OpenStack Folsom 構築 bash スクリプトなのだけど quantum の代わり
に nova-network も使えるようにしておいた。&lt;/p&gt;
&lt;p&gt;構築 bash スクリプトは、&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/openstack_folsom_deploy/blob/master/README_jp.md&#34;&gt;https://github.com/jedipunkz/openstack_folsom_deploy/blob/master/README_jp.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;に詳しい使い方を書いておきました。またパラメータを修正して実行するのだけどパラ
メータについては、&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jedipunkz/openstack_folsom_deploy/blob/master/README_parameters_jp.md&#34;&gt;https://github.com/jedipunkz/openstack_folsom_deploy/blob/master/README_parameters_jp.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;に書いておきました。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.com/pix/openstack_folsom_thinkpad.jpg&#34;&gt;
&lt;p&gt;手持ちの Thinkpad に OpenStack folsom 入れた写真。この写真の OpenStack Folsom
を構築した時の手順を書いておくよ。&lt;/p&gt;
&lt;h4 id=&#34;os-をインストール&#34;&gt;OS をインストール&lt;/h4&gt;
&lt;p&gt;OS をインストールします。12.10 を使いました。(12.04 LTS でも可)。/dev/sda6 等、
Cinder 用に一つパーティションを作ってマウントしないでおきます。また固定 IP ア
ドレスを NIC に付与しておきます。&lt;/p&gt;
&lt;h4 id=&#34;スクリプト取得&#34;&gt;スクリプト取得&lt;/h4&gt;
&lt;p&gt;スクリプトを取得する。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get update; sudo apt-get install git-core
% git clone https://github.com/jedipunkz/openstack_folsom_deploy.git
% cd openstack_folsom_deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;パラメータ修正&#34;&gt;パラメータ修正&lt;/h4&gt;
&lt;p&gt;deploy_with_nova-network.conf 内のパラメータを修正します。オールインワン構成な
ので、ほぼほぼ修正せずに実行しますが&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;HOST_IP=&#39;&amp;lt;Thinkpad の IP アドレス&amp;gt;&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;だけ修正。&lt;/p&gt;</description>
    </item>
    <item>
      <title>FreeBSD on OpenStack</title>
      <link>https://jedipunkz.github.io/post/2013/01/01/freebsd-on-openstack/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2013/01/01/freebsd-on-openstack/</guid>
      <description>&lt;p&gt;FreeBSD を OpenStack で管理したいなぁと思って自宅に OpenStack 環境作ってました。&lt;/p&gt;
&lt;p&gt;お正月なのに&amp;hellip;&lt;/p&gt;
&lt;p&gt;使ったのは folsom ベースの OpenStack (nova-network) と FreeBSD 9.1 です。8 系
の FreeBSD でも大体同じ作業で実現出来るぽいです。あと nova-network でって書い
たのは自宅に quantum だと少し厳しいからです。FlatDHCPManager が調度良かった。&lt;/p&gt;
&lt;p&gt;今回のポイントは FreeBSD の HDD, NIC のドライバに virtio を使うように修正する
ところです。OpenStack (KVM) は virtio 前提なので、そうせざるを得なかったです。&lt;/p&gt;
&lt;h2 id=&#34;今回使ったソフトウェア&#34;&gt;今回使ったソフトウェア&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenStack Folsom (nova-network)&lt;/li&gt;
&lt;li&gt;Ubuntu Server 12.10&lt;/li&gt;
&lt;li&gt;FreeBSD 9.1 amd64&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;作業方法&#34;&gt;作業方法&lt;/h2&gt;
&lt;p&gt;準備としてこれらが必要になります。事前に行なってください。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FreeBSD-9.1-RELEASE-amd64-disc1.iso ダウンロード&lt;/li&gt;
&lt;li&gt;作業ホスト (Ubuntu Server 12.10) に qemu-kvm をインストール&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;freebsd9.img として qcow2 イメージを作成します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% kvm-img create -f qcow2 freebsd9.img 8G
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;作成したイメージファイルに FreeBSD 9.1 をインストールします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack API を理解しインフラエンジニアの仕事の変化を感じる</title>
      <link>https://jedipunkz.github.io/post/2012/12/08/knife-fog-openstack-api/</link>
      <pubDate>Sat, 08 Dec 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/12/08/knife-fog-openstack-api/</guid>
      <description>&lt;p&gt;今日は &amp;ldquo;OpenStack Advent Calendar 2012 JP&amp;rdquo; というイベントのために記事を書きた
いと思います。Advent Calendar とはキリスト生誕を祝うため 12/25 まで毎日誰かがブログ
等で特定の話題について述べるもの、らしいです。CloudStack さん, Eucalyptus さん
も今年はやっているそうですね。&lt;/p&gt;
&lt;p&gt;イベントサイト : &lt;a href=&#34;http://atnd.org/events/34389&#34;&gt;http://atnd.org/events/34389&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;では早速！(ただ..CloudStack の Advent Calendar とネタがかぶり気味です..。)&lt;/p&gt;
&lt;p&gt;御存知の通り OpenStack は API を提供していてユーザがコードを書くことで
OpenStack のコマンド・Horizon で出来ることは全て可能です。API を叩くのに幾つか
フレームワークが存在します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fog&lt;/li&gt;
&lt;li&gt;libcloud&lt;/li&gt;
&lt;li&gt;deltacloud&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;などです。&lt;/p&gt;
&lt;p&gt;ここでは内部で fog を使っている knife-openstack を利用して API に触れてみよう
かと思います。API を叩くことを想像してもらって、インフラエンジニアの仕事内容の
変化まで述べられたらいいなぁと思っています。&lt;/p&gt;
&lt;h2 id=&#34;openstack-環境の用意&#34;&gt;OpenStack 環境の用意&lt;/h2&gt;
&lt;p&gt;予め OpenStack 環境は揃っているものとしますです。お持ちでなければ&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.com/blog/2012/11/10/openstack-folsom-install/&#34;&gt;http://jedipunkz.github.com/blog/2012/11/10/openstack-folsom-install/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;この記事を参考に環境を作ってみて下さい。あ、devstack でも大丈夫です。&lt;/p&gt;
&lt;h2 id=&#34;chef-knife-openstack-の用意&#34;&gt;chef, knife-openstack の用意&lt;/h2&gt;
&lt;p&gt;chef, knife-openstack を入れるのは OpenStack 環境でも、別のノードでも構いません。&lt;/p&gt;
&lt;p&gt;chef が確か 1.9.2 ベースが推奨だったので今回は 1.9.2-p320 使います。
ruby は rbenv で入れるのがオススメです。knife-openstack, chef のインストールは&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenFlow Trema ハンズオン参加レポート</title>
      <link>https://jedipunkz.github.io/post/2012/11/21/openflow-trema-handson-report/</link>
      <pubDate>Wed, 21 Nov 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/11/21/openflow-trema-handson-report/</guid>
      <description>&lt;p&gt;InternetWeek2012 で開かれた &amp;ldquo;OpenFlow Trema ハンズオン&amp;rdquo; に参加してきました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;講師   : Trema 開発チーム 鈴木一哉さま, 高宮安仁さま
開催日 : 2012年11月21日
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OpenStack の Quantum Plugin として Trema が扱えるという話だったので興味を持っ
たのがきっかけです。また Ruby で簡潔にネットワークをコード化出来る、という点も
個人的に非常に興味を持ちました。OpenStack, CloudStack 等のクラウド管理ソフトウェ
アが提供する API といい、Opscode Chef, Puppet 等のインフラソフトウェア構築フレー
ムワークといい、この OpenFlow もインフラを形成する技術を抽象化し、技術者がコー
ドを書くことでインフラ構築を行える、という点ではイマドキだなと思います。&lt;/p&gt;
&lt;p&gt;Google は既にデータセンター間の通信を 100% 、OpenFlow の仕様に沿った機器・ソフ
トウェアをを独自に実装しさばいているそうですし、我々が利用する日も近いと想像し
ます。&lt;/p&gt;
&lt;h2 id=&#34;openflow-のモチベーション&#34;&gt;OpenFlow のモチベーション&lt;/h2&gt;
&lt;p&gt;OpenFlow の登場には理由が幾つかあって、既存のネットワークの抱えている下記の幾
つかの問題を解決するためです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;装置仕様の肥大化&lt;/li&gt;
&lt;li&gt;多様なプロトコルが標準化&lt;/li&gt;
&lt;li&gt;装置のコスト増大&lt;/li&gt;
&lt;li&gt;ある意味、自律したシステムが招く複雑さ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一方、OpenFlow を利用すると..&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;コモディティ化された HW の利用が可能&lt;/li&gt;
&lt;li&gt;OpenFlow はコントローラ (神) が集中管理するので楽な場合もある&lt;/li&gt;
&lt;li&gt;ネットワーク運用の自動化が図れる&lt;/li&gt;
&lt;li&gt;アプリケーションに合わせた最適化&lt;/li&gt;
&lt;li&gt;柔軟な自己修復&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等のメリットが。&lt;/p&gt;
&lt;h2 id=&#34;openflow-と-trema-とは&#34;&gt;OpenFlow と Trema とは?&lt;/h2&gt;
&lt;p&gt;OpenFlow は &amp;lsquo;OpenFlow コントローラ&amp;rsquo;, &amp;lsquo;OpenFlow スイッチ&amp;rsquo; から成る。OpenFlow コ
ントローラと OpenFlow スイッチの間の通信は OpenFlow プロトコルでされる。今日の
話題 Trema はこの..&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack Folsom 構築スクリプト</title>
      <link>https://jedipunkz.github.io/post/2012/11/10/openstack-folsom-install/</link>
      <pubDate>Sat, 10 Nov 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/11/10/openstack-folsom-install/</guid>
      <description>&lt;p&gt;※2012/12/04 に内容を修正しました。Network Node を切り出すよう修正。
※213/01/09 に内容を修正しました。パラメータ修正です。&lt;/p&gt;
&lt;p&gt;OpenStack の Folsom リリースからメインコンポーネントの仲間入りした Quantum を
理解するのに時間を要してしまったのだけど、もう数十回とインストールを繰り返して
だいぶ理解出来てきました。手作業でインストールしてると日が暮れてしまうのでと思っ
て自分用に bash で構築スクリプトを作ったのだけど、それを公開しようと思います。&lt;/p&gt;
&lt;p&gt;OpenStack Folsom の構築に四苦八苦している方に使ってもらえたらと思ってます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://jedipunkz.github.com/openstack_folsom_deploy/&#34;&gt;http://jedipunkz.github.com/openstack_folsom_deploy/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;chef や puppet, juju などデプロイのフレームワークは今流行です。ただどれも環境
を予め構築しなくてはいけないので、誰でもすぐに使える環境ってことで bash スクリ
プトで書いています。時間があれば是非 chef の cookbook を書いていきたいです。と
いうか予定です。でも、もうすでに opscode 等は書き始めています。(汗&lt;/p&gt;
&lt;p&gt;ではでは、紹介を始めます。&lt;/p&gt;
&lt;h2 id=&#34;前提の構成&#34;&gt;前提の構成&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;management segment 172.16.1.0/24
+--------------------------------------------+------------------+-----------------
|                                            |                  |
|                                            |                  |
| eth2 172.16.1.13                           | eth2 172.16.1.12 | eth2 172.24.1.11
+------------+                               +-----------+      +------------+
|            | eth1 ------------------- eth1 |           |      |            |
|  network   | vlan/gre seg = 172.24.17.0/24 |  compute  |      | controller |
|    node    | data segment = 172.16.2.0/24  |   node    |      |    node    |
+------------+ 172.16.2.13       172.16.2.12 +-----------+      +------------+      
| eth0 10.200.8.13                                              | eth0 10.200.8.11
|                                                               |
|                                                               |
+--------------------------------------------+------------------+-----------------
|       public segment 10.200.8.0/24
|
| 10.200.8.1
+-----------+
| GW Router |-&amp;gt; The Internet
+-----------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quantum は、&lt;/p&gt;</description>
    </item>
    <item>
      <title>Swift で簡単に分散オブジェクトストレージ</title>
      <link>https://jedipunkz.github.io/post/2012/11/04/swift-tempauth/</link>
      <pubDate>Sun, 04 Nov 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/11/04/swift-tempauth/</guid>
      <description>&lt;p&gt;最近、OpenStack にどっぷり浸かってる &lt;a href=&#34;https://twitter.com/jedipunkz&#34;&gt;@jedipunkz&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;Folsom がリリースされて Quantum を理解するのにめちゃ苦労して楽しい真っ最中なのだけど、
今日は OpenStack の中でも最も枯れているコンポーネント Swift を使ったオブジェクトストレー
ジ構築について少し書こうかなぁと思ってます。&lt;/p&gt;
&lt;p&gt;最近は OpenStack を構築・デプロイするのに皆、Swift 入れてないのね。仲間はずれ
感たっぷりだけど、一番安定して動くと思ってる。&lt;/p&gt;
&lt;p&gt;これを読んで、自宅にオブジェクトストレージを置いちゃおぅ。&lt;/p&gt;
&lt;h2 id=&#34;構成は-&#34;&gt;構成は ?&amp;hellip;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;                        +--------+
                        | client |
                        +--------+
                             |
                      +-------------+
                      | swift-proxy |
                      +-------------+ 172.16.0.10
                             |
         +-------------------+-------------------+ 172.16.0.0/24
         |                   |                   |
+-----------------+ +-----------------+ +-----------------+
| swift-storage01 | | swift-storage02 | | swift-storage03 |
+-----------------+ +-----------------+ +-----------------+
172.16.0.11         172.16.0.12         172.16.0.13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;となる。IP アドレスは&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client : 172.16.0.0/24 のどこか&lt;/li&gt;
&lt;li&gt;swift-proxy : 172.16.0.10&lt;/li&gt;
&lt;li&gt;swift-storage01 : 172.16.0.11&lt;/li&gt;
&lt;li&gt;swift-storage02 : 172.16.0.12&lt;/li&gt;
&lt;li&gt;swift-storage03 : 172.16.0.13&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これはサンプル。自宅の環境に合わせて読み替えてください。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Secret Training of Opscode Chef</title>
      <link>https://jedipunkz.github.io/post/2012/10/06/secret-training-of-opscode-chef/</link>
      <pubDate>Sat, 06 Oct 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/10/06/secret-training-of-opscode-chef/</guid>
      <description>&lt;p&gt;昨日、開かれた &amp;ldquo;Opscode Chef のシークレットトレーニング&amp;rdquo; に参加してきました。&lt;/p&gt;
&lt;p&gt;場所はうちの会社で KDDI ウェブコミュニケーションズ。主催はクリエーションオンラ
インさんでした。講師は Sean OMeara (@someara) さん。今後 Chef のトレーニングを
日本で開くため、事前に内容についてフィードバックが欲しかったそうで、オープンな
レッスンではありませんでしたが、次回以降、日本でも期待できそうです。&lt;/p&gt;
&lt;p&gt;内容は chef の基本・メリット・考え方などを網羅した資料で1時間程進められ、その
後はハンズオンがメインでした。今日は実際にハンズオンの内容を書いていこうかと思
います。&lt;/p&gt;
&lt;p&gt;chef workstation 環境は揃っている前提にします。また chef server として opscode
の hosted chef (opscode が提供している chef のホスティングサービス,
chef-server として動作します) を使います。またターゲットホストは当日は ec2 イ
ンスタンスを使いましたが、chef ワークステーションから到達できるホストであれば
何でも良いでしょう。&lt;/p&gt;
&lt;p&gt;まずは chef-repo のクローン。講習会で使われたものです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/opscode/chef-repo-workshop-sysadmin.git chef-repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;予め cookbook が入っています。&lt;/p&gt;
&lt;p&gt;次に、manage.opscode.com へアクセスしアカウントを作ります。Free アカウントが誰
でも作れるようになっています。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://manage.opscode.com&#34;&gt;https://manage.opscode.com&lt;/a&gt; へアクセス -&amp;gt; Sign Up をクリック -&amp;gt; アカウント情報
を入力 -&amp;gt; submit -&amp;gt; メールにて verify -&amp;gt; 自分のアカウント名をクリック -&amp;gt; Get a
new key をクリックし &amp;lt;アカウント名&amp;gt;.pem をダウンロード -&amp;gt; create a
organization をクリックし Free を選択し、適当な名前で organization を作成。
validation key と knife.rb をダウンロード&lt;/p&gt;</description>
    </item>
    <item>
      <title>第7回 OpenStack 勉強会参加レポート</title>
      <link>https://jedipunkz.github.io/post/2012/08/29/7th-openstack-meetup/</link>
      <pubDate>Wed, 29 Aug 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/08/29/7th-openstack-meetup/</guid>
      <description>&lt;p&gt;第7回 OpenStack 勉強会に参加してきました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;開催日   : 2012年08月28日
開催場所 : 天王洲アイル ビットアイル
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1年以上前から OpenStack, CloudStack 界隈はウォッチしていたのだけど、実際に構築
してってなると、今月始めばかりで、OpenStack も先週4日間掛けてやっとこさ構築出来たっ
てところ&amp;hellip;orz。前回のブログ記事でへなちょこスクリプト公開しちゃったのを後悔しつ
つ現地に向かいましたw あと、その他に Opscode Chef 等の技術にも興味持って調査し
ていたので、今回の勉強会はまさに直ぐに活かせる内容だった。&lt;/p&gt;
&lt;p&gt;では早速、報告があった内容と自分の感想を交えつつ書いていきます。&lt;/p&gt;
&lt;h2 id=&#34;hp-さんのクラウドサービス-hp-cloud-services&#34;&gt;HP さんのクラウドサービス HP Cloud Services&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;日本 HP 真壁さま
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HP さんは既に Public クラウドサービスを提供し始めていて Ojbect Storage, CDN 部
分は既にリリース済みだそうだ。compute, block storage 等はベータ版状態でこれか
らリリース。OpenStack ベースな構成で Horizon 部分は自前で開発したもの。既
にサーバ数は万の桁まで到達！ MySQL な DaaS も登場予定だとか。&lt;/p&gt;
&lt;p&gt;あと HP だけにクラウドサービスに特化したサーバ機器も出していて、それが HP
Project Moonshot 。ARM/Atom 搭載のサーバで 2,880 nodes/rack が可能だとか！す
げぇ。もちろん電源等のボトルネックとなるリソースは他にも出てきそうだけど。&lt;/p&gt;
&lt;p&gt;ノード数って増えると嬉しいのかな？コア数が増えるのは嬉しいけど。&lt;/p&gt;
&lt;h2 id=&#34;canonical-juju&#34;&gt;Canonical JuJu&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Canonical 松本さま
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;JuJu は Canonical が提供しているデプロイツールで charms と呼ばれるレシピ集 (っ
て言うと語弊があるのか) に従ってソフトウェアの配布を行うツール。MAAS という物
理サーバのプロビジョニングツールと組み合わせればハードウェアを設置した後のプロ
ビジョニング操作は一気通貫出来る、といったもの。具体的な操作例を挙げてくれたの
で添付してきます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenStack ESSEX オールインワン インストール</title>
      <link>https://jedipunkz.github.io/post/2012/08/26/all-in-one-openstack-installation/</link>
      <pubDate>Sun, 26 Aug 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/08/26/all-in-one-openstack-installation/</guid>
      <description>&lt;p&gt;OpenStack のインストールってしんどいなぁ、って感じて devstack
&lt;a href=&#34;http://devstack.org/&#34;&gt;http://devstack.org/&lt;/a&gt; とかで構築して中を覗いていたのですが、そもそも devstack
って再起動してしまえば何も起動してこないし、swift がインストールされないしで。
やっぱり公式のマニュアル見ながらインストールするしかないかぁって&amp;hellip;。感じてい
たのですが&amp;hellip;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org/essex/openstack-compute/starter/os-compute-starterguide-trunk.pdf&#34;&gt;http://docs.openstack.org/essex/openstack-compute/starter/os-compute-starterguide-trunk.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;このマニュアルの前提は、ネットワーク2セグメント・server1, server2 の計2台が前
提なのですが、環境作るのがしんどいので、オールインワンな構築がしたい！サーバ1台で OpenStack ESSEX を
インストールしたい！で、シェルスクリプトを作ったのでそれを使ったインストール方法を紹介します。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.com/pix/openstack_thinkpad.jpg&#34;&gt;
&lt;p&gt;ぼくの Thinkpad に OpenStack ESSEX をインストールしてブラウザで localhost に接続して
いる画面です。ちゃんと KVM VM が起動して noVNC で接続できています。自己満足やぁ。&lt;/p&gt;
&lt;h2 id=&#34;前提条件&#34;&gt;前提条件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu Server 12.04 LTS amd64 がインストールされていること&lt;/li&gt;
&lt;li&gt;Intel-VT もしくは AMD−Vなマシン&lt;/li&gt;
&lt;li&gt;NIC が一つ以上ついているマシン&lt;/li&gt;
&lt;li&gt;/dev/sda6, /dev/sda7 (デバイス名は何でもいい) の2つが未使用で空いていること&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;です。&lt;/p&gt;
&lt;h2 id=&#34;構成&#34;&gt;構成&lt;/h2&gt;
&lt;p&gt;1 NIC を前提に eth0 と eth0:0 の2つを想定すると、こんな構成になります。eth0:0
は完全にダミーで IP アドレスは何でもいいです。br100 ブリッジデバイス上で VM が
NW I/F を持ちます。floating range ってのは OpenStack で言うグローバル IP レン
ジ。グローバルである必要は無いですが eth0 と同じレンジの IP アドレスを VM に付
与出来ます。/dev/sda6 が nova-volumes で /dev/sda7 が swift 。なので OS インス
トール時に2つのデバイスを未使用で空けておいてください。&lt;/p&gt;</description>
    </item>
    <item>
      <title>chef-solo で学ぶ chef の基本動作</title>
      <link>https://jedipunkz.github.io/post/2012/08/18/chef-solo/</link>
      <pubDate>Sat, 18 Aug 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/08/18/chef-solo/</guid>
      <description>&lt;p&gt;仕事で Opesocd Chef の情報収集をしてたのですが、僕が感じるにこれはインフラエン
ジニアの未来だと。逆に言うとインフラエンジニアの危機。AWS のようなクラウドサー
ビスがあればアプリケーションエンジニアが今までインフラエンジニアが行っていた作
業を自ら出来てしまうからです。&lt;/p&gt;
&lt;p&gt;インフラエンジニアなら身に付けるしかない！って僕が感じる Chef について
chef-solo を通して理解するために情報まとめました。&lt;/p&gt;
&lt;p&gt;chef には chef-server 構成で動作するものと chef-solo というサーバ無しで動作す
るものがある。chef-server は構築するのが少し大変 (後に方法をブログに書きたい)
なので今回は chef-solo を使ってみる。ちなみに Opscode が chef-server のホスティ
ングサービスを展開している。彼らとしてはこちらがメイン。&lt;/p&gt;
&lt;h2 id=&#34;chef-solo-の入れ方&#34;&gt;chef-solo の入れ方&lt;/h2&gt;
&lt;p&gt;opscode が推奨している ruby-1.9.2 をインストールする。rvm は色々問題を招き寄せ
るので rbenv を使って環境整えます。root ユーザ環境内に入れてください。&lt;/p&gt;
&lt;p&gt;必要なパッケージをインストール&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get update
% sudo apt-get install build-essential zlib1g-dev libssl-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;root ユーザにてrbenv をインストール&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo -i
# cd ~
# git clone git://github.com/sstephenson/rbenv.git .rbenv
# echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.zshrc
# echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ruby-build をインストール&lt;/p&gt;</description>
    </item>
    <item>
      <title>Opscode Bootstrap を使った Chef-Server 構築</title>
      <link>https://jedipunkz.github.io/post/2012/08/18/opscode-bootstrap-chef-server/</link>
      <pubDate>Sat, 18 Aug 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/08/18/opscode-bootstrap-chef-server/</guid>
      <description>&lt;p&gt;chef-server の構築は少し面倒だと前回の記事
&lt;a href=&#34;http://jedipunkz.github.com/blog/2012/08/18/chef-solo/&#34;&gt;http://jedipunkz.github.com/blog/2012/08/18/chef-solo/&lt;/a&gt; に書いたのですが、
opscode が提供している bootstrap を用いると、構築作業がほぼ自動化出来ます。
今回はこの手順を書いていきます。&lt;/p&gt;
&lt;h2 id=&#34;chef-のインストール&#34;&gt;chef のインストール&lt;/h2&gt;
&lt;p&gt;前回同様に rbenv を使って ruby をインストールし chef を gem でインストールして
いきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get update
% sudo apt-get install zlib1g-dev build-essential libssl-dev
% sudo -i
# cd ~
# git clone git://github.com/sstephenson/rbenv.git .rbenv
# echo &#39;export PATH=&amp;quot;$HOME/.rbenv/bin:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.zshrc
# echo &#39;eval &amp;quot;$(rbenv init -)&amp;quot;&#39; &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ruby-build をインストールします。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir -p ~/.rbenv/plugins
# cd ~/.rbenv/plugins
# git clone git://github.com/sstephenson/ruby-build.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ruby-1.9.2 インストール&lt;/p&gt;</description>
    </item>
    <item>
      <title>#DevLOVE に参加してきました。Chef De DevOps</title>
      <link>https://jedipunkz.github.io/post/2012/07/22/number-devlove-nican-jia-sitekimasita.-chef-de-devops/</link>
      <pubDate>Sun, 22 Jul 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/07/22/number-devlove-nican-jia-sitekimasita.-chef-de-devops/</guid>
      <description>&lt;p&gt;2012年07月21日に大崎のフィーチャーアーキテクトさんで行われた #DevLOVE (Chef De
DevOps) に参加してきました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;開催日 : 2012年07月21日(土曜日) 15:00 - 20:40
場所   : 大崎 フューチャーアーキテクトさま
URL    : http://www.zusaar.com/event/314003
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;仕事場でも Chef の利用を考え始めていて今回いい機会でした。半年前と比べるとだい
ぶ揃って来ましたが、まだまだ資料の少ない Chef。貴重な機会でした。&lt;/p&gt;
&lt;p&gt;プログラムは下の通り。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;*『Chefの下準備』by Ryutaro YOSHIBA [ @ryuzee ]
*『Chef自慢のレシピ披露』 by 中島弘貴さん [ @nakashii_ ]
* ワークショップ『みんなでCooking』
* dialog『試食会』
* Niftyさんのスーパー宣伝タイム!!!
*『渾身会』
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;@ryuzee さんの &amp;ldquo;Chef の下準備&amp;rdquo; は SlideShare に使った資料が公開されています。&lt;/p&gt;
&lt;iframe src=&#34;http://www.slideshare.net/slideshow/embed_code/13712176&#34;
width=&#34;427&#34; height=&#34;356&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34;
scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC;border-width:1px 1px
0;margin-bottom:5px&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div
style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a
href=&#34;http://www.slideshare.net/Ryuzee/20120721-chef-devlove&#34; title=&#34;20120721
chefの下準備 #devlove&#34; target=&#34;_blank&#34;&gt;20120721 chefの下準備 #devlove&lt;/a&gt;
&lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;http://www.slideshare.net/Ryuzee&#34;
target=&#34;_blank&#34;&gt;Ryuzee YOSHIBA&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;
&lt;p&gt;印象的だったのが、VirtualBox + Vagrant という環境。実際に使っていらっしゃいま
した。MacBook の中に仮想環境とそのインターフェースである Vegrant を使って、デ
プロイのテスト等が実施できるそうです。また、Vegrant 設定ファイルは Chef のレシ
ピを自動読込して、常に本番環境と同じ状態にしているそうです。CloudFormation と
いうキーワードや Capistrano というキーワードが出てきました。最近よく耳にするワー
ドです。また CI は Jenkins だよね、だったり。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DNS の猛威とその対策, 参加レポ #interop2012</title>
      <link>https://jedipunkz.github.io/post/2012/06/16/dns-report-interop2012/</link>
      <pubDate>Sat, 16 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/06/16/dns-report-interop2012/</guid>
      <description>&lt;p&gt;interop 2012 で &amp;lsquo;DNS の猛威とその対策&amp;rsquo; を傍聴してきました。簡単にレポート書い
ておきます。ちょっと油断しただけで大きな問題のアップデートが出てくる DNS。怖い
です..。&lt;/p&gt;
&lt;h2 id=&#34;本講義の概要&#34;&gt;本講義の概要&lt;/h2&gt;
&lt;p&gt;ブラジルで大規模な ISP への DNS ポイゾニング攻撃が発生。それら猛威について理解
すると同時に技術的対応策や具体的な対応プロセスについて説明。&lt;/p&gt;
&lt;h2 id=&#34;イントロダクション--インターネットエクスチェンジ-石田さん&#34;&gt;イントロダクション : インターネットエクスチェンジ 石田さん&lt;/h2&gt;
&lt;p&gt;DNS を取り巻く状況&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNS を乗っ取って悪事を働く試み : DNS Changer&lt;/li&gt;
&lt;li&gt;DNS そのものをセキュアにする方向性 : DNSSEC&lt;/li&gt;
&lt;li&gt;DNS に様々な制御を任せる方向性 : SPF, AAAA, DANE, 児童ポルノブロッキング&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事例--iij-松崎さん&#34;&gt;事例 : IIJ 松崎さん&lt;/h2&gt;
&lt;h4 id=&#34;201111-ブラジルの事例&#34;&gt;2011/11 ブラジルの事例&lt;/h4&gt;
&lt;p&gt;著名サイトへのアクセスを行うと malware が仕込まれたサイトへ誘導。ホームルータ
のキャッシュがポイゾニングされた。&lt;/p&gt;
&lt;h4 id=&#34;とあるホームルータの問題&#34;&gt;とあるホームルータの問題&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;admin パスワードが管理 web で見える&lt;/li&gt;
&lt;li&gt;wan からのアクセスが有効&lt;/li&gt;
&lt;li&gt;同じチップセットを使っている製品で同様の問題..&lt;/li&gt;
&lt;li&gt;wan からルータへアクセスすると html ソースにアカウント情報が平文で書かれてい
た&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これは怖い..。&lt;/p&gt;
&lt;h4 id=&#34;攻撃活動の実施&#34;&gt;攻撃活動の実施&lt;/h4&gt;
&lt;p&gt;攻撃者が行う手順。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;脆弱性な CPE 発見&lt;/li&gt;
&lt;li&gt;パスワード書き換え&lt;/li&gt;
&lt;li&gt;CPE が参照する DNS の書き換え&lt;/li&gt;
&lt;li&gt;著名サイト向け DNS への応答を書き換え&lt;/li&gt;
&lt;li&gt;malware サイトへ誘導&lt;/li&gt;
&lt;li&gt;銀行の安全客員ツールを無効にする malware をインストールさせる&lt;/li&gt;
&lt;li&gt;幾つかの銀行向け DNS 応答を書き換え、目的のフィッシングサイトに誘導。DNS 書
き換えは短い期間のみであった。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;規模&#34;&gt;規模&lt;/h4&gt;
&lt;p&gt;2011年時点、450万の CPE の DNS が書き換えられていた。今年も 30万以上の CPE が
影響を受けたまま。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vyatta ハンズオン参加レポ #interop2012</title>
      <link>https://jedipunkz.github.io/post/2012/06/14/vyatta-handson-interop2012/</link>
      <pubDate>Thu, 14 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/06/14/vyatta-handson-interop2012/</guid>
      <description>&lt;p&gt;interop 2012 で開催された &amp;ldquo;仮想ルータ Vyatta を使ったネットワーク構築法&amp;rdquo; に参
加してきました。簡単ですがレポートを書いておきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;開催日 : 2012/06/14(木)
場所   : 幕張メッセ Interop 2012
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最初に所感。反省です。サーバエンジニアの視点でしか感じられていなかった。次期バー
ジョンの vPlane 実装などエンタープライズ向けとしても利用出来る可能性を感じる
し、比較的小さなリソースでハンズオン参加者30人程度の vyatta ルータを動かしてサ
クサク動いているのを見て、簡単にパフォーマンスがどうとか
&lt;a href=&#34;http://jedipunkz.github.com/blog/2012/06/13/vyatta-vpn/&#34;&gt;前回の記事&lt;/a&gt;で言うべ
きじゃなかったぁ。ホント反省。&lt;/p&gt;
&lt;p&gt;ではハンズオンの内容。&lt;/p&gt;
&lt;h2 id=&#34;最初に基本情報の話&#34;&gt;最初に、基本情報の話&lt;/h2&gt;
&lt;p&gt;有償版と無償版の違い&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;メジャーリリースのみの無償版に対して有償版はマイナーリリースもあり&lt;/li&gt;
&lt;li&gt;有償版は保守あり&lt;/li&gt;
&lt;li&gt;仮想 image template 機能が有償版であり&lt;/li&gt;
&lt;li&gt;API, Web GUI, Config Sync, Systen Image Cloning が有償版であり&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;image template, config sync, cloning など、有償版ではあると嬉しい機能がモリモ
リ。&lt;/p&gt;
&lt;h2 id=&#34;最近の利用ケース&#34;&gt;最近の利用ケース&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Vyatta + VM で VPN 接続環境構築&lt;/li&gt;
&lt;li&gt;キャンパスネットワーク&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;キャンパスネットワークのユースケースが一番多いそうだ。また、会場内にアンケート
をとった結果、仮想環境での構築を想定されている方が多数だった。&lt;/p&gt;
&lt;h2 id=&#34;構成と特徴&#34;&gt;構成と特徴&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Debian Gnu/Linux ベース&lt;/li&gt;
&lt;li&gt;Quagga, StrongSwam が内部で動作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;apt-get など馴染み深いコマンドが使えます。
&lt;a href=&#34;http://www.vyatta4people.org/tag/vybuddy/&#34;&gt;http://www.vyatta4people.org/tag/vybuddy/&lt;/a&gt;
ここに色々ノウハウがあるらしい。僕はまだ見ていません。まほろば工房の近藤さんに
教えて頂きました。あとでチェックします。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vyatta で構築する簡単 VPN サーバ</title>
      <link>https://jedipunkz.github.io/post/2012/06/13/vyatta-vpn/</link>
      <pubDate>Wed, 13 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/06/13/vyatta-vpn/</guid>
      <description>&lt;p&gt;Vyatta で VPN しようと思ったら信じられないくらい簡単に構築できたので共有します。&lt;/p&gt;
&lt;p&gt;今回は PPTP (Point-to-Point Tunneling Protocol) を用いました。&lt;/p&gt;
&lt;p&gt;さっそく手順に。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ configure
# set vpn pptp remote-access authentication local-users username ${USER} password ${PASSWORD}
# set vpn pptp remote-access authentication mode local
# set vpn pptp remote-access client-ip-pool start ${IP_START}
# set vpn pptp remote-access client-ip-pool stop ${IP_END}
# set vpn pptp remote-access outside-address ${GLOBAL_IP}
# set vpn pptp remote-access dns-servers server-1 8.8.8.8
# set vpn pptp remote-access dns-servers server-1 8.8.4.4
# commit
# save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これだけです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NetBSD インストール直後の初期設定まとめ</title>
      <link>https://jedipunkz.github.io/post/2012/05/12/netbsd-first-setup/</link>
      <pubDate>Sat, 12 May 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/05/12/netbsd-first-setup/</guid>
      <description>&lt;p&gt;普段は Mac, Linux がメインなのですが、NetBSD もたまにデスクトップ機として利用
するので、初期設定手順をまとめ。&lt;/p&gt;
&lt;h2 id=&#34;console-設定-キーリマップ&#34;&gt;Console 設定, キーリマップ&lt;/h2&gt;
&lt;p&gt;Caps と Ctrl キーを入れ替えます。お約束。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# wsconsctl -w encoding=us.swapctrlcaps
# vi /etc/wscons.conf # 同様の設定を入れる
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;キーリピートを速くします。標準では遅すぎる。値は好みで。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# wsconsctl -w repeat.del1=300 # リピートが始まるまでの時間
# wsconsctl -w repeat.deln=40  # 反復間隔
# vi /etc/wscons.conf          # 同様の値を入れる
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;pkgsrc-をインストール&#34;&gt;pkgsrc をインストール&lt;/h2&gt;
&lt;p&gt;xx, y は次期に応じて変える。例 :2012Q1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr
# cvs -q -z3 -d anoncvs@anoncvs.NetBSD.org:/cvsroot checkout -r pkgsrc-20xxQy -P pkgsrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最新の状態に更新する場合。リリースタグを利用したいなら不要。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/pkgsrc
# cvs update -dP
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;grub-のインストール&#34;&gt;grub のインストール&lt;/h2&gt;
&lt;p&gt;grub をインストール。デフォルトでも良いのだけど、安心したいから。他の OS とデュ
アル・トリプルブートに設定することが多いので必要を感じて入れている場合もある。
もちろん Linux 側からインストールしても OK。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emacs でファイルブラウザ emacs-nav を利用</title>
      <link>https://jedipunkz.github.io/post/2012/05/04/emacs-nav/</link>
      <pubDate>Fri, 04 May 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/05/04/emacs-nav/</guid>
      <description>&lt;p&gt;Hacker News で取り上げられていた emacs-nav を使ってみた。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://code.google.com/p/emacs-nav/&#34;&gt;http://code.google.com/p/emacs-nav/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;インストール方法は簡単で&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% wget http://emacs-nav.googlecode.com/files/emacs-nav-20110220a.tar.gz
% tar zxvf emacs-nav-20110220a.tar.gz
% mv emacs-nav-20110220a ~/.emacs.d/emacs-nav
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;して&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;;; emacs-nav
(add-to-list &#39;load-path &amp;quot;~/.emacs.d/emacs-nav/&amp;quot;)
(require &#39;nav)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;するだけ。&lt;/p&gt;
&lt;p&gt;見た目はこんな感じ。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.com/pix/emacs-nav.png&#34;&gt;
&lt;p&gt;起動は M-x nav と入力。ウィンドウの左にファイルブラウザが開いてファイルを選択
出来る。これだけだと、使うメリットを感じないが、面白いのがマウスで選択出来ると
ころ。TextMate のブラウザのような感じだ。&lt;/p&gt;
&lt;p&gt;今だと anything.el が便利すぎて、こちらを利用する価値を見出せるか分からないけ
ど、暫く使ってみようと思う。&lt;/p&gt;</description>
    </item>
    <item>
      <title>powerline.el で emacs モードラインを派手に</title>
      <link>https://jedipunkz.github.io/post/2012/05/04/powerline.el-emacs/</link>
      <pubDate>Fri, 04 May 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/05/04/powerline.el-emacs/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.emacswiki.org/emacs-en/PowerLine&#34;&gt;http://www.emacswiki.org/emacs-en/PowerLine&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;vim の powerline に似たモードを emacs で実現できる powerline.el を試してみた。
見た目が派手でかわいくなるので、気に入った。w すでに下記のようなサイトで紹介さ
れつつある。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://d.hatena.ne.jp/kenjiskywalker/20120502/1335922233&#34;&gt;http://d.hatena.ne.jp/kenjiskywalker/20120502/1335922233&lt;/a&gt;
&lt;a href=&#34;http://n8.hatenablog.com/entry/2012/03/21/172928&#34;&gt;http://n8.hatenablog.com/entry/2012/03/21/172928&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;インストールすると見た目はこんな感じになる。&lt;/p&gt;
&lt;img src=&#34;http://jedipunkz.github.com/pix/powerline.png&#34;&gt;
&lt;p&gt;うん、かわいい。&lt;/p&gt;
&lt;p&gt;インストール方法は簡単。auto-install 環境が構築されているとして&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto-install-from-emacs-wiki powerline.el
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;する。auto-install が入っていなければ
&lt;a href=&#34;http://www.emacswiki.org/emacs/powerline.el&#34;&gt;http://www.emacswiki.org/emacs/powerline.el&lt;/a&gt;
ここにある powerline.el をダウンロードして ~/.emacs.d/lisp/ 配下など path の通っ
ている所に入れれば OK。&lt;/p&gt;
&lt;p&gt;あとは .emacs 内には下記を追記するだけだ。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;;; powerline.el
(defun arrow-right-xpm (color1 color2)
  &amp;quot;Return an XPM right arrow string representing.&amp;quot;
  (format &amp;quot;/* XPM */
static char * arrow_right[] = {
\&amp;quot;12 18 2 1\&amp;quot;,
\&amp;quot;. c %s\&amp;quot;,
\&amp;quot;  c %s\&amp;quot;,
\&amp;quot;.           \&amp;quot;,
\&amp;quot;..          \&amp;quot;,
\&amp;quot;...         \&amp;quot;,
\&amp;quot;....        \&amp;quot;,
\&amp;quot;.....       \&amp;quot;,
\&amp;quot;......      \&amp;quot;,
\&amp;quot;.......     \&amp;quot;,
\&amp;quot;........    \&amp;quot;,
\&amp;quot;.........   \&amp;quot;,
\&amp;quot;.........   \&amp;quot;,
\&amp;quot;........    \&amp;quot;,
\&amp;quot;.......     \&amp;quot;,
\&amp;quot;......      \&amp;quot;,
\&amp;quot;.....       \&amp;quot;,
\&amp;quot;....        \&amp;quot;,
\&amp;quot;...         \&amp;quot;,
\&amp;quot;..          \&amp;quot;,
\&amp;quot;.           \&amp;quot;};&amp;quot;  color1 color2))

(defun arrow-left-xpm (color1 color2)
  &amp;quot;Return an XPM right arrow string representing.&amp;quot;
  (format &amp;quot;/* XPM */
static char * arrow_right[] = {
\&amp;quot;12 18 2 1\&amp;quot;,
\&amp;quot;. c %s\&amp;quot;,
\&amp;quot;  c %s\&amp;quot;,
\&amp;quot;           .\&amp;quot;,
\&amp;quot;          ..\&amp;quot;,
\&amp;quot;         ...\&amp;quot;,
\&amp;quot;        ....\&amp;quot;,
\&amp;quot;       .....\&amp;quot;,
\&amp;quot;      ......\&amp;quot;,
\&amp;quot;     .......\&amp;quot;,
\&amp;quot;    ........\&amp;quot;,
\&amp;quot;   .........\&amp;quot;,
\&amp;quot;   .........\&amp;quot;,
\&amp;quot;    ........\&amp;quot;,
\&amp;quot;     .......\&amp;quot;,
\&amp;quot;      ......\&amp;quot;,
\&amp;quot;       .....\&amp;quot;,
\&amp;quot;        ....\&amp;quot;,
\&amp;quot;         ...\&amp;quot;,
\&amp;quot;          ..\&amp;quot;,
\&amp;quot;           .\&amp;quot;};&amp;quot;  color2 color1))


(defconst color1 &amp;quot;#FF6699&amp;quot;)
(defconst color3 &amp;quot;#CDC0B0&amp;quot;)
(defconst color2 &amp;quot;#FF0066&amp;quot;)
(defconst color4 &amp;quot;#CDC0B0&amp;quot;)

(defvar arrow-right-1 (create-image (arrow-right-xpm color1 color2) &#39;xpm t :ascent &#39;center))
(defvar arrow-right-2 (create-image (arrow-right-xpm color2 &amp;quot;None&amp;quot;) &#39;xpm t :ascent &#39;center))
(defvar arrow-left-1  (create-image (arrow-left-xpm color2 color1) &#39;xpm t :ascent &#39;center))
(defvar arrow-left-2  (create-image (arrow-left-xpm &amp;quot;None&amp;quot; color2) &#39;xpm t :ascent &#39;center))

(setq-default mode-line-format
 (list  &#39;(:eval (concat (propertize &amp;quot; %b &amp;quot; &#39;face &#39;mode-line-color-1)
                        (propertize &amp;quot; &amp;quot; &#39;display arrow-right-1)))
        &#39;(:eval (concat (propertize &amp;quot; %m &amp;quot; &#39;face &#39;mode-line-color-2)
                        (propertize &amp;quot; &amp;quot; &#39;display arrow-right-2)))

        ;; Justify right by filling with spaces to right fringe - 16
        ;; (16 should be computed rahter than hardcoded)
        &#39;(:eval (propertize &amp;quot; &amp;quot; &#39;display &#39;((space :align-to (- right-fringe 17)))))

        &#39;(:eval (concat (propertize &amp;quot; &amp;quot; &#39;display arrow-left-2)
                        (propertize &amp;quot; %p &amp;quot; &#39;face &#39;mode-line-color-2)))
        &#39;(:eval (concat (propertize &amp;quot; &amp;quot; &#39;display arrow-left-1)
                        (propertize &amp;quot;%4l:%2c  &amp;quot; &#39;face &#39;mode-line-color-1)))
)) 

(make-face &#39;mode-line-color-1)
(set-face-attribute &#39;mode-line-color-1 nil
                    :foreground &amp;quot;#fff&amp;quot;
                    :background color1)

(make-face &#39;mode-line-color-2)
(set-face-attribute &#39;mode-line-color-2 nil
                    :foreground &amp;quot;#fff&amp;quot;
                    :background color2)

(set-face-attribute &#39;mode-line nil
                    :foreground &amp;quot;#fff&amp;quot;
                    :background color3
                    :box nil)
(set-face-attribute &#39;mode-line-inactive nil
                    :foreground &amp;quot;#fff&amp;quot;
                    :background color4)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;色を少し変えただけで、ほぼ emacswiki に載っているコードそのままだ。no window
だと寂しいことになるが、まぁ仕方ない。vim でも powerline を使って気に入ってい
たので emacs でも使えるとあって嬉しい限りだ。これから少しずつカスタマイズして
いこうと思う。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vyatta で無線アクセスポイント</title>
      <link>https://jedipunkz.github.io/post/2012/05/04/vyatta-wireless-ap/</link>
      <pubDate>Fri, 04 May 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/05/04/vyatta-wireless-ap/</guid>
      <description>&lt;p&gt;自宅ルータを Vyatta で運用開始したのだけど、無線ルータ化ができたのでメモしておき
ます。&lt;/p&gt;
&lt;p&gt;まずはアクセスポイントとして稼働する無線カードの選定。下記の URL に Linux 系で
動作する無線カードチップ名の一覧が載っている。Vyatta は Linux 系ドライバを利用
しているので、この一覧が有効なはずだ。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://linuxwireless.org/en/users/Drivers&#34;&gt;http://linuxwireless.org/en/users/Drivers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Intel 系も結構アクセスポイントとしては動作しないことが判ったので Atheros の
AR9k のカードを購入した。私が買ったのはAR9280 チップの mini PCI-E 無線カード。&lt;/p&gt;
&lt;p&gt;早速装着してみると、認識した！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% dmesg | grep ath
[   11.528390] ath9k 0000:01:00.0: PCI INT A -&amp;gt; GSI 16 (level, low) -&amp;gt; IRQ
16
[   11.528398] ath9k 0000:01:00.0: setting latency timer to 64
[   11.961619] ath: EEPROM regdomain: 0x37
[   11.961620] ath: EEPROM indicates we should expect a direct regpair map
[   11.961622] ath: Country alpha2 being used: AW
[   11.961623] ath: Regpair used: 0x37
[   12.031676] ieee80211 phy0: Selected rate control algorithm &#39;ath9k_rate_control&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;早速設定に入る。有線側有線 NIC と無線 NIC をブリッジ接続する。br0 デバイスにの
み IP アドレスを振り、eth1, wlan0 は IP アドレスを振らない構成にする。&lt;/p&gt;</description>
    </item>
    <item>
      <title>vyatta で UPnP 接続</title>
      <link>https://jedipunkz.github.io/post/2012/04/29/vyatta-upnp/</link>
      <pubDate>Sun, 29 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/04/29/vyatta-upnp/</guid>
      <description>&lt;p&gt;Vyatta を自宅ルータで使い始めて感じたのは、PS3 などのゲーム機や IP 電話など
UPnP 接続が必要なことがあるってこと。ただ Vyatta は UPnP に対応していないので、
どうしようかと思っていたら、有志の方が作ってくれたソフトウェアがあり、うちでも
これを使うことにした。今回はその方法を記していきます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kiall/vyatta-upnp&#34;&gt;https://github.com/kiall/vyatta-upnp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上記のソースを取得して生成するのだが、vyatta 上で構築する環境を作りたくないの
で、私は Debian Gnu/Linux マシン上で行いました。Ubuntu でも大丈夫だと思います。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;debian% sudo apt-get &amp;amp;&amp;amp; sudo apt-get install build-essential
debian% git clone https://github.com/kiall/vyatta-upnp.git
debian% cd vyatta-upnp
debian% dpkg-buildpackage -us -uc -d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一つ上のディレクトリに vyatta-upnp_0.2_all.deb という .deb ファイルができあがっ
ているはずで、これが UPnP パッケージファイル vyatta-upnp_0.2_all.deb です。&lt;/p&gt;
&lt;p&gt;次に vyatta 上での作業。packages.vyatta.com から libupnp4 と linux-igd を取得、
その後先ほど生成した vyatta-upnp_0.2_all.deb を vyatta 上に持ってきてからイン
ストールします。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vyatta# cd /tmp/
vyatta# wget http://packages.vyatta.com/debian/pool/main/libu/libupnp4/libupnp4_1.8.0~svn20100507-1_amd64.deb
vyatta# wget http://packages.vyatta.com/debian/pool/main/l/linux-igd/linux-igd_1.0+cvs20070630-3_amd64.deb
vyatta# scp ${DEBIAN}:/${SOMEWHERE}/vyatta-upnp_0.2_all.deb . # 先ほど生成したファイル
vyatta# dpkg -i libupnp4_1.8.0~svn20100507-1_amd64.deb linux-igd_1.0+cvs20070630-3_amd64.deb
vyatta# dpkg -i vyatta-upnp_0.2_all.deb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これで設定が可能になりました。設定してみます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>vyatta で自宅ルータ構築</title>
      <link>https://jedipunkz.github.io/post/2012/04/28/vyattarouter/</link>
      <pubDate>Sat, 28 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/04/28/vyattarouter/</guid>
      <description>&lt;p&gt;自宅ルータを Vyatta で構築してみたくなり、秋葉原の ark でマシンを調達しました。
Broadcom の BCM57780 チップが搭載された NIC がマザーボード J&amp;amp;W MINIX™
H61M-USB3 だったのですが、Vyatta.org によると Broadcom の NIC が Certificated
Hardware に載っていなくて心配でした。まぁ定評のある NIC メーカだから動くだろう
と楽観視していたのですけど、案の定動きました。vyatta.org の Certificated
Hardware にコミットしたら &amp;ldquo;user tested&amp;rdquo; として掲載してもらえました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.vyatta.org/hardware/interfaces&#34;&gt;http://www.vyatta.org/hardware/interfaces&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;こんな感じに見えています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# dmesg | grep Broadcom
[    3.284646] tg3 0000:03:00.0: eth0: attached PHY driver [Broadcom BCM57780](mii_bus:phy_addr=300:01)
[    3.524122] tg3 0000:05:00.0: eth1: attached PHY driver [Broadcom BCM57780](mii_bus:phy_addr=500:01)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;今回は、基本的な設定 (PPPoE, NAT, DHCP) 周りを記していきます。&lt;/p&gt;
&lt;p&gt;環境は&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+--------+
|  Modem |
+--------+
|
| pppoe0
+--eth0--+
| vyatta |
+--eth1--+
|           192.168.1.0/24
+----------+
|          |192.168.1.10
+--------+ +--------+
|  CPE   | |  DNS   |
+--------+ +--------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;として記します。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mosh を使う</title>
      <link>https://jedipunkz.github.io/post/2012/04/14/ssh-mosh/</link>
      <pubDate>Sat, 14 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/04/14/ssh-mosh/</guid>
      <description>&lt;p&gt;今週/先週？、Hacker News で取り上げられた &lt;a href=&#34;http://mosh.mit.edu/&#34;&gt;Mosh&lt;/a&gt; を自宅
と会社で使い始めた。SSH 代替なソフトウェアで、SSP (State Synchronization
Protocol)over UDP で動作している。MIT が開発したそうだ。&lt;/p&gt;
&lt;p&gt;動作は、クライアントがシーケンス番号と共にデータグラムをサーバに送信し、同期し
続ける。クライアントがローミングし IP アドレスが代わる等した時、以前より大きい
シーケンス番号と共に正当なパケットが送信されたとサーバが認識した場合のみ、サー
バは新しいソース IP アドレスを新たなクライアントだと認識する。もちろん、この場
合のローミングは NAT 越しの IP 再アサイン時やクライアントのネットワークインター
フェース切り替えやノート PC を新たな無線アクセスポイント配下へ移動した場合も同
様に動作する。めちゃ便利やん。Mosh は SSP を2経路持ち、1つはクライアントからサー
バへユーザの打ったキーの同期を取る。もう一方はサーバからクライアントへで、スク
リーンの状態をクライアントへ同期を取るためだ。&lt;/p&gt;
&lt;p&gt;つまり、ノート PC やその他モバイル機器の IP アドレスが変わったとしても接続性は
担保され、また ノート PC のスリープ解除後にも接続性は確保され続ける。また、UDP
で動作しているので、フルスクリーンの vim や emacs 等での再描画の遅延等も起こり
にくそうだ。あと Ctrl-C 。TCP だと、キータイプがサーバプログラムに伝わらない状
況はプログラムプロセスが混雑しているとよくあるのだが、SSP over UDP での Ctrl-C
はそういうことが無いそうだ。&lt;/p&gt;
&lt;p&gt;また、認証機構は SSH に任せているので sshd は引き続き稼働させておく必要がある。
mosh は接続する先のユーザが一般ユーザ権限で動作させるプログラムでしかない。つ
まり mosh daemon は必要ないようだ。&lt;/p&gt;
&lt;p&gt;実際にインストールしてみた。Mac の場合、homebrew で&lt;/p&gt;</description>
    </item>
    <item>
      <title>debian sid on thinkpad</title>
      <link>https://jedipunkz.github.io/post/2012/04/07/debian-sid-on-thinkpad-first-setup/</link>
      <pubDate>Sat, 07 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/04/07/debian-sid-on-thinkpad-first-setup/</guid>
      <description>&lt;p&gt;ノート PC を購入するといつも Debian Gnu/Linux sid をインストールするのだけれど
も、X Window System や InputMethod をインストールして利用し始められるところま
での手順っていつも忘れる。メモとしてブログに載せておきます。&lt;/p&gt;
&lt;h2 id=&#34;console-上での-ctrlcaps-swap-設定&#34;&gt;console 上での ctrl:caps swap 設定&lt;/h2&gt;
&lt;p&gt;取りあえずこの設定をしないと、何も操作出来ない。Caps Lock と Control キーを入
れ替える設定です。&lt;/p&gt;
&lt;p&gt;/etc/default/keyboard を下記のように修正&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;XKBOPTIONS=&amp;quot;ctrl:swapcaps&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下記のコマンドで設定を反映。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo /etc/init.d/console-setup restart
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sid-の-sourceslist-設定&#34;&gt;sid の sources.list 設定&lt;/h2&gt;
&lt;p&gt;Debian Gnu/Linux をノート PC にインストールする時は必ず sid を入れます。新し目
のソフトウェアを使いたいから。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;deb http://ftp.riken.jp/Linux/debian/debian/ unstable main contrib non-free
deb-src http://ftp.riken.jp/Linux/debian/debian/ unstable main contrib non-free
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下記のコマンドで dist-upgrade&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get update
% sudo apt-get dist-upgrade
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;iwlwifi-のインストールとネットワーク設定&#34;&gt;iwlwifi のインストールとネットワーク設定&lt;/h2&gt;
&lt;p&gt;買うノート PC はいつも ThinkPad。大体 intel チップな Wi-Fi モジュールが搭載さ
れているので、iwlwifi を使う。&lt;/p&gt;</description>
    </item>
    <item>
      <title>switching screen-&gt;tmux</title>
      <link>https://jedipunkz.github.io/post/2012/04/01/switching-screen-tmux/</link>
      <pubDate>Sun, 01 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/04/01/switching-screen-tmux/</guid>
      <description>&lt;p&gt;長年 Gnu screen 愛用者だったのだけど完全に tmux に移行しました。&lt;/p&gt;
&lt;p&gt;愛用している iterm2 との相性も良く、好都合な点が幾つかあり移行する価値がありました。&lt;/p&gt;
&lt;p&gt;ただ、サーバサイドでの利用は諦めました。問題だったコピペ問題をクリアしている tmux のバージョンが
Debian sid から取得出来たのだけど、まだまだ完成度高くなく..。&lt;/p&gt;
&lt;p&gt;よって、Mac に tmux をインストールして作業するようになりました。インストール方法はこれ。&lt;/p&gt;
&lt;p&gt;予め &lt;a href=&#34;https://github.com/mxcl/homebrew/wiki/installation&#34;&gt;https://github.com/mxcl/homebrew/wiki/installation&lt;/a&gt; に
したがって homebrew をインストールする必要あり。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% brew update
% brew install tmux
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;インストールしたら .tmux.conf の作成に入る。prefix キーは C-t にしたかった。screen 時代から
これを使っていて指がそう動くから。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# prefix key
set-option -g prefix C-t
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;またステータスライン周りの設定。色なども自分で選択すると良い。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# view
set -g status-interval 5
set -g status-left-length 16
set -g status-right-length 50
# status
set -g status-fg white
set -g status-bg black
set -g status-left-length 30
set -g status-left &#39;#[fg=white,bg=black]#H#[fg=white]:#[fg=white][#S#[fg=white]][#[default]&#39;
set -g status-right &#39;#[fg=white,bg=red,bold] [%Y-%m-%d(%a) %H:%M]#[default]&#39;
# window-status-current
setw -g window-status-current-fg white
setw -g window-status-current-bg red
setw -g window-status-current-attr bold#,underscore
# pane-active-border
set -g pane-active-border-fg black
set -g pane-active-border-bg blue
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;UTF-8 有効化やキーバインド設定等は&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>github.com で octopress 構築</title>
      <link>https://jedipunkz.github.io/post/2012/03/20/github-dot-com-de-octopress-gou-zhu/</link>
      <pubDate>Tue, 20 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/20/github-dot-com-de-octopress-gou-zhu/</guid>
      <description>&lt;p&gt;pages.github.com は github.com の WEB ホスティングサービスです。これを利用して octopress のブログを
構築する方法をメモしていきます。&lt;/p&gt;
&lt;p&gt;まず、github.com に &amp;ldquo;${好きな名前}.github.com&amp;rdquo; という名前のレポジトリを github.com 上で作成します。
レポジトリの作成は普通のレポジトリ作成と同じ方法で行えます。しばらくすると
&amp;ldquo;${好きな名前}.github.com のページがビルド出来ました&amp;rdquo; という内容でメールが送られてきます。&lt;/p&gt;
&lt;p&gt;pages.github.com によると、レポジトリページで &amp;ldquo;GitHub Page&amp;rdquo; にチェックを入れろと書いてありますが、情報が古いようです。
2012/03/20 現在、この操作の必要はありませんでした。&lt;/p&gt;
&lt;p&gt;次に octopress の環境構築。&lt;/p&gt;
&lt;p&gt;octopress は、jekyll ベースのブログツールです。markdown 形式で記事を書くのですが、emacs や vim 等
好きなエディタを使って記事を書けるので便利です。最近 &amp;ldquo;Blogging with Emacs&amp;rdquo; なんてブログをよく目にしたと
思うのですが、まさにソレですよね。エンジニアにとっては嬉しいブログ環境です。&lt;/p&gt;
&lt;p&gt;まずは、rvm の環境構築を。octopress は ruby 1.9.2 以上が必要なので用意するのですが rvm を使うと
手軽に用意出来るので、今回はその方法を記します。&lt;/p&gt;
&lt;p&gt;参考 URL は &lt;a href=&#34;http://octopress.org/docs/setup/rvm/&#34;&gt;http://octopress.org/docs/setup/rvm/&lt;/a&gt; です。&lt;/p&gt;
&lt;p&gt;まずは準備から。私の環境は Ubuntu Server 10.04 LTS なのですが、下記のパッケージが必用になります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get install gcc make zlib1g-dev libssl-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下記のコマンドを実行すると、rvm がインストールされます。&lt;/p&gt;</description>
    </item>
    <item>
      <title>cocoa な emacs インストール</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/cocoa-na-emacs-insutoru/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/cocoa-na-emacs-insutoru/</guid>
      <description>&lt;p&gt;Carbon な API は排除していくべきと Apple も言っているようですし、自宅も会社も Cocoa な emacs を使うようになりました。&lt;/p&gt;
&lt;p&gt;その手順を書いていきます。&lt;/p&gt;
&lt;p&gt;ソースとパッチでビルドも出来るのですが、&lt;a href=&#34;http://mxcl.github.com/homebrew/&#34; target=&#34;_blank&#34;&gt;homebrew&lt;/a&gt; 使うとメチャ楽なので今回はそれを使います。
homebrew は公式サイトに詳しいことが書いてありますけどインストールがワンラインで済みます。
あと、事前に AppStore で Xcode を入れてください。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% /usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.github.com/gist/323731)&amp;quot;                                                     
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;だけです。&lt;/p&gt;
&lt;p&gt;そして Cocoa な emacs インストール。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% brew install --cocoa emacs 
% sudo mv /usr/local/Cellar/emacs/24.1/Emacs.app /Applications/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上です..。簡単すぎる。先人たちのおかげですね。&lt;/p&gt;
&lt;p&gt;次は時間見つけて anything.el のことを書こうかなぁと思ってます。&lt;/p&gt;
&lt;p&gt;参考 URL : &lt;a href=&#34;http://mxcl.github.com/homebrew/&#34; title=&#34;homebrew&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;http://mxcl.github.com/homebrew/&#34;&gt;http://mxcl.github.com/homebrew/&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>conky statusbar</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/conky-statusbar/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/conky-statusbar/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://files.chobiwan.me/pix/conky_capture.png&#34;&gt;&lt;img src=&#34;http://files.chobiwan.me/pix/conky_capture.png&#34; alt=&#34;&#34; title=&#34;conky_capture&#34; width=&#34;721&#34; height=&#34;274&#34; class=&#34;alignnone size-full wp-image-60&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上の画像は conky というツールのキャプチャです。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://conky.sourceforge.net/&#34; target=&#34;_blank&#34;&gt;conky&lt;/a&gt; は x window で使える linux マシンのステータスを文字・グラフ描画で表現してくれるツールです。&lt;/p&gt;
&lt;p&gt;透明にしたりグラフ表示を派手にすることも出来るのだけど、わたしは上図のようにステータスバーとして使ってます。Window Manager に openbox という素っ気ないものを使うようにしてるので、これ自体がファイラーもステータスバーも無いんです。なので conky を利用して &amp;lsquo;時間&amp;rsquo;, &amp;lsquo;バッテリ残量&amp;rsquo;, &amp;lsquo;AC アダプタ有無&amp;rsquo;, &amp;lsquo;ネットワーク使用量&amp;rsquo; 等を表示してます。&lt;/p&gt;
&lt;p&gt;deviantart に &lt;a href=&#34;http://rent0n86.deviantart.com/art/My-horizontal-conkyrc-122604863&#34; target=&#34;_blank&#34;&gt;rent0n86&lt;/a&gt; さんという方が投稿した作品があって、それをこちょこちょ自分用にいじって使ってます。&lt;/p&gt;
&lt;p&gt;debian gnu/linux な GUI 環境があれば&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get conky-all
% cd $HOME
% wget https://raw.github.com/chobiwan/dotfiles/master/.conkyrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;で、この環境を作れます。&lt;/p&gt;
&lt;p&gt;表示する内容は環境に合わせて修正すると楽しいです。幅は minimum_size パラメータで合わせてください。&lt;/p&gt;
&lt;p&gt;パラメータ一覧は、&lt;a href=&#34;http://wiki.conky.be/index.php?title=Configuration_Settings&#34; target=&#34;_blank&#34;&gt;公式 Wiki サイト&lt;/a&gt; に正しい情報が載っています。&lt;/p&gt;
&lt;p&gt;話変わるけど、enlightenment 17 が完成度高くならない理由ってなんなのでしょうかね？ 16 を愛用していただけに残念。&lt;/p&gt;</description>
    </item>
    <item>
      <title>gitosis ssh&#43;git サーバ</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/gitosis-ssh-plus-git-saba/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/gitosis-ssh-plus-git-saba/</guid>
      <description>&lt;p&gt;github.com は便利なのだけどプライベートなレポジトリを作るのにお金払うのはもったいないので自宅サーバに SSH 経由の Git サーバを構築した。その時の手順をメモしておきます。&lt;/p&gt;
&lt;p&gt;gitosis という便利なツールがあって、これを使うとあっという間に環境構築できます。私の環境は debian Gnu/Linux Squeeze なのですが apt-get で必要なモノを入れました。gitosis は git で持ってきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;remote% sudo apt-get update
remote% sudo apt-get install git git-core python python-setuptools
remote% cd $HOME/usr/src
remote% git clone git://eagain.net/gitosis.git
remote% cd gitosis
remote% sudo python setup.py install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;SSH でアクセスする先のユーザを作ります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;remote% sudo adduser --shell /bin/sh -gecos --group \
        --disable-password --home /home/git git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;作業端末で rsa な SSH 公開鍵を生成して ${remote} サーバは転送する。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;local% ssh-keygen -t rsa
... インタラクティブに答える
local% scp .ssh/id_dsa.pub ${remote}:/tmp/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;転送した鍵を元に ${remote} サーバ上で git レポジトリを初期化する。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Heroku JP Meetup #3</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/heroku-jp-meetup-number-3/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/heroku-jp-meetup-number-3/</guid>
      <description>&lt;p&gt;白金台のクックパッドさんで行われた &amp;ldquo;heroku jp meet up #3&amp;rdquo; に参加してきました。&lt;/p&gt;
&lt;p&gt;東京マラソン参加のため来日されていた &lt;a href=&#34;http://twitter.com/stolt45&#34;&gt;Christopher Stolt&lt;/a&gt; さんや Ruby コミッタの&lt;a href=&#34;http://twitter.com/ayumin&#34;&gt;相澤&lt;/a&gt;さんなどの話を聞けました。&lt;/p&gt;
&lt;p&gt;Christopher さんからは、基本的な使い方や heroku で動作させたアプリケーションをローカル環境で動作させる foreman、また皆が意外と気にするアプリのログを tail する方法などの説明がありました。PaaS での皆の懸念点が結構解決されたんじゃないかなぁ。&lt;/p&gt;
&lt;p&gt;相澤さんからは NY マラソンでの実績など、比較的エンタープライズな使われ方もされ初めていると説明がありました。あと、呼び名なのですが heroku は &amp;ldquo;へろく&amp;rdquo; と発音するそうです。確かに about.heroku.com には &amp;ldquo;Heroku (pronounced her-OH-koo) is a cloud application platform&amp;rdquo; と書いてあるのだが、&amp;ldquo;へろく&amp;rdquo; が正しいそうです。w&lt;/p&gt;
&lt;p&gt;そのた LT が幾つあって、ちょうど気になっていた &lt;a href=&#34;http://lokka.org/&#34;&gt;Lokka&lt;/a&gt; の話があったので、自宅に帰ってから自分の heroku アカウントで lokka を動かしてみました。lokka の公式サイトに手順が書いてあって、そのままなのですが行ったのは、&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% gem install heroku bundler
% git clone git://github.com/komagata/lokka.git
% cd lokka
% heroku create
% git push heroku master
% heroku rake db:setup
% heroku open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;すれば OK。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenFlow 勉強会</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/openflow-mian-qiang-hui/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/openflow-mian-qiang-hui/</guid>
      <description>&lt;p&gt;2012年2月6日、西新宿にある株式会社ニフティさんで行われた &amp;ldquo;OpenFlow 勉強会&amp;rdquo; に参加したので簡単なレポメモを書いておきます。&lt;/p&gt;
&lt;p&gt;まずは OpenFlow の基本動作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;メッセージの切り出し&lt;/li&gt;
&lt;li&gt;ハンドシェイク&lt;/li&gt;
&lt;li&gt;コネクションの維持&lt;/li&gt;
&lt;li&gt;スイッチから送られてくるメッセージへの応答&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;構成は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenFlow コントローラ, スイッチから成る&lt;/li&gt;
&lt;li&gt;コントローラは通信制御&lt;/li&gt;
&lt;li&gt;スイッチはフロールールをコントローラに問い合わせ通信を受け流し(packet/frame 転送)&lt;/li&gt;
&lt;li&gt;コントローラは L2 - L4 フィールドを見て制御する&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;そしてコントローラ、スイッチは各社・団体から提供されている。今月も Nicira Networks さんが自社システムの構成を抽象的ではありますが公開され、HP さんも OpenFlow 対応スイッチを12製品ほど発表されました。&lt;/p&gt;
&lt;p&gt;コントローラの種別、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Beacon (Java)&lt;/li&gt;
&lt;li&gt;NOX (Python)&lt;/li&gt;
&lt;li&gt;Ryu&lt;/li&gt;
&lt;li&gt;NodeFlow&lt;/li&gt;
&lt;li&gt;Trema (C/ruby)&lt;/li&gt;
&lt;li&gt;Nicira Networks&lt;/li&gt;
&lt;li&gt;Big Switch Networks&lt;/li&gt;
&lt;li&gt;Midokura&lt;/li&gt;
&lt;li&gt;NTT Data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;スイッチの種別、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cisco nexus 3000&lt;/li&gt;
&lt;li&gt;IBM BNT rackSwitch G8264&lt;/li&gt;
&lt;li&gt;NEC Univerge PF5240/PF5820&lt;/li&gt;
&lt;li&gt;Pronto Systems 3240/3290&lt;/li&gt;
&lt;li&gt;HP 3500/5400&lt;/li&gt;
&lt;li&gt;HP OpenFlow 化 firmware&lt;/li&gt;
&lt;li&gt;Reference Implementation (Software)&lt;/li&gt;
&lt;li&gt;Open vSwitch (Software)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NEC さんの PF ほにゃららは、GUI なインターフェースと API を持った製品で OpenFlow 1.0.0 仕様に準拠。スイッチ25台までを管理するコントローラ。価格は、コントローラ : 1000万, スイッチ : 250万 だそうです。スイッチ25台はあくまでもソフトリミットらしいです。&lt;/p&gt;</description>
    </item>
    <item>
      <title>USB Stick で Debian Gnu/Linux インストール</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/usb-stick-de-debian-gnu-slash-linux-insutoru/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/usb-stick-de-debian-gnu-slash-linux-insutoru/</guid>
      <description>&lt;p&gt;MS Windows なツールを使う方法だったり、vmlinuz, initrd をファイラーでコピーしたり、何故かいつもインターネットで調べると USB スティックを利用した debian のインストール方法が&amp;rsquo;面倒&amp;rsquo;, &amp;lsquo;不確か&amp;rsquo; なので、忘れないようにメモ。&lt;/p&gt;
&lt;p&gt;手元に linux 端末用意して、USB スティック挿す。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% wget ftp://ftp.jp.debian.org/pub/Linux/debian-cd/6.0.3/amd64/iso-cd/debian-6.0.3-amd64-netinst.iso
% sudo cat debian-6.0.3-amd64-netinst.iso &amp;gt; /dev/sdb # 挿した USB スティックのデバイス名
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;で終わり。&lt;/p&gt;
&lt;p&gt;ただ弱点があって、フルイメージの iso は利用できないでの、今回みたいに netinstall だったり businesscard な iso を利用しかない。
他のディストリビューションもだけど、インストールする環境はネットに繋がっていないと不都合があるって時代だからいいかなぁ。&lt;/p&gt;
&lt;p&gt;一方、Ubuntu Server は賢い子なので &lt;a href=&#34;http://www.ubuntu.com/download/ubuntu/download&#34; target=&#34;blank&#34;&gt;公式サイト&lt;/a&gt; に行くと USB スティック用の iso がダウンロードできたり iso を焼く環境に合わせて手順まで教えてくれる&amp;hellip;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>WordPress を nginx &#43; fastcgi で高速化</title>
      <link>https://jedipunkz.github.io/post/2012/03/07/wordpress-wo-nginx-plus-fastcgi-degao-su-hua/</link>
      <pubDate>Wed, 07 Mar 2012 00:00:00 +0000</pubDate>
      <guid>https://jedipunkz.github.io/post/2012/03/07/wordpress-wo-nginx-plus-fastcgi-degao-su-hua/</guid>
      <description>&lt;p&gt;ブログを始めるにあたり、wordpress 環境を構築する必要が出てきました。いつもの apache2 + mysql5 + PHP じゃつまらないので、nginx と fastcgi を使って少しだけ高速化してみました。メモですけど、ここに手順を記していきます。&lt;/p&gt;
&lt;p&gt;※ wordpress から octopress に移行しました&amp;hellip; (2012/03/07)&lt;/p&gt;
&lt;p&gt;ただ、今回は nginx や mysql の基本的なオペレーション手順は割愛させてもらいます。&lt;/p&gt;
&lt;p&gt;私の環境について&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% lsb_release -a
No LSB modules are available.
Distributor ID: Debian
Description:    Debian GNU/Linux 6.0.3 (squeeze)
Release:        6.0.3
Codename:       squeeze
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;インストールしたもの&amp;hellip;
メタパッケージを指定したのでその他必要なモノはインストールされます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% sudo apt-get update
% sudo apt-get install spawn-fcgi php5 php5-mysql php5-cgi mysql-server nginx 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まずはお決まりの gzip 圧縮転送。IE の古いモノ以外は対応しているので心配なし。今回のテーマと関係無いですけど、一応入れておきます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% diff -u /etc/nginx/nginx.conf.org /etc/nginx/nginx.conf
--- /etc/nginx/nginx.conf.org   2012-01-14 15:27:45.000000000 +0900
+++ /etc/nginx/nginx.conf       2012-01-14 15:28:58.000000000 +0900
@@ -22,6 +22,10 @@
     tcp_nodelay        on;
  
     gzip  on;
+    gzip_http_version 1.0;
+    gzip_vary         on;
+    gzip_comp_level   6;
+    gzip_types        text/html text/xml text/css application/xhtml+xml application/xml application/rss+xml application/atom_xml application/x-javascript application/x-httpd-php;
     gzip_disable &amp;quot;MSIE [1-6]\.(?!.*SV1)&amp;quot;;
 
     include /etc/nginx/conf.d/*.conf;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;spawn-fcgi を稼働させるスクリプトを生成する。/usr/bin/php-fastcgi として下記の内容で保存する。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
